"""
CSVæ•°æ®åŠ è½½å™¨æ¨¡å— (CSV Data Loader Module)

æä¾›CSVæ–‡ä»¶æ•°æ®åŠ è½½åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- åŸºç¡€CSVåŠ è½½
- OHLCVæ•°æ®å¤„ç†
- æ•°æ®éªŒè¯
- æ ¼å¼åŒ–å¤„ç†
"""

import os
from pathlib import Path
from typing import List, Optional, Union

import pandas as pd


class CSVDataLoader:
    """CSVæ•°æ®åŠ è½½å™¨ç±»"""

    def __init__(self, base_path: Optional[Union[str, Path]] = None):
        """
        åˆå§‹åŒ–CSVæ•°æ®åŠ è½½å™¨

        å‚æ•°:
            base_path: æ•°æ®æ–‡ä»¶åŸºç¡€è·¯å¾„
        """
        self.base_path = Path(base_path) if base_path else Path.cwd()

    def load_data(
        self, file_path: Union[str, Path], columns: Optional[List[str]] = None, **kwargs
    ) -> pd.DataFrame:
        """
        ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®

        å‚æ•°:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            columns: è¦åŠ è½½çš„åˆ—ååˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            **kwargs: pandas.read_csvçš„å…¶ä»–å‚æ•°

        è¿”å›:
            pandas DataFrame
        """
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not Path(file_path).is_absolute():
            file_path = self.base_path / file_path

        try:
            if columns:
                df = pd.read_csv(file_path, usecols=columns, **kwargs)
            else:
                df = pd.read_csv(file_path, **kwargs)

            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {file_path} ({len(df)} è¡Œ)")
            return df

        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨")
            return pd.DataFrame()
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def load_ohlcv_data(
        self, file_path: Union[str, Path], date_column: str = "date", validate_columns: bool = True
    ) -> pd.DataFrame:
        """
        åŠ è½½OHLCVæ ¼å¼çš„äº¤æ˜“æ•°æ®

        å‚æ•°:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            date_column: æ—¥æœŸåˆ—å
            validate_columns: æ˜¯å¦éªŒè¯å¿…éœ€åˆ—çš„å­˜åœ¨

        è¿”å›:
            å¤„ç†åçš„OHLCV DataFrame
        """
        df = self.load_data(file_path)

        if df.empty:
            return df

        # éªŒè¯å¿…éœ€çš„OHLCVåˆ—
        if validate_columns:
            required_columns = ["open", "high", "low", "close"]
            missing_columns = [col for col in required_columns if col not in df.columns]

            if missing_columns:
                print(f"âš ï¸ è­¦å‘Š: ç¼ºå¤±å¿…éœ€åˆ—: {missing_columns}")
                # å°è¯•æŸ¥æ‰¾ç›¸ä¼¼åˆ—å
                self._suggest_column_mapping(df.columns, missing_columns)

        return self._process_ohlcv_data(df, date_column)

    def _process_ohlcv_data(self, df: pd.DataFrame, date_column: str = "date") -> pd.DataFrame:
        """
        å¤„ç†OHLCVæ•°æ®çš„å†…éƒ¨æ–¹æ³•

        å‚æ•°:
            df: åŸå§‹DataFrame
            date_column: æ—¥æœŸåˆ—å

        è¿”å›:
            å¤„ç†åçš„DataFrame
        """
        # å¤åˆ¶DataFrameä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        df_processed = df.copy()

        # å¤„ç†æ—¥æœŸåˆ—
        if date_column in df_processed.columns:
            df_processed[date_column] = pd.to_datetime(df_processed[date_column])
            df_processed.set_index(date_column, inplace=True)
            df_processed.sort_index(inplace=True)
        else:
            print(f"âš ï¸ è­¦å‘Š: æ—¥æœŸåˆ— '{date_column}' ä¸å­˜åœ¨")

        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_columns = ["open", "high", "low", "close", "volume"]
        for col in numeric_columns:
            if col in df_processed.columns:
                df_processed[col] = pd.to_numeric(df_processed[col], errors="coerce")

        return df_processed

    def _suggest_column_mapping(self, existing_columns: List[str], missing_columns: List[str]):
        """
        å»ºè®®åˆ—åæ˜ å°„

        å‚æ•°:
            existing_columns: ç°æœ‰åˆ—å
            missing_columns: ç¼ºå¤±åˆ—å
        """
        suggestions = {
            "open": ["Open", "OPEN", "o", "opening"],
            "high": ["High", "HIGH", "h", "max"],
            "low": ["Low", "LOW", "l", "min"],
            "close": ["Close", "CLOSE", "c", "closing"],
            "volume": ["Volume", "VOLUME", "v", "vol"],
        }

        for missing_col in missing_columns:
            if missing_col in suggestions:
                possible_matches = [
                    col for col in existing_columns if col in suggestions[missing_col]
                ]
                if possible_matches:
                    print(f"  ğŸ’¡ å»ºè®®: '{missing_col}' å¯èƒ½å¯¹åº” {possible_matches}")

    def load_multiple_files(
        self, file_patterns: List[Union[str, Path]], combine: bool = False
    ) -> Union[List[pd.DataFrame], pd.DataFrame]:
        """
        åŠ è½½å¤šä¸ªCSVæ–‡ä»¶

        å‚æ•°:
            file_patterns: æ–‡ä»¶è·¯å¾„æ¨¡å¼åˆ—è¡¨
            combine: æ˜¯å¦åˆå¹¶æ‰€æœ‰æ•°æ®

        è¿”å›:
            DataFrameåˆ—è¡¨æˆ–åˆå¹¶åçš„DataFrame
        """
        dataframes = []

        for pattern in file_patterns:
            if isinstance(pattern, str) and ("*" in pattern or "?" in pattern):
                # å¤„ç†é€šé…ç¬¦æ¨¡å¼
                matching_files = list(self.base_path.glob(pattern))
            else:
                matching_files = [self.base_path / pattern]

            for file_path in matching_files:
                if file_path.exists():
                    df = self.load_data(file_path)
                    if not df.empty:
                        df["source_file"] = file_path.name  # æ·»åŠ æ¥æºæ–‡ä»¶ä¿¡æ¯
                        dataframes.append(df)

        if combine and dataframes:
            combined_df = pd.concat(dataframes, ignore_index=True)
            print(f"âœ… åˆå¹¶äº† {len(dataframes)} ä¸ªæ–‡ä»¶çš„æ•°æ®")
            return combined_df

        return dataframes

    def get_file_info(self, file_path: Union[str, Path]) -> dict:
        """
        è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯

        å‚æ•°:
            file_path: æ–‡ä»¶è·¯å¾„

        è¿”å›:
            æ–‡ä»¶ä¿¡æ¯å­—å…¸
        """
        if not Path(file_path).is_absolute():
            file_path = self.base_path / file_path

        try:
            file_stats = os.stat(file_path)
            # è¯»å–æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯
            sample_df = pd.read_csv(file_path, nrows=5)

            return {
                "file_path": str(file_path),
                "file_size_mb": round(file_stats.st_size / (1024 * 1024), 2),
                "columns": list(sample_df.columns),
                "column_count": len(sample_df.columns),
                "sample_rows": len(sample_df),
                "exists": True,
            }
        except Exception as e:
            return {"file_path": str(file_path), "error": str(e), "exists": False}


# ä¾¿æ·å‡½æ•°
def load_csv(
    file_path: Union[str, Path] = "btc_eth.csv",  # æ·»åŠ é»˜è®¤å€¼ä»¥ä¿æŒå‘åå…¼å®¹
    columns: Optional[List[str]] = None,
    base_path: Optional[Union[str, Path]] = None,
    **kwargs,
) -> pd.DataFrame:
    """
    ä¾¿æ·çš„CSVåŠ è½½å‡½æ•°

    å‚æ•°:
        file_path: CSVæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤btc_eth.csvä»¥ä¿æŒå‘åå…¼å®¹ï¼‰
        columns: è¦åŠ è½½çš„åˆ—ååˆ—è¡¨
        base_path: åŸºç¡€è·¯å¾„
        **kwargs: pandas.read_csvçš„å…¶ä»–å‚æ•°

    è¿”å›:
        pandas DataFrame
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç‰¹æ®Šå‚æ•°ï¼Œä½¿ç”¨æ—§çš„è¡Œä¸ºï¼ˆè§£ææ—¥æœŸå’Œè®¾ç½®ç´¢å¼•ï¼‰
    if not kwargs and file_path == "btc_eth.csv":
        kwargs = {"parse_dates": ["date"], "index_col": "date"}

    loader = CSVDataLoader(base_path)
    return loader.load_data(file_path, columns, **kwargs)


def load_ohlcv_csv(
    file_path: Union[str, Path],
    date_column: str = "date",
    base_path: Optional[Union[str, Path]] = None,
) -> pd.DataFrame:
    """
    ä¾¿æ·çš„OHLCV CSVåŠ è½½å‡½æ•°

    å‚æ•°:
        file_path: CSVæ–‡ä»¶è·¯å¾„
        date_column: æ—¥æœŸåˆ—å
        base_path: åŸºç¡€è·¯å¾„

    è¿”å›:
        å¤„ç†åçš„OHLCV DataFrame
    """
    loader = CSVDataLoader(base_path)
    return loader.load_ohlcv_data(file_path, date_column)
