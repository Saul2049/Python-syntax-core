#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤æ˜“ç³»ç»Ÿç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨
é›†æˆä¸šåŠ¡æŒ‡æ ‡åˆ°ç°æœ‰çš„äº¤æ˜“ç³»ç»Ÿç»„ä»¶ä¸­
"""

import logging
import os
import time
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Any, Dict, Generator, Optional

from .prometheus_exporter import PrometheusExporter


def _setup_prometheus_imports():
    """è®¾ç½®Prometheuså¯¼å…¥ï¼Œæä¾›å›é€€æœºåˆ¶ä»¥é™ä½å¤æ‚åº¦"""
    try:
        from prometheus_client import (
            CollectorRegistry,
            Counter,
            Gauge,
            Histogram,
            start_http_server,
        )

        return CollectorRegistry, Counter, Gauge, Histogram, start_http_server
    except ImportError:
        return _create_fallback_prometheus_classes()


def _create_fallback_prometheus_classes():
    """åˆ›å»ºPrometheusçš„å›é€€ç±»å®ç°"""

    class Counter:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def labels(self, *args: Any, **kwargs: Any) -> "Counter":
            return self

        def inc(self, *args: Any, **kwargs: Any) -> None:
            pass

    class Histogram:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def observe(self, *args: Any, **kwargs: Any) -> None:
            pass

    class Gauge:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def set(self, *args: Any, **kwargs: Any) -> None:
            pass

    def start_http_server(*args: Any, **kwargs: Any) -> None:
        pass

    return None, Counter, Gauge, Histogram, start_http_server


# è®¾ç½®Prometheusç»„ä»¶
CollectorRegistry, Counter, Gauge, Histogram, start_http_server = _setup_prometheus_imports()


@dataclass
class MetricsConfig:
    """
    ç›‘æ§é…ç½®ç±» (Monitoring configuration class)

    Attributes:
        enabled: æ˜¯å¦å¯ç”¨ç›‘æ§ (Whether monitoring is enabled)
        port: PrometheusæœåŠ¡ç«¯å£ (Prometheus server port)
        include_system_metrics: æ˜¯å¦åŒ…å«ç³»ç»ŸæŒ‡æ ‡ (Whether to include system metrics)
    """

    enabled: bool = True  # ç›‘æ§å¯ç”¨çŠ¶æ€
    port: int = 8000  # Prometheusç«¯å£
    include_system_metrics: bool = True  # ç³»ç»ŸæŒ‡æ ‡å¼€å…³


class TradingMetricsCollector:
    """äº¤æ˜“ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, config: Optional[MetricsConfig] = None) -> None:
        """
        åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨

        Args:
            config: ç›‘æ§é…ç½®å¯¹è±¡ (Monitoring configuration object)
        """
        # å‘åå…¼å®¹ï¼šå¦‚æœconfigä¸æ˜¯MetricsConfigç±»å‹ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
        if config is not None and not isinstance(config, MetricsConfig):
            self.exporter: Optional[PrometheusExporter] = config  # ä¿å­˜ä¼ å…¥çš„exporter
            config = MetricsConfig()
        else:
            self.exporter: Optional[PrometheusExporter] = None

        self.config: MetricsConfig = config or MetricsConfig()
        self.logger: logging.Logger = logging.getLogger(__name__)
        self._server_started: bool = False

        if not self.config.enabled:
            self.logger.info("ç›‘æ§å·²ç¦ç”¨")
            return

        self._init_metrics()

    def _init_metrics(self) -> None:
        """åˆå§‹åŒ–PrometheusæŒ‡æ ‡"""
        # æ¸…é™¤ç°æœ‰æ³¨å†Œè¡¨ä»¥é¿å…é‡å¤æ³¨å†Œé”™è¯¯
        from prometheus_client import REGISTRY

        try:
            # æ¸…é™¤æ‰€æœ‰å·²æ³¨å†Œçš„æŒ‡æ ‡ï¼ˆé™¤äº†é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼‰
            collectors_to_remove: list = []
            for collector in list(REGISTRY._collector_to_names.keys()):
                # åªä¿ç•™é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼Œæ¸…é™¤å…¶ä»–æ‰€æœ‰æŒ‡æ ‡
                if hasattr(collector, "_name"):
                    metric_names: list[str] = REGISTRY._collector_to_names.get(collector, [])
                    # ä¿ç•™é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼ˆè¿™äº›æ˜¯ç”±prometheus_clientè‡ªåŠ¨åˆ›å»ºçš„ï¼‰
                    is_default_process_metric: bool = any(
                        name
                        in [
                            "process_virtual_memory_bytes",
                            "process_resident_memory_bytes",
                            "process_start_time_seconds",
                            "process_cpu_seconds_total",
                            "process_open_fds",
                            "process_max_fds",
                            "python_gc_objects_collected_total",
                            "python_gc_objects_uncollectable_total",
                            "python_gc_collections_total",
                            "python_info",
                        ]
                        for name in metric_names
                    )
                    if not is_default_process_metric:
                        collectors_to_remove.append(collector)

            for collector in collectors_to_remove:
                try:
                    REGISTRY.unregister(collector)
                except (KeyError, ValueError):
                    pass  # å·²ç»è¢«ç§»é™¤æˆ–ä¸å­˜åœ¨
        except Exception:
            pass  # å¿½ç•¥æ¸…ç†é”™è¯¯ï¼Œç»§ç»­åˆå§‹åŒ–

        # ä¿¡å·å¤„ç†å»¶è¿Ÿ (Signal processing latency)
        self.signal_latency: Histogram = Histogram(
            "trading_signal_latency_seconds",
            "Time to calculate trading signals",
            buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
        )

        # è®¢å•æ‰§è¡Œå»¶è¿Ÿ (Order execution latency)
        self.order_latency: Histogram = Histogram(
            "trading_order_latency_seconds",
            "Time to execute orders",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0],
        )

        # æ•°æ®è·å–å»¶è¿Ÿ (Data fetch latency)
        self.data_fetch_latency: Histogram = Histogram(
            "trading_data_fetch_latency_seconds",
            "Time to fetch market data",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0],
        )

        # æ»‘ç‚¹ç›‘æ§ (Slippage monitoring)
        self.slippage: Histogram = Histogram(
            "trading_slippage_percentage",
            "Price slippage percentage",
            buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0],
        )

        # å¼‚å¸¸è®¡æ•° (Exception counter)
        self.exceptions: Counter = Counter(
            "trading_exceptions_total",
            "Total exceptions by module and type",
            ["module", "exception_type"],
        )

        # è´¦æˆ·ä½™é¢ (Account balance)
        self.account_balance: Gauge = Gauge("trading_account_balance_usd", "Account balance in USD")

        # å›æ’¤ç›‘æ§ (Drawdown monitoring)
        self.drawdown: Gauge = Gauge("trading_drawdown_percentage", "Current drawdown from peak")

        # æŒä»“æ•°é‡ (Position count)
        self.position_count: Gauge = Gauge("trading_positions_total", "Number of open positions")

        # APIè°ƒç”¨æ¬¡æ•° (API call counter)
        self.api_calls: Counter = Counter(
            "trading_api_calls_total", "Total API calls by endpoint", ["endpoint", "status"]
        )

        # WebSocketå¿ƒè·³ (WebSocket heartbeat)
        self.ws_heartbeat_age: Gauge = Gauge(
            "trading_ws_heartbeat_age_seconds", "WebSocket heartbeat age in seconds"
        )

        # ATRè®¡ç®—å»¶è¿Ÿ (ATR calculation latency)
        self.atr_calculation_latency: Histogram = Histogram(
            "atr_calculation_latency_seconds",
            "ATRè®¡ç®—å»¶è¿Ÿ",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
        )

        # M4é˜¶æ®µ - WebSocketç›¸å…³æŒ‡æ ‡ (M4 Phase - WebSocket related metrics)
        self.ws_latency: Histogram = Histogram(
            "binance_ws_latency_seconds",
            "WebSocketæ¶ˆæ¯å»¶è¿Ÿ",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0],
        )

        self.ws_reconnects_total: Counter = Counter(
            "ws_reconnects_total", "WebSocketé‡è¿æ¬¡æ•°", ["symbol", "reason"]
        )

        self.ws_connections_total: Counter = Counter(
            "ws_connections_total", "WebSocketè¿æ¥æ¬¡æ•°", ["status"]  # success, error
        )

        self.ws_messages_total: Counter = Counter(
            "ws_messages_total", "WebSocketæ¶ˆæ¯è®¡æ•°", ["symbol", "type"]  # kline, ticker
        )

        self.price_updates_total: Counter = Counter(
            "price_updates_total", "ä»·æ ¼æ›´æ–°è®¡æ•°", ["symbol", "source"]  # source: ws, api
        )

        self.order_roundtrip_latency: Histogram = Histogram(
            "order_roundtrip_latency_seconds",
            "è®¢å•å¾€è¿”å»¶è¿Ÿ",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
        )

        self.concurrent_tasks: Gauge = Gauge(
            "concurrent_tasks_count", "å¹¶å‘ä»»åŠ¡æ•°é‡", ["task_type"]  # order_execution, data_fetch
        )

        self.ws_processing_time: Histogram = Histogram(
            "ws_processing_time_seconds",
            "WebSocketæ¶ˆæ¯å¤„ç†æ—¶é—´",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
        )

        self.msg_lag: Histogram = Histogram(
            "message_lag_seconds",
            "æ¶ˆæ¯å»¶è¿Ÿï¼ˆä»äº¤æ˜“æ‰€åˆ°æœ¬åœ°å¤„ç†ï¼‰",
            buckets=[0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0],
        )

        # M5é˜¶æ®µæ€§èƒ½ç›‘æ§æŒ‡æ ‡ (M5 Phase performance monitoring metrics)

        # ä»»åŠ¡å»¶è¿ŸæŒ‡æ ‡ (Task latency metrics)
        self.task_latency: Histogram = Histogram(
            "task_latency_seconds",
            "å„ç±»ä»»åŠ¡æ‰§è¡Œå»¶è¿Ÿ (Task execution latency)",
            ["task_type"],  # signal_processing, order_placement, data_analysis
            buckets=[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 30.0],
        )

        # å†…å­˜ä½¿ç”¨æŒ‡æ ‡ (Memory usage metrics)
        self.process_memory_usage: Gauge = Gauge(
            "process_memory_usage_bytes", "è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡ (Process memory usage in bytes)"
        )

        self.process_memory_percent: Gauge = Gauge(
            "process_memory_percent", "è¿›ç¨‹å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯” (Process memory usage percentage)"
        )

        self.process_cpu_percent: Gauge = Gauge(
            "process_cpu_percent", "è¿›ç¨‹CPUä½¿ç”¨ç™¾åˆ†æ¯” (Process CPU usage percentage)"
        )

        self.process_threads: Gauge = Gauge(
            "process_threads_count", "è¿›ç¨‹çº¿ç¨‹æ•° (Process thread count)"
        )

        self.process_fds: Gauge = Gauge(
            "process_file_descriptors", "è¿›ç¨‹æ–‡ä»¶æè¿°ç¬¦æ•°é‡ (Process file descriptor count)"
        )

        # åƒåœ¾å›æ”¶æŒ‡æ ‡ (Garbage collection metrics)
        self.gc_collections: Counter = Counter(
            "gc_collections_total", "åƒåœ¾å›æ”¶æ¬¡æ•° (Garbage collection count)", ["generation"]
        )

        self.gc_collected_objects: Counter = Counter(
            "gc_collected_objects_total", "å›æ”¶å¯¹è±¡æ•° (Collected objects count)", ["generation"]
        )

        self.gc_pause_time: Histogram = Histogram(
            "gc_pause_time_seconds",
            "åƒåœ¾å›æ”¶æš‚åœæ—¶é—´ (Garbage collection pause time)",
            buckets=[0.001, 0.01, 0.1, 0.5, 1.0, 5.0],
        )

        self.gc_tracked_objects: Gauge = Gauge(
            "gc_tracked_objects", "GCè·Ÿè¸ªå¯¹è±¡æ•°é‡ (Number of objects tracked by GC)"
        )

        # å†…å­˜åˆ†é…è·Ÿè¸ª (Memory allocation tracking)
        self.memory_allocation_rate: Gauge = Gauge(
            "memory_allocation_rate_bytes_per_second",
            "å†…å­˜åˆ†é…é€Ÿç‡ (Memory allocation rate in bytes per second)",
        )

        self.memory_peak_usage: Gauge = Gauge(
            "memory_peak_usage_bytes", "å†…å­˜ä½¿ç”¨å³°å€¼ (Peak memory usage in bytes)"
        )

        # å†…å­˜å¢é•¿ç›‘æ§ (Memory growth monitoring)
        self.memory_growth_rate: Gauge = Gauge(
            "memory_growth_rate_mb_per_minute",
            "å†…å­˜å¢é•¿é€Ÿç‡ (Memory growth rate in MB per minute)",
        )

        self.fd_growth_rate: Gauge = Gauge(
            "fd_growth_rate_per_minute", "æ–‡ä»¶æè¿°ç¬¦å¢é•¿é€Ÿç‡ (FD growth rate per minute)"
        )

        # å†…å­˜å¥åº·çŠ¶æ€ (Memory health status)
        self.memory_health_score: Gauge = Gauge(
            "memory_health_score", "å†…å­˜å¥åº·è¯„åˆ† (Memory health score 0-100)"
        )

        # å½“å‰ä»·æ ¼æŒ‡æ ‡ (Current price metrics) - ä¿®å¤ç¼ºå¤±çš„æŒ‡æ ‡
        self.current_price: Gauge = Gauge(
            "trading_current_price_usd",
            "å½“å‰äº¤æ˜“ä»·æ ¼ (Current trading price by symbol)",
            ["symbol"],
        )

    def start_server(self) -> None:
        """
        å¯åŠ¨Prometheus HTTPæœåŠ¡å™¨

        Raises:
            Exception: æœåŠ¡å™¨å¯åŠ¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if not self.config.enabled or self._server_started:
            return

        try:
            port: int = self.config.port
            start_http_server(port)
            self._server_started = True
            self.logger.info(f"PrometheusæŒ‡æ ‡æœåŠ¡å™¨å·²å¯åŠ¨åœ¨ç«¯å£ {port}")
        except Exception as e:
            self.logger.error(f"å¯åŠ¨PrometheusæœåŠ¡å™¨å¤±è´¥: {e}")
            raise

    @contextmanager
    def measure_signal_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡ä¿¡å·è®¡ç®—å»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_signal_latency():
                signals = strategy.generate_signals(data)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = time.perf_counter() - start_time
            self.signal_latency.observe(elapsed)

    @contextmanager
    def measure_order_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡è®¢å•æ‰§è¡Œå»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_order_latency():
                order_result = broker.place_order(...)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = time.perf_counter() - start_time
            self.order_latency.observe(elapsed)

    @contextmanager
    def measure_data_fetch_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡æ•°æ®è·å–å»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_data_fetch_latency():
                data = fetch_price_data(symbol)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = time.perf_counter() - start_time
            self.data_fetch_latency.observe(elapsed)

    def record_slippage(self, expected_price: float, actual_price: float) -> None:
        """
        è®°å½•æ»‘ç‚¹

        Args:
            expected_price: æœŸæœ›ä»·æ ¼ (Expected price)
            actual_price: å®é™…ä»·æ ¼ (Actual price)
        """
        slippage_percent: float = abs(actual_price - expected_price) / expected_price * 100
        self.slippage.observe(slippage_percent)

    def record_exception(self, module: str, exception: Exception) -> None:
        """
        è®°å½•å¼‚å¸¸

        Args:
            module: æ¨¡å—å (Module name)
            exception: å¼‚å¸¸å¯¹è±¡ (Exception object)
        """
        exception_type: str = type(exception).__name__
        self.exceptions.labels(module=module, exception_type=exception_type).inc()

    def update_account_balance(self, balance_usd: float) -> None:
        """
        æ›´æ–°è´¦æˆ·ä½™é¢

        Args:
            balance_usd: ç¾å…ƒä½™é¢ (USD balance)
        """
        self.account_balance.set(balance_usd)

    def update_drawdown(self, current_balance: float, peak_balance: float) -> None:
        """
        æ›´æ–°å›æ’¤

        Args:
            current_balance: å½“å‰ä½™é¢ (Current balance)
            peak_balance: å³°å€¼ä½™é¢ (Peak balance)
        """
        drawdown_percent: float = (peak_balance - current_balance) / peak_balance * 100
        self.drawdown.set(drawdown_percent)

    def update_position_count(self, count: int) -> None:
        """
        æ›´æ–°æŒä»“æ•°é‡

        Args:
            count: æŒä»“æ•°é‡ (Position count)
        """
        self.position_count.set(count)

    def record_api_call(self, endpoint: str, status: str) -> None:
        """
        è®°å½•APIè°ƒç”¨

        Args:
            endpoint: APIç«¯ç‚¹ (API endpoint)
            status: çŠ¶æ€ç  (Status code)
        """
        self.api_calls.labels(endpoint=endpoint, status=status).inc()

    def update_ws_heartbeat_age(self, last_heartbeat_timestamp: float) -> None:
        """
        æ›´æ–°WebSocketå¿ƒè·³å¹´é¾„

        Args:
            last_heartbeat_timestamp: æœ€åå¿ƒè·³æ—¶é—´æˆ³ (Last heartbeat timestamp)
        """
        current_time: float = time.time()
        age_seconds: float = current_time - last_heartbeat_timestamp
        self.ws_heartbeat_age.set(age_seconds)

    # M4é˜¶æ®µ - WebSocketæŒ‡æ ‡è®°å½•æ–¹æ³•
    def observe_ws_latency(self, latency_seconds: float):
        """è®°å½•WebSocketå»¶è¿Ÿ"""
        self.ws_latency.observe(latency_seconds)

    def record_ws_reconnect(self, symbol: str = "ALL", reason: str = "connection_lost"):
        """è®°å½•WebSocketé‡è¿"""
        self.ws_reconnects_total.labels(symbol=symbol, reason=reason).inc()

    def record_ws_connection_success(self):
        """è®°å½•WebSocketè¿æ¥æˆåŠŸ"""
        self.ws_connections_total.labels(status="success").inc()

    def record_ws_connection_error(self):
        """è®°å½•WebSocketè¿æ¥é”™è¯¯"""
        self.ws_connections_total.labels(status="error").inc()

    def record_ws_message(self, symbol: str, msg_type: str):
        """è®°å½•WebSocketæ¶ˆæ¯"""
        self.ws_messages_total.labels(symbol=symbol, type=msg_type).inc()

    def record_price_update(self, symbol: str, price: float, source: str = "ws"):
        """è®°å½•ä»·æ ¼æ›´æ–°"""
        self.price_updates_total.labels(symbol=symbol, source=source).inc()

        # åŒæ—¶æ›´æ–°ä»·æ ¼æŒ‡æ ‡
        self.current_price.labels(symbol=symbol).set(price)

    def observe_msg_lag(self, lag_seconds: float):
        """è®°å½•æ¶ˆæ¯æ»åæ—¶é—´"""
        self.msg_lag.observe(lag_seconds)

    def observe_order_roundtrip_latency(self, latency_seconds: float):
        """è®°å½•è®¢å•å¾€è¿”å»¶è¿Ÿ"""
        self.order_roundtrip_latency.observe(latency_seconds)

    def update_concurrent_tasks(self, task_type: str, count: int):
        """æ›´æ–°å¹¶å‘ä»»åŠ¡è®¡æ•°"""
        self.concurrent_tasks.labels(task_type=task_type).set(count)

    @contextmanager
    def measure_ws_processing_time(self):
        """æµ‹é‡WebSocketæ¶ˆæ¯å¤„ç†æ—¶é—´"""
        start_time = time.time()
        try:
            yield
        finally:
            processing_time = time.time() - start_time
            self.signal_latency.observe(processing_time)

    @contextmanager
    def measure_task_latency(self, task_type: str = "general"):
        """æµ‹é‡å¼‚æ­¥ä»»åŠ¡å»¶è¿Ÿ"""
        if not self.config.enabled:
            yield
            return

        start_time = time.time()
        try:
            yield
        finally:
            latency = time.time() - start_time
            self.task_latency.labels(task_type=task_type).observe(latency)

    def observe_task_latency(self, task_type: str, latency_seconds: float):
        """ç›´æ¥è®°å½•ä»»åŠ¡å»¶è¿Ÿ"""
        if not self.config.enabled:
            return
        self.task_latency.labels(task_type=task_type).observe(latency_seconds)

    # M5é˜¶æ®µ - å†…å­˜å’ŒGCç›‘æ§æ–¹æ³•
    def update_process_memory_stats(self):
        """æ›´æ–°è¿›ç¨‹å†…å­˜ç»Ÿè®¡"""
        if not self.config.enabled:
            return

        try:
            import psutil

            process = psutil.Process()

            memory_info = process.memory_info()
            self.process_memory_usage.set(memory_info.rss)
            self.process_memory_percent.set(process.memory_percent())
            self.process_cpu_percent.set(process.cpu_percent())

            # æ–‡ä»¶æè¿°ç¬¦
            try:
                num_fds = process.num_fds()
            except AttributeError:
                # Windowsä¸æ”¯æŒnum_fds
                num_fds = len(process.open_files())
            self.process_fds.set(num_fds)

            # çº¿ç¨‹æ•°
            self.process_threads.set(process.num_threads())

            # ç½‘ç»œè¿æ¥
            connections = process.connections()
            self.active_connections.labels(connection_type="total").set(len(connections))

            # æ›´æ–°å†…å­˜å³°å€¼
            current_rss = memory_info.rss
            if not hasattr(self, "_peak_rss") or current_rss > self._peak_rss:
                self._peak_rss = current_rss
                self.memory_peak_usage.set(current_rss)

        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿›ç¨‹å†…å­˜ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

    def record_gc_event(self, generation: int, pause_duration: float, collected_objects: int):
        """è®°å½•GCäº‹ä»¶"""
        if not self.config.enabled:
            return

        gen_label = str(generation)
        self.gc_collections.labels(generation=gen_label).inc()
        self.gc_pause_time.labels(generation=gen_label).observe(pause_duration)
        self.gc_collected_objects.labels(generation=gen_label).inc(collected_objects)

    def update_gc_tracked_objects(self):
        """æ›´æ–°GCè¿½è¸ªçš„å¯¹è±¡æ•°é‡"""
        if not self.config.enabled:
            return

        try:
            import gc

            for generation in range(3):
                objects_count = len(gc.get_objects(generation))
                self.gc_tracked_objects.labels(generation=str(generation)).set(objects_count)
        except Exception as e:
            self.logger.warning(f"âš ï¸ GCå¯¹è±¡ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

    def record_memory_allocation(self, size_bytes: int):
        """è®°å½•å†…å­˜åˆ†é…"""
        if not self.config.enabled:
            return

        # è®°å½•å†…å­˜åˆ†é…å¤§å°
        self.memory_allocation_rate.set(size_bytes)

    def update_memory_growth_rate(self, growth_mb_per_minute: float):
        """æ›´æ–°å†…å­˜å¢é•¿ç‡"""
        if not self.config.enabled:
            return
        self.memory_growth_rate.set(growth_mb_per_minute)

    def update_fd_growth_rate(self, growth_per_minute: float):
        """æ›´æ–°æ–‡ä»¶æè¿°ç¬¦å¢é•¿ç‡"""
        if not self.config.enabled:
            return
        self.fd_growth_rate.set(growth_per_minute)

    @contextmanager
    def monitor_memory_allocation(self, operation_name: str = "unknown"):
        """ç›‘æ§å†…å­˜åˆ†é…çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if not self.config.enabled:
            yield
            return

        try:
            import tracemalloc

            was_tracing = tracemalloc.is_tracing()

            if not was_tracing:
                tracemalloc.start()

            # è·å–å¼€å§‹æ—¶çš„å†…å­˜å¿«ç…§
            snapshot_start = tracemalloc.take_snapshot()

            yield

            # è·å–ç»“æŸæ—¶çš„å†…å­˜å¿«ç…§
            snapshot_end = tracemalloc.take_snapshot()

            # è®¡ç®—å·®å¼‚
            top_stats = snapshot_end.compare_to(snapshot_start, "lineno")

            # è®°å½•æœ€å¤§çš„å‡ ä¸ªåˆ†é…
            for stat in top_stats[:5]:
                self.record_memory_allocation(stat.size)

            if not was_tracing:
                tracemalloc.stop()

        except Exception as e:
            self.logger.warning(f"âš ï¸ å†…å­˜åˆ†é…ç›‘æ§å¤±è´¥: {e}")

    def get_memory_health_status(self) -> Dict[str, Any]:
        """è·å–å†…å­˜å¥åº·çŠ¶æ€"""
        try:
            import gc

            import psutil

            process = psutil.Process()
            memory_info = process.memory_info()

            # å½“å‰çŠ¶æ€
            current_rss_mb = memory_info.rss / 1024 / 1024
            current_vms_mb = memory_info.vms / 1024 / 1024
            memory_percent = process.memory_percent()

            # GCçŠ¶æ€
            gc_counts = gc.get_count()
            gc_thresholds = gc.get_threshold()

            # å¥åº·è¯„ä¼°
            health_issues = []

            if current_rss_mb > 100:  # RSS > 100MB
                health_issues.append(f"RSSå†…å­˜ä½¿ç”¨è¿‡é«˜: {current_rss_mb:.1f}MB")

            if memory_percent > 5:  # è¶…è¿‡ç³»ç»Ÿå†…å­˜5%
                health_issues.append(f"ç³»ç»Ÿå†…å­˜å ç”¨è¿‡é«˜: {memory_percent:.1f}%")

            if gc_counts[0] > gc_thresholds[0] * 0.9:  # Gen0æ¥è¿‘é˜ˆå€¼
                health_issues.append(f"GC Gen0æ¥è¿‘é˜ˆå€¼: {gc_counts[0]}/{gc_thresholds[0]}")

            return {
                "timestamp": time.time(),
                "memory": {
                    "rss_mb": current_rss_mb,
                    "vms_mb": current_vms_mb,
                    "percent": memory_percent,
                    "peak_rss_mb": getattr(self, "_peak_rss", 0) / 1024 / 1024,
                },
                "gc": {"counts": gc_counts, "thresholds": gc_thresholds},
                "health": {
                    "status": "healthy" if not health_issues else "warning",
                    "issues": health_issues,
                },
            }

        except Exception as e:
            return {"error": str(e), "timestamp": time.time()}

    def get_error_summary(self) -> Dict[str, int]:
        """è·å–é”™è¯¯ç»Ÿè®¡æ‘˜è¦"""
        try:
            from prometheus_client import REGISTRY

            return self._extract_error_counts_from_registry(REGISTRY)
        except Exception as e:
            self.logger.warning(f"âš ï¸ è·å–é”™è¯¯æ‘˜è¦å¤±è´¥: {e}")
            return {}

    def _extract_error_counts_from_registry(self, registry) -> Dict[str, int]:
        """ä»Prometheusæ³¨å†Œè¡¨æå–é”™è¯¯è®¡æ•°"""
        error_counts = {}

        for collector in registry._collector_to_names.keys():
            if not self._is_exception_collector(collector):
                continue

            try:
                self._process_exception_samples(collector, error_counts)
            except Exception:
                pass

        return error_counts

    def _is_exception_collector(self, collector) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚å¸¸æ”¶é›†å™¨"""
        return hasattr(collector, "_name") and "exceptions" in str(collector._name)

    def _process_exception_samples(self, collector, error_counts: Dict[str, int]):
        """å¤„ç†å¼‚å¸¸æ ·æœ¬æ•°æ®"""
        for sample in collector.collect():
            for metric_sample in sample.samples:
                if "exceptions_total" in metric_sample.name:
                    module = metric_sample.labels.get("module", "unknown")
                    value = int(metric_sample.value)
                    error_counts[module] = error_counts.get(module, 0) + value

    def record_trade(self, symbol: str, action: str, price: float = 0.0, quantity: float = 0.0):
        """
        è®°å½•äº¤æ˜“äº‹ä»¶ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            action: äº¤æ˜“åŠ¨ä½œ (buy/sell)
            price: äº¤æ˜“ä»·æ ¼
            quantity: äº¤æ˜“æ•°é‡
        """
        try:
            # è®°å½•ä»·æ ¼æ›´æ–°
            self.record_price_update(symbol, price, source="trade")

            # è®°å½•äº¤æ˜“ä»·æ ¼
            if price > 0:
                self.current_price.labels(symbol=symbol).set(price)

            self.logger.info(f"ğŸ“Š è®°å½•äº¤æ˜“: {symbol} {action} @ {price} x {quantity}")

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•äº¤æ˜“å¤±è´¥: {e}")
            self.record_exception("metrics_collector", e)

    def get_trade_summary(self) -> Dict[str, Any]:
        """
        è·å–äº¤æ˜“æ‘˜è¦ (å‘åå…¼å®¹æ–¹æ³•)

        Returns:
            äº¤æ˜“æ‘˜è¦ä¿¡æ¯ï¼ŒåŒ…å«äº¤æ˜“å¯¹ä½œä¸ºé¡¶çº§é”®
        """
        try:
            from prometheus_client import REGISTRY

            return self._extract_trade_summary_from_registry(REGISTRY)
        except Exception as e:
            self.logger.error(f"âŒ è·å–äº¤æ˜“æ‘˜è¦å¤±è´¥: {e}")
            return {}

    def _extract_trade_summary_from_registry(self, registry) -> Dict[str, Any]:
        """ä»Prometheusæ³¨å†Œè¡¨æå–äº¤æ˜“æ‘˜è¦"""
        summary = {}

        for collector in registry._collector_to_names.keys():
            try:
                self._process_trade_samples(collector, summary)
            except Exception:
                pass

        return summary if summary else {}

    def _process_trade_samples(self, collector, summary: Dict[str, Any]):
        """å¤„ç†äº¤æ˜“æ ·æœ¬æ•°æ®"""
        for sample in collector.collect():
            for metric_sample in sample.samples:
                if "price_updates_total" in metric_sample.name:
                    self._update_trade_summary_for_symbol(metric_sample, summary)

    def _update_trade_summary_for_symbol(self, metric_sample, summary: Dict[str, Any]):
        """ä¸ºç‰¹å®šäº¤æ˜“å¯¹æ›´æ–°äº¤æ˜“æ‘˜è¦"""
        if "symbol" not in metric_sample.labels:
            return

        symbol = metric_sample.labels["symbol"]
        if symbol not in summary:
            summary[symbol] = {"trades": 0, "price_updates": 0}

        summary[symbol]["price_updates"] += int(metric_sample.value)
        summary[symbol]["trades"] += 1

    def record_error(self, module: str, error_message: str):
        """
        è®°å½•é”™è¯¯ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            module: æ¨¡å—åç§°
            error_message: é”™è¯¯æ¶ˆæ¯
        """
        try:
            # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿå¼‚å¸¸æ¥è®°å½•
            error = Exception(error_message)
            self.record_exception(module, error)

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•é”™è¯¯å¤±è´¥: {e}")

    def update_price(self, symbol: str, price: float):
        """
        æ›´æ–°ä»·æ ¼ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            price: ä»·æ ¼
        """
        try:
            self.current_price.labels(symbol=symbol).set(price)
            self.record_price_update(symbol, price, source="manual")

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°ä»·æ ¼å¤±è´¥: {e}")

    def get_latest_prices(self) -> Dict[str, float]:
        """
        è·å–æœ€æ–°ä»·æ ¼ (å‘åå…¼å®¹æ–¹æ³•)

        Returns:
            ç¬¦å·åˆ°ä»·æ ¼çš„æ˜ å°„
        """
        try:
            from prometheus_client import REGISTRY

            prices = {}

            # ä»Prometheusæ³¨å†Œè¡¨ä¸­è·å–ä»·æ ¼æ•°æ®
            for collector in REGISTRY._collector_to_names.keys():
                try:
                    for sample in collector.collect():
                        for metric_sample in sample.samples:
                            if "current_price_usd" in metric_sample.name:
                                if "symbol" in metric_sample.labels:
                                    symbol = metric_sample.labels["symbol"]
                                    prices[symbol] = float(metric_sample.value)

                except Exception:
                    pass

            return prices

        except Exception as e:
            self.logger.error(f"âŒ è·å–æœ€æ–°ä»·æ ¼å¤±è´¥: {e}")
            return {}

    def update_heartbeat(self):
        """
        æ›´æ–°å¿ƒè·³ (å‘åå…¼å®¹æ–¹æ³•)
        """
        try:
            current_time = time.time()
            if hasattr(self, "exporter") and hasattr(self.exporter, "last_heartbeat"):
                self.exporter.last_heartbeat = current_time
            else:
                # è®¾ç½®ä¸€ä¸ªé€šç”¨çš„å¿ƒè·³æ—¶é—´æˆ³
                self._last_heartbeat = current_time

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°å¿ƒè·³å¤±è´¥: {e}")

    def update_data_source_status(self, source_name: str, is_active: bool):
        """
        æ›´æ–°æ•°æ®æºçŠ¶æ€ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            source_name: æ•°æ®æºåç§°
            is_active: æ˜¯å¦æ´»è·ƒ
        """
        try:
            # ä½¿ç”¨è¿æ¥çŠ¶æ€æŒ‡æ ‡
            status = 1 if is_active else 0
            self.active_connections.labels(connection_type=source_name).set(status)

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°æ•°æ®æºçŠ¶æ€å¤±è´¥: {e}")

    def update_memory_usage(self, memory_mb: float):
        """
        æ›´æ–°å†…å­˜ä½¿ç”¨é‡ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            memory_mb: å†…å­˜ä½¿ç”¨é‡(MB)
        """
        try:
            memory_bytes = memory_mb * 1024 * 1024
            self.process_memory_usage.set(memory_bytes)

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°å†…å­˜ä½¿ç”¨é‡å¤±è´¥: {e}")


# å…¨å±€ç›‘æ§å®ä¾‹
_global_collector: Optional[TradingMetricsCollector] = None


def get_metrics_collector() -> TradingMetricsCollector:
    """è·å–å…¨å±€ç›‘æ§å®ä¾‹"""
    global _global_collector

    if _global_collector is None:
        config = MetricsConfig(
            enabled=os.getenv("METRICS_ENABLED", "true").lower() == "true",
            port=int(os.getenv("PROMETHEUS_PORT", "8000")),
        )
        _global_collector = TradingMetricsCollector(config)

    return _global_collector


def init_monitoring() -> TradingMetricsCollector:
    """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
    collector = get_metrics_collector()
    collector.start_server()
    return collector
