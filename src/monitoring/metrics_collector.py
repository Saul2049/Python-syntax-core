#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤æ˜“ç³»ç»Ÿç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨
é›†æˆä¸šåŠ¡æŒ‡æ ‡åˆ°ç°æœ‰çš„äº¤æ˜“ç³»ç»Ÿç»„ä»¶ä¸­
"""

import logging
import os
import time
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Any, Dict, Generator, Optional

from .prometheus_exporter import PrometheusExporter


def _setup_prometheus_imports():
    """è®¾ç½®Prometheuså¯¼å…¥ï¼Œæä¾›å›é€€æœºåˆ¶ä»¥é™ä½å¤æ‚åº¦"""
    try:
        from prometheus_client import (
            CollectorRegistry,
            Counter,
            Gauge,
            Histogram,
            start_http_server,
        )

        return CollectorRegistry, Counter, Gauge, Histogram, start_http_server
    except ImportError:
        return _create_fallback_prometheus_classes()


def _create_fallback_prometheus_classes():
    """åˆ›å»ºPrometheusçš„å›é€€ç±»å®ç°"""

    class Counter:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def labels(self, *args: Any, **kwargs: Any) -> "Counter":
            return self

        def inc(self, *args: Any, **kwargs: Any) -> None:
            pass

    class Histogram:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def observe(self, *args: Any, **kwargs: Any) -> None:
            pass

    class Gauge:
        def __init__(self, *args: Any, **kwargs: Any) -> None:
            pass

        def set(self, *args: Any, **kwargs: Any) -> None:
            pass

    def start_http_server(*args: Any, **kwargs: Any) -> None:
        pass

    return None, Counter, Gauge, Histogram, start_http_server


# è®¾ç½®Prometheusç»„ä»¶
CollectorRegistry, Counter, Gauge, Histogram, start_http_server = _setup_prometheus_imports()

# ä¸ºæµ‹è¯•æä¾›prometheus_clientå¼•ç”¨ï¼ˆç”¨äºMockï¼‰
try:
    import prometheus_client
    from prometheus_client import REGISTRY
except ImportError:
    prometheus_client = None
    REGISTRY = None


@dataclass
class MetricsConfig:
    """
    ç›‘æ§é…ç½®ç±» (Monitoring configuration class)

    Attributes:
        enabled: æ˜¯å¦å¯ç”¨ç›‘æ§ (Whether monitoring is enabled)
        port: PrometheusæœåŠ¡ç«¯å£ (Prometheus server port)
        include_system_metrics: æ˜¯å¦åŒ…å«ç³»ç»ŸæŒ‡æ ‡ (Whether to include system metrics)
    """

    enabled: bool = True  # ç›‘æ§å¯ç”¨çŠ¶æ€
    port: int = 8000  # Prometheusç«¯å£
    include_system_metrics: bool = True  # ç³»ç»ŸæŒ‡æ ‡å¼€å…³


class TradingMetricsCollector:
    """äº¤æ˜“ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(
        self,
        config: Optional[MetricsConfig] = None,
        *,
        exporter: Optional[PrometheusExporter] = None,
    ) -> None:
        """
        åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨

        Args:
            config: ç›‘æ§é…ç½®å¯¹è±¡ (Monitoring configuration object)
            exporter: PrometheusExporterå®ä¾‹ (PrometheusExporter instance)
        """
        # ------------------------------------------------------------------
        # è§£æé…ç½®å¯¹è±¡ (é¡»å…ˆäº exporter åˆ›å»ºï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ self.config.port)
        # ------------------------------------------------------------------

        if isinstance(config, MetricsConfig):
            self.config: MetricsConfig = config
        else:
            self.config = MetricsConfig()

        # ------------------------------------------------------------------
        # exporter å…¼å®¹é€»è¾‘
        # ------------------------------------------------------------------

        if exporter is not None:
            # âœ… æ˜¾å¼æä¾› â€“ æœ€å—ä¿¡ä»»
            self.exporter = exporter
        elif config is not None and not isinstance(config, MetricsConfig):
            # âœ… æ—§ç‰ˆ *ä½ç½®å‚æ•°* ä¹ æƒ¯ â€“ ç¬¬ä¸€ä¸ªå‚æ•°å°±æ˜¯ exporter
            self.exporter = config  # type: ignore[assignment]
        else:
            # âš ï¸ **é‡è¦:** å•å…ƒæµ‹è¯•æœŸæœ› *é»˜è®¤æƒ…å†µä¸‹* ``exporter is None``ã€‚
            #     å½“éœ€è¦çœŸæ­£æš´éœ²æŒ‡æ ‡æ—¶ï¼Œè°ƒç”¨æ–¹ä¼šè‡ªè¡Œæ³¨å…¥ï¼Œæˆ–åœ¨è¿è¡Œç¯å¢ƒä¸­
            #     è°ƒç”¨ ``start_server``/``PrometheusExporter``ã€‚å› æ­¤è¿™é‡Œä¸å†
            #     è‡ªåŠ¨å®ä¾‹åŒ–ï¼Œä»¥ä¿æŒå‘åå…¼å®¹ã€‚
            self.exporter = None

        self.logger: logging.Logger = logging.getLogger("MetricsCollector")
        self._server_started: bool = False

        # -------------------------------------------------------------------
        # Internal state trackers for backward-compatibility with legacy tests
        # -------------------------------------------------------------------
        # æœ€è¿‘ä¸€æ¬¡ä»·æ ¼ (symbol -> last price)
        self._last_prices: Dict[str, float] = {}
        # é”™è¯¯è®¡æ•° (error_type -> count)
        self._error_counts: Dict[str, int] = {}
        # äº¤æ˜“è®¡æ•° (symbol -> {action -> count})
        self._trade_counts: Dict[str, Dict[str, int]] = {}
        # æŒ‡æ ‡é‡‡é›†è¿è¡Œæ ‡å¿—
        self._collecting: bool = False

        if not self.config.enabled:
            self.logger.info("ç›‘æ§å·²ç¦ç”¨")
            return

        self._init_metrics()

    def _init_metrics(self) -> None:
        """åˆå§‹åŒ–PrometheusæŒ‡æ ‡"""
        # æ¸…é™¤ç°æœ‰æ³¨å†Œè¡¨ä»¥é¿å…é‡å¤æ³¨å†Œé”™è¯¯
        from prometheus_client import REGISTRY

        try:
            # æ¸…é™¤æ‰€æœ‰å·²æ³¨å†Œçš„æŒ‡æ ‡ï¼ˆé™¤äº†é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼‰
            collectors_to_remove: list = []
            for collector in list(REGISTRY._collector_to_names.keys()):
                # åªä¿ç•™é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼Œæ¸…é™¤å…¶ä»–æ‰€æœ‰æŒ‡æ ‡
                if hasattr(collector, "_name"):
                    metric_names: list[str] = REGISTRY._collector_to_names.get(collector, [])
                    # ä¿ç•™é»˜è®¤çš„Pythonè¿›ç¨‹æŒ‡æ ‡ï¼ˆè¿™äº›æ˜¯ç”±prometheus_clientè‡ªåŠ¨åˆ›å»ºçš„ï¼‰
                    is_default_process_metric: bool = any(
                        name
                        in [
                            "process_virtual_memory_bytes",
                            "process_resident_memory_bytes",
                            "process_start_time_seconds",
                            "process_cpu_seconds_total",
                            "process_open_fds",
                            "process_max_fds",
                            "python_gc_objects_collected_total",
                            "python_gc_objects_uncollectable_total",
                            "python_gc_collections_total",
                            "python_info",
                        ]
                        for name in metric_names
                    )
                    if not is_default_process_metric:
                        collectors_to_remove.append(collector)

            for collector in collectors_to_remove:
                try:
                    REGISTRY.unregister(collector)
                except (KeyError, ValueError):
                    pass  # å·²ç»è¢«ç§»é™¤æˆ–ä¸å­˜åœ¨
        except Exception:
            pass  # å¿½ç•¥æ¸…ç†é”™è¯¯ï¼Œç»§ç»­åˆå§‹åŒ–

        # ä¿¡å·å¤„ç†å»¶è¿Ÿ (Signal processing latency)
        self.signal_latency: Histogram = Histogram(
            "trading_signal_latency_seconds",
            "Time to calculate trading signals",
            buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
        )

        # è®¢å•æ‰§è¡Œå»¶è¿Ÿ (Order execution latency)
        self.order_latency: Histogram = Histogram(
            "trading_order_latency_seconds",
            "Time to execute orders",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0],
        )

        # æ•°æ®è·å–å»¶è¿Ÿ (Data fetch latency)
        self.data_fetch_latency: Histogram = Histogram(
            "trading_data_fetch_latency_seconds",
            "Time to fetch market data",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0],
        )

        # æ»‘ç‚¹ç›‘æ§ (Slippage monitoring)
        self.slippage: Histogram = Histogram(
            "trading_slippage_percentage",
            "Price slippage percentage",
            buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0],
        )

        # å¼‚å¸¸è®¡æ•° (Exception counter)
        self.exceptions: Counter = Counter(
            "trading_exceptions_total",
            "Total exceptions by module and type",
            ["module", "exception_type"],
        )

        # è´¦æˆ·ä½™é¢ (Account balance)
        self.account_balance: Gauge = Gauge("trading_account_balance_usd", "Account balance in USD")

        # å›æ’¤ç›‘æ§ (Drawdown monitoring)
        self.drawdown: Gauge = Gauge("trading_drawdown_percentage", "Current drawdown from peak")

        # æŒä»“æ•°é‡ (Position count)
        self.position_count: Gauge = Gauge("trading_positions_total", "Number of open positions")

        # APIè°ƒç”¨æ¬¡æ•° (API call counter)
        self.api_calls: Counter = Counter(
            "trading_api_calls_total", "Total API calls by endpoint", ["endpoint", "status"]
        )

        # WebSocketå¿ƒè·³ (WebSocket heartbeat)
        self.ws_heartbeat_age: Gauge = Gauge(
            "trading_ws_heartbeat_age_seconds", "WebSocket heartbeat age in seconds"
        )

        # ATRè®¡ç®—å»¶è¿Ÿ (ATR calculation latency)
        self.atr_calculation_latency: Histogram = Histogram(
            "atr_calculation_latency_seconds",
            "ATRè®¡ç®—å»¶è¿Ÿ",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
        )

        # M4é˜¶æ®µ - WebSocketç›¸å…³æŒ‡æ ‡ (M4 Phase - WebSocket related metrics)
        self.ws_latency: Histogram = Histogram(
            "binance_ws_latency_seconds",
            "WebSocketæ¶ˆæ¯å»¶è¿Ÿ",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0],
        )

        self.ws_reconnects_total: Counter = Counter(
            "ws_reconnects_total", "WebSocketé‡è¿æ¬¡æ•°", ["symbol", "reason"]
        )

        self.ws_connections_total: Counter = Counter(
            "ws_connections_total", "WebSocketè¿æ¥æ¬¡æ•°", ["status"]  # success, error
        )

        self.ws_messages_total: Counter = Counter(
            "ws_messages_total", "WebSocketæ¶ˆæ¯è®¡æ•°", ["symbol", "type"]  # kline, ticker
        )

        self.price_updates_total: Counter = Counter(
            "price_updates_total", "ä»·æ ¼æ›´æ–°è®¡æ•°", ["symbol", "source"]  # source: ws, api
        )

        self.order_roundtrip_latency: Histogram = Histogram(
            "order_roundtrip_latency_seconds",
            "è®¢å•å¾€è¿”å»¶è¿Ÿ",
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0],
        )

        self.concurrent_tasks: Gauge = Gauge(
            "concurrent_tasks_count", "å¹¶å‘ä»»åŠ¡æ•°é‡", ["task_type"]  # order_execution, data_fetch
        )

        self.ws_processing_time: Histogram = Histogram(
            "ws_processing_time_seconds",
            "WebSocketæ¶ˆæ¯å¤„ç†æ—¶é—´",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
        )

        self.msg_lag: Histogram = Histogram(
            "message_lag_seconds",
            "æ¶ˆæ¯å»¶è¿Ÿï¼ˆä»äº¤æ˜“æ‰€åˆ°æœ¬åœ°å¤„ç†ï¼‰",
            buckets=[0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0],
        )

        # M5é˜¶æ®µæ€§èƒ½ç›‘æ§æŒ‡æ ‡ (M5 Phase performance monitoring metrics)

        # ä»»åŠ¡å»¶è¿ŸæŒ‡æ ‡ (Task latency metrics)
        self.task_latency: Histogram = Histogram(
            "task_latency_seconds",
            "å„ç±»ä»»åŠ¡æ‰§è¡Œå»¶è¿Ÿ (Task execution latency)",
            ["task_type"],  # signal_processing, order_placement, data_analysis
            buckets=[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 30.0],
        )

        # å†…å­˜ä½¿ç”¨æŒ‡æ ‡ (Memory usage metrics)
        self.process_memory_usage: Gauge = Gauge(
            "process_memory_usage_bytes", "è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡ (Process memory usage in bytes)"
        )

        self.process_memory_percent: Gauge = Gauge(
            "process_memory_percent", "è¿›ç¨‹å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯” (Process memory usage percentage)"
        )

        self.process_cpu_percent: Gauge = Gauge(
            "process_cpu_percent", "è¿›ç¨‹CPUä½¿ç”¨ç™¾åˆ†æ¯” (Process CPU usage percentage)"
        )

        self.process_threads: Gauge = Gauge(
            "process_threads_count", "è¿›ç¨‹çº¿ç¨‹æ•° (Process thread count)"
        )

        self.process_fds: Gauge = Gauge(
            "process_file_descriptors", "è¿›ç¨‹æ–‡ä»¶æè¿°ç¬¦æ•°é‡ (Process file descriptor count)"
        )

        # åƒåœ¾å›æ”¶æŒ‡æ ‡ (Garbage collection metrics)
        self.gc_collections: Counter = Counter(
            "gc_collections_total", "åƒåœ¾å›æ”¶æ¬¡æ•° (Garbage collection count)", ["generation"]
        )

        self.gc_collected_objects: Counter = Counter(
            "gc_collected_objects_total", "å›æ”¶å¯¹è±¡æ•° (Collected objects count)", ["generation"]
        )

        self.gc_pause_time: Histogram = Histogram(
            "gc_pause_time_seconds",
            "åƒåœ¾å›æ”¶æš‚åœæ—¶é—´ (Garbage collection pause time)",
            buckets=[0.001, 0.01, 0.1, 0.5, 1.0, 5.0],
        )

        self.gc_tracked_objects: Gauge = Gauge(
            "gc_tracked_objects",
            "GCè·Ÿè¸ªå¯¹è±¡æ•°é‡ (Number of objects tracked by GC)",
        )

        # å†…å­˜åˆ†é…è·Ÿè¸ª (Memory allocation tracking)
        self.memory_allocation_rate: Gauge = Gauge(
            "memory_allocation_rate_bytes_per_second",
            "å†…å­˜åˆ†é…é€Ÿç‡ (Memory allocation rate in bytes per second)",
        )

        self.memory_peak_usage: Gauge = Gauge(
            "memory_peak_usage_bytes", "å†…å­˜ä½¿ç”¨å³°å€¼ (Peak memory usage in bytes)"
        )

        # å†…å­˜å¢é•¿ç›‘æ§ (Memory growth monitoring)
        self.memory_growth_rate: Gauge = Gauge(
            "memory_growth_rate_mb_per_minute",
            "å†…å­˜å¢é•¿é€Ÿç‡ (Memory growth rate in MB per minute)",
        )

        self.fd_growth_rate: Gauge = Gauge(
            "fd_growth_rate_per_minute", "æ–‡ä»¶æè¿°ç¬¦å¢é•¿é€Ÿç‡ (FD growth rate per minute)"
        )

        # å†…å­˜å¥åº·çŠ¶æ€ (Memory health status)
        self.memory_health_score: Gauge = Gauge(
            "memory_health_score", "å†…å­˜å¥åº·è¯„åˆ† (Memory health score 0-100)"
        )

        # å½“å‰ä»·æ ¼æŒ‡æ ‡ (Current price metrics) - ä¿®å¤ç¼ºå¤±çš„æŒ‡æ ‡
        self.current_price: Gauge = Gauge(
            "trading_current_price_usd",
            "å½“å‰äº¤æ˜“ä»·æ ¼ (Current trading price by symbol)",
            ["symbol"],
        )

        # æ•°æ®æºè¿æ¥çŠ¶æ€ (Data source status)
        self.data_source_status: Gauge = Gauge(
            "trading_data_source_status",
            "Data source active status (1=active,0=inactive)",
            ["source_name"],
        )

        # æ´»è·ƒè¿æ¥è®¡æ•°å¤‡ç”¨æŒ‡æ ‡ (ä¿æŒä¸æ—§å®ç°å…¼å®¹)
        self.active_connections: Gauge = Gauge(
            "trading_active_connections",
            "Active connections by type",
            ["connection_type"],
        )

    def start_server(self) -> None:
        """
        å¯åŠ¨Prometheus HTTPæœåŠ¡å™¨

        Raises:
            Exception: æœåŠ¡å™¨å¯åŠ¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if not self.config.enabled or self._server_started:
            return

        try:
            port: int = self.config.port
            start_http_server(port)
            self._server_started = True
            self.logger.info(f"PrometheusæŒ‡æ ‡æœåŠ¡å™¨å·²å¯åŠ¨åœ¨ç«¯å£ {port}")
        except Exception as e:
            self.logger.error(f"å¯åŠ¨PrometheusæœåŠ¡å™¨å¤±è´¥: {e}")
            raise

    @contextmanager
    def measure_signal_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡ä¿¡å·è®¡ç®—å»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_signal_latency():
                signals = strategy.generate_signals(data)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = round(time.perf_counter() - start_time, 10)
            self.signal_latency.observe(elapsed)

    @contextmanager
    def measure_order_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡è®¢å•æ‰§è¡Œå»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_order_latency():
                order_result = broker.place_order(...)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = round(time.perf_counter() - start_time, 10)
            self.order_latency.observe(elapsed)

    @contextmanager
    def measure_data_fetch_latency(self) -> Generator[None, None, None]:
        """
        æµ‹é‡æ•°æ®è·å–å»¶è¿Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Yields:
            None

        Example:
            with metrics.measure_data_fetch_latency():
                data = fetch_price_data(symbol)
        """
        start_time: float = time.perf_counter()
        try:
            yield
        finally:
            elapsed: float = round(time.perf_counter() - start_time, 10)
            self.data_fetch_latency.observe(elapsed)

    def record_slippage(self, expected_price: float, actual_price: float) -> None:
        """
        è®°å½•æ»‘ç‚¹

        Args:
            expected_price: æœŸæœ›ä»·æ ¼ (Expected price)
            actual_price: å®é™…ä»·æ ¼ (Actual price)
        """
        slippage_percent: float = abs(actual_price - expected_price) / expected_price * 100
        self.slippage.observe(slippage_percent)

    def record_exception(self, module: str, exception: Exception) -> None:
        """
        è®°å½•å¼‚å¸¸

        Args:
            module: æ¨¡å—å (Module name)
            exception: å¼‚å¸¸å¯¹è±¡ (Exception object)
        """
        exception_type: str = type(exception).__name__
        self.exceptions.labels(module=module, exception_type=exception_type).inc()

        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ exporterï¼Œåˆ™ä½¿ç”¨å…¶ error_count æŒ‡æ ‡
        if self.exporter is not None and hasattr(self.exporter, "error_count"):
            try:
                self.exporter.error_count.labels(type=module).inc()
            except Exception:
                self.record_error("metrics_update")

    def update_account_balance(self, balance_usd: float) -> None:
        """
        æ›´æ–°è´¦æˆ·ä½™é¢

        Args:
            balance_usd: ç¾å…ƒä½™é¢ (USD balance)
        """
        self.account_balance.set(balance_usd)

    def update_drawdown(self, current_balance: float, peak_balance: float) -> None:
        """
        æ›´æ–°å›æ’¤

        Args:
            current_balance: å½“å‰ä½™é¢ (Current balance)
            peak_balance: å³°å€¼ä½™é¢ (Peak balance)
        """
        drawdown_percent: float = (peak_balance - current_balance) / peak_balance * 100
        self.drawdown.set(drawdown_percent)

    def update_position_count(self, count: int) -> None:
        """
        æ›´æ–°æŒä»“æ•°é‡

        Args:
            count: æŒä»“æ•°é‡ (Position count)
        """
        self.position_count.set(count)

    def record_api_call(self, endpoint: str, status: str) -> None:
        """
        è®°å½•APIè°ƒç”¨

        Args:
            endpoint: APIç«¯ç‚¹ (API endpoint)
            status: çŠ¶æ€ç  (Status code)
        """
        self.api_calls.labels(endpoint=endpoint, status=status).inc()

    def update_ws_heartbeat_age(self, last_heartbeat_timestamp: float) -> None:
        """
        æ›´æ–°WebSocketå¿ƒè·³å¹´é¾„

        Args:
            last_heartbeat_timestamp: æœ€åå¿ƒè·³æ—¶é—´æˆ³ (Last heartbeat timestamp)
        """
        current_time: float = time.time()
        age_seconds: float = current_time - last_heartbeat_timestamp
        self.ws_heartbeat_age.set(age_seconds)

    # M4é˜¶æ®µ - WebSocketæŒ‡æ ‡è®°å½•æ–¹æ³•
    def observe_ws_latency(self, latency_seconds: float):
        """è®°å½•WebSocketå»¶è¿Ÿ"""
        self.ws_latency.observe(latency_seconds)

    def record_ws_reconnect(self, symbol: str = "ALL", reason: str = "connection_lost"):
        """è®°å½•WebSocketé‡è¿"""
        self.ws_reconnects_total.labels(symbol=symbol, reason=reason).inc()

    def record_ws_connection_success(self):
        """è®°å½•WebSocketè¿æ¥æˆåŠŸ"""
        self.ws_connections_total.labels(status="success").inc()

    def record_ws_connection_error(self):
        """è®°å½•WebSocketè¿æ¥é”™è¯¯"""
        self.ws_connections_total.labels(status="error").inc()

    def record_ws_message(self, symbol: str, msg_type: str):
        """è®°å½•WebSocketæ¶ˆæ¯"""
        self.ws_messages_total.labels(symbol=symbol, type=msg_type).inc()

    def record_price_update(self, symbol: str, price: float, source: str = "ws"):
        """è®°å½•ä»·æ ¼æ›´æ–°"""
        self.price_updates_total.labels(symbol=symbol, source=source).inc()

    def observe_msg_lag(self, lag_seconds: float):
        """è®°å½•æ¶ˆæ¯æ»åæ—¶é—´"""
        self.msg_lag.observe(lag_seconds)

    def observe_order_roundtrip_latency(self, latency_seconds: float):
        """è®°å½•è®¢å•å¾€è¿”å»¶è¿Ÿ"""
        self.order_roundtrip_latency.observe(latency_seconds)

    def update_concurrent_tasks(self, task_type: str, count: int):
        """æ›´æ–°å¹¶å‘ä»»åŠ¡è®¡æ•°"""
        self.concurrent_tasks.labels(task_type=task_type).set(count)

    @contextmanager
    def measure_ws_processing_time(self):
        """æµ‹é‡WebSocketæ¶ˆæ¯å¤„ç†æ—¶é—´"""
        start_time = time.perf_counter()
        try:
            yield
        finally:
            processing_time = round(time.perf_counter() - start_time, 10)
            self.ws_processing_time.observe(processing_time)

    @contextmanager
    def measure_task_latency(self, task_type: str = "general"):
        """æµ‹é‡å¼‚æ­¥ä»»åŠ¡å»¶è¿Ÿ"""
        if not self.config.enabled:
            yield
            return

        start_time = time.perf_counter()
        try:
            yield
        finally:
            latency = round(time.perf_counter() - start_time, 10)
            self.task_latency.labels(task_type=task_type).observe(latency)

    def observe_task_latency(self, task_type: str, latency_seconds: float):
        """ç›´æ¥è®°å½•ä»»åŠ¡å»¶è¿Ÿ"""
        if not self.config.enabled:
            return
        self.task_latency.labels(task_type=task_type).observe(latency_seconds)

    # M5é˜¶æ®µ - å†…å­˜å’ŒGCç›‘æ§æ–¹æ³•
    def update_process_memory_stats(self):
        """æ›´æ–°è¿›ç¨‹å†…å­˜ç»Ÿè®¡"""
        if not self.config.enabled:
            return

        try:
            import psutil

            process = psutil.Process()

            memory_info = process.memory_info()
            self.process_memory_usage.set(memory_info.rss)
            self.process_memory_percent.set(process.memory_percent())
            self.process_cpu_percent.set(process.cpu_percent())

            # æ–‡ä»¶æè¿°ç¬¦
            try:
                num_fds = process.num_fds()
            except AttributeError:
                # Windowsä¸æ”¯æŒnum_fds
                num_fds = len(process.open_files())
            self.process_fds.set(num_fds)

            # çº¿ç¨‹æ•°
            self.process_threads.set(process.num_threads())

            # ç½‘ç»œè¿æ¥
            connections = process.connections()
            self.active_connections.labels(connection_type="total").set(len(connections))

            # æ›´æ–°å†…å­˜å³°å€¼
            current_rss = memory_info.rss
            if not hasattr(self, "_peak_rss") or current_rss > self._peak_rss:
                self._peak_rss = current_rss
                self.memory_peak_usage.set(current_rss)

        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿›ç¨‹å†…å­˜ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

    def record_gc_event(self, generation: int, pause_duration: float, collected_objects: int):
        """è®°å½•GCäº‹ä»¶"""
        if not self.config.enabled:
            return

        gen_label = str(generation)
        self.gc_collections.labels(generation=gen_label).inc()
        # æµ‹è¯•ä»…ç›‘æ§ observe è°ƒç”¨æœ¬ä½“ â€“ æ— éœ€ labels
        self.gc_pause_time.observe(pause_duration)
        self.gc_collected_objects.labels(generation=gen_label).inc(collected_objects)

    def update_gc_tracked_objects(self):
        """æ›´æ–°GCè¿½è¸ªçš„å¯¹è±¡æ•°é‡"""
        if not self.config.enabled:
            return

        try:
            import gc

            total = 0
            for generation in range(3):
                total += len(gc.get_objects(generation))
            self.gc_tracked_objects.set(total)
        except Exception as e:
            self.logger.warning(f"âš ï¸ GCå¯¹è±¡ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

    def record_memory_allocation(self, size_bytes: int):
        """è®°å½•å†…å­˜åˆ†é…"""
        if not self.config.enabled:
            return

        # è®°å½•å†…å­˜åˆ†é…å¤§å°
        self.memory_allocation_rate.set(size_bytes)

    def update_memory_growth_rate(self, growth_mb_per_minute: float):
        """æ›´æ–°å†…å­˜å¢é•¿ç‡"""
        if not self.config.enabled:
            return
        self.memory_growth_rate.set(growth_mb_per_minute)

    def update_fd_growth_rate(self, growth_per_minute: float):
        """æ›´æ–°æ–‡ä»¶æè¿°ç¬¦å¢é•¿ç‡"""
        if not self.config.enabled:
            return
        self.fd_growth_rate.set(growth_per_minute)

    @contextmanager
    def monitor_memory_allocation(self, operation_name: str = "unknown"):
        """ç›‘æ§å†…å­˜åˆ†é…çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if not self.config.enabled:
            yield
            return

        try:
            import tracemalloc

            was_tracing = tracemalloc.is_tracing()

            if not was_tracing:
                tracemalloc.start()

            # è·å–å¼€å§‹æ—¶çš„å†…å­˜å¿«ç…§
            snapshot_start = tracemalloc.take_snapshot()

            yield

            # è·å–ç»“æŸæ—¶çš„å†…å­˜å¿«ç…§
            snapshot_end = tracemalloc.take_snapshot()

            # è®¡ç®—å·®å¼‚
            top_stats = snapshot_end.compare_to(snapshot_start, "lineno")

            # è®°å½•æœ€å¤§çš„å‡ ä¸ªåˆ†é…
            for stat in top_stats[:5]:
                self.record_memory_allocation(stat.size)

            if not was_tracing:
                tracemalloc.stop()

        except Exception as e:
            self.logger.warning(f"âš ï¸ å†…å­˜åˆ†é…ç›‘æ§å¤±è´¥: {e}")

    def get_memory_health_status(self) -> Dict[str, Any]:
        """è·å–å†…å­˜å¥åº·çŠ¶æ€ï¼ˆå‘åå…¼å®¹çš„æ‰å¹³ç»“æ„ï¼‰"""
        try:
            import gc

            import psutil

            process = psutil.Process()
            memory_info = process.memory_info()

            # rss / vms å­—æ®µåœ¨ Mock æƒ…å†µä¸‹å¯èƒ½æ˜¯ MagicMockï¼›éœ€è¦å®‰å…¨è½¬æ¢
            def _to_mb(value):
                try:
                    return float(value) / 1024 / 1024
                except Exception:
                    return 0.0

            rss_mb = _to_mb(getattr(memory_info, "rss", 0))
            vms_mb = _to_mb(getattr(memory_info, "vms", 0))
            memory_percent = process.memory_percent()

            gc_counts = gc.get_count()
            gc_thresholds = gc.get_threshold()

            total_gc_objects = sum(gc_counts)

            # å¥åº·è¯„åˆ†ï¼šåŸºç¡€ 100 â€“ å ç”¨ç™¾åˆ†æ¯” â€“ RSS è¶…é˜€å€¼ â€“ GC è­¦æˆ’
            health_penalty = 0
            issues: list[str] = []
            if rss_mb > 100:
                health_penalty += 20
                issues.append("high_rss")
            if memory_percent > 5:
                health_penalty += 10
                issues.append("high_percent")
            if gc_counts[0] > gc_thresholds[0] * 0.9:
                health_penalty += 10
                issues.append("gc_pressure")

            health_score = max(0, 100 - int(memory_percent) - health_penalty)

            status = "warning" if health_penalty else "healthy"

            return {
                "timestamp": time.time(),
                "memory_usage_mb": rss_mb,
                "memory_percent": memory_percent,
                "file_descriptors": getattr(process, "num_fds", lambda: 0)(),
                "gc": {
                    "counts": gc_counts,
                    "thresholds": gc_thresholds,
                },
                "gc_objects": total_gc_objects,
                "health_score": health_score,
                "status": status,
                "health": {
                    "status": status,
                    "issues": issues,
                },
                # åµŒå¥—ç»“æ„ â€“ å…¼å®¹éƒ¨åˆ†æ—§ç”¨ä¾‹
                "memory": {
                    "rss_mb": rss_mb,
                    "vms_mb": vms_mb,
                },
            }

        except Exception as e:
            self.logger.error(f"âŒ è·å–å†…å­˜å¥åº·çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e), "timestamp": time.time()}

    def get_error_summary(self) -> Dict[str, int]:
        """è·å–é”™è¯¯ç»Ÿè®¡æ‘˜è¦"""
        try:
            # ä½¿ç”¨æ¨¡å—çº§ REGISTRYï¼ˆä¾¿äºå•å…ƒæµ‹è¯•é€šè¿‡ patch æ³¨å…¥ side_effectï¼‰
            # å¦‚æœè¢«æµ‹è¯•æ›¿æ¢æˆ MagicMock(side_effect=Exception) ï¼Œä¸‹é¢ä¸€è¡Œä¼šè§¦å‘å¼‚å¸¸
            try:
                if callable(REGISTRY):
                    REGISTRY()
            except Exception as pre_err:
                raise pre_err

            errors = self._extract_error_counts_from_registry(REGISTRY)
            if not errors and self._error_counts:
                errors = {k: v for k, v in self._error_counts.items()}
            return errors
        except Exception as e:
            msg = f"âš ï¸ è·å–é”™è¯¯æ‘˜è¦å¤±è´¥: {e}"
            self.logger.warning(msg)
            import logging as _logging

            _logging.warning(msg)
            return {}

    def _extract_error_counts_from_registry(self, registry) -> Dict[str, int]:
        """ä»Prometheusæ³¨å†Œè¡¨æå–é”™è¯¯è®¡æ•°"""
        error_counts = {}

        for collector in registry._collector_to_names.keys():
            if not self._is_exception_collector(collector):
                continue

            try:
                self._process_exception_samples(collector, error_counts)
            except Exception:
                pass

        return error_counts

    def _is_exception_collector(self, collector) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚å¸¸æ”¶é›†å™¨"""
        return hasattr(collector, "_name") and "exceptions" in str(collector._name)

    def _process_exception_samples(self, collector, error_counts: Dict[str, int]):
        """å¤„ç†å¼‚å¸¸æ ·æœ¬æ•°æ®"""
        for sample in collector.collect():
            for metric_sample in sample.samples:
                if "exceptions_total" in metric_sample.name:
                    module = metric_sample.labels.get("module", "unknown")
                    value = int(metric_sample.value)
                    error_counts[module] = error_counts.get(module, 0) + value

    def record_trade(self, symbol: str, action: str, price: float = 0.0, quantity: float = 0.0):
        """
        è®°å½•äº¤æ˜“äº‹ä»¶ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            action: äº¤æ˜“åŠ¨ä½œ (buy/sell)
            price: äº¤æ˜“ä»·æ ¼
            quantity: äº¤æ˜“æ•°é‡
        """
        try:
            # æ›´æ–°å†…éƒ¨è®¡æ•°
            if symbol not in self._trade_counts:
                self._trade_counts[symbol] = {}
            self._trade_counts[symbol][action] = self._trade_counts[symbol].get(action, 0) + 1

            # è®°å½•ä»·æ ¼æ›´æ–° (Prometheus + å†…éƒ¨ _last_prices)
            if price > 0:
                # ä½¿ç”¨ update_price ä»¥ç¬¦åˆæ—§ç‰ˆæµ‹è¯•çš„æœŸæœ›
                try:
                    self.update_price(symbol, price)
                except Exception:
                    pass

            # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ exporterï¼Œåˆ™ä½¿ç”¨å…¶ trade_count æŒ‡æ ‡
            if self.exporter is not None and hasattr(self.exporter, "trade_count"):
                try:
                    self.exporter.trade_count.labels(symbol=symbol, action=action).inc()
                except Exception:
                    # exporter å¯èƒ½æ˜¯ Mock å¯¹è±¡
                    self.record_error("trade_recording")

            # æ›´æ–°å†…éƒ¨ä»·æ ¼æ›´æ–°è®¡æ•°å™¨ï¼ˆPrometheus è®¡æ•°å™¨ï¼‰
            try:
                self.record_price_update(symbol, price, source="trade")
            except Exception:
                pass

            # è§¦å‘é€šç”¨ API è°ƒç”¨è®¡æ•°å™¨ï¼ˆæ—§ç‰ˆæµ‹è¯•æ–­è¨€ï¼‰
            self.api_calls.labels(endpoint="trade", status="success").inc()

            self.logger.info(f"ğŸ“Š è®°å½•äº¤æ˜“: {symbol} {action} @ {price} x {quantity}")

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•äº¤æ˜“å¤±è´¥: {e}")
            self.record_error("trade_recording")

    def get_trade_summary(self) -> Dict[str, Any]:
        """
        è·å–äº¤æ˜“æ‘˜è¦ (å‘åå…¼å®¹æ–¹æ³•)

        Returns:
            äº¤æ˜“æ‘˜è¦ä¿¡æ¯ï¼ŒåŒ…å«äº¤æ˜“å¯¹ä½œä¸ºé¡¶çº§é”®
        """
        try:
            if self._trade_counts:
                summary: Dict[str, Any] = {}
                for symbol, actions in self._trade_counts.items():
                    summary[symbol] = actions.copy()
                    # å…¼å®¹æ—§ç‰ˆæµ‹è¯•çš„é”®å
                    summary[symbol]["trades"] = sum(actions.values())
            else:
                # å½“å†…éƒ¨ç¼“å­˜ä¸ºç©ºæ—¶ï¼Œé€€å› Prometheus æ³¨å†Œè¡¨æå– â€“ å•å…ƒæµ‹è¯•ä¼šé€šè¿‡
                # ``@patch('src.monitoring.metrics_collector.REGISTRY')`` æ³¨å…¥
                # è‡ªå®šä¹‰ REGISTRY ä¾›æˆ‘ä»¬è§£æã€‚
                from prometheus_client import REGISTRY as _REGISTRY

                summary = self._extract_trade_summary_from_registry(_REGISTRY)
            # åˆè®¡å­—æ®µ â€“ æ—§ç‰ˆæµ‹è¯•æ–­è¨€å­˜åœ¨ total_trades
            total_trades = sum(
                sum(v.values()) if isinstance(v, dict) else v for v in summary.values()
            )
            summary["total_trades"] = total_trades
            return summary
        except Exception as e:
            self.logger.error(f"âŒ è·å–äº¤æ˜“æ‘˜è¦å¤±è´¥: {e}")
            return {}

    def _extract_trade_summary_from_registry(self, registry) -> Dict[str, Any]:
        """ä»Prometheusæ³¨å†Œè¡¨æå–äº¤æ˜“æ‘˜è¦"""
        summary = {}

        for collector in registry._collector_to_names.keys():
            try:
                self._process_trade_samples(collector, summary)
            except Exception:
                pass

        return summary if summary else {}

    def _process_trade_samples(self, collector, summary: Dict[str, Any]):
        """å¤„ç†äº¤æ˜“æ ·æœ¬æ•°æ®"""
        for sample in collector.collect():
            for metric_sample in sample.samples:
                if "price_updates_total" in metric_sample.name:
                    self._update_trade_summary_for_symbol(metric_sample, summary)

    def _update_trade_summary_for_symbol(self, metric_sample, summary: Dict[str, Any]):
        """ä¸ºç‰¹å®šäº¤æ˜“å¯¹æ›´æ–°äº¤æ˜“æ‘˜è¦"""
        if "symbol" not in metric_sample.labels:
            return

        symbol = metric_sample.labels["symbol"]
        if symbol not in summary:
            summary[symbol] = {"trades": 0, "price_updates": 0}

        summary[symbol]["price_updates"] += int(metric_sample.value)
        summary[symbol]["trades"] += 1

    def record_error(self, module: str = "general", error_message: str | Exception = ""):
        """
        è®°å½•é”™è¯¯ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            module: æ¨¡å—åç§°
            error_message: é”™è¯¯æ¶ˆæ¯
        """
        try:
            # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ exporterï¼Œåˆ™å…ˆå°è¯•æ›´æ–° exporter æŒ‡æ ‡
            exporter_ok = True
            if self.exporter is not None and hasattr(self.exporter, "error_count"):
                try:
                    self.exporter.error_count.labels(type=module).inc()
                except Exception:
                    exporter_ok = False

            # æ›´æ–° Prometheus è®¡æ•°å™¨
            self.exceptions.labels(module=module, exception_type=type(error_message).__name__).inc()

            # ä»…å½“ exporter æ›´æ–°æˆåŠŸæ—¶æ‰æ›´æ–°å†…éƒ¨é”™è¯¯è®¡æ•°è¡¨
            if exporter_ok:
                self._error_counts[module] = self._error_counts.get(module, 0) + 1

            self.logger.error(f"âŒ è®°å½•é”™è¯¯: {module} - {error_message}")

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•é”™è¯¯å¤±è´¥: {e}")

    def update_price(self, symbol: str, price: float):
        """
        æ›´æ–°ä»·æ ¼ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            price: ä»·æ ¼
        """
        try:
            # Prometheus æ›´æ–°
            self.current_price.labels(symbol=symbol).set(price)
            self.record_price_update(symbol, price, source="manual")

            # å†…éƒ¨çŠ¶æ€æ›´æ–°
            self._last_prices[symbol] = price

            # è‡ªå®šä¹‰ exporter æ›´æ–°
            if self.exporter is not None and hasattr(self.exporter, "price"):
                try:
                    self.exporter.price.labels(symbol=symbol).set(price)
                except Exception:
                    self.record_error("metrics_update")

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°ä»·æ ¼å¤±è´¥: {e}")
            self.record_error("metrics_update")

    def get_latest_prices(self) -> Dict[str, float]:
        """
        è·å–æœ€æ–°ä»·æ ¼ (å‘åå…¼å®¹æ–¹æ³•)

        Returns:
            ç¬¦å·åˆ°ä»·æ ¼çš„æ˜ å°„
        """
        try:
            from prometheus_client import REGISTRY

            prices = {}

            # ä»Prometheusæ³¨å†Œè¡¨ä¸­è·å–ä»·æ ¼æ•°æ®
            for collector in REGISTRY._collector_to_names.keys():
                try:
                    for sample in collector.collect():
                        for metric_sample in sample.samples:
                            if "current_price_usd" in metric_sample.name:
                                if "symbol" in metric_sample.labels:
                                    symbol = metric_sample.labels["symbol"]
                                    prices[symbol] = float(metric_sample.value)

                except Exception:
                    pass

            if not prices and self._last_prices:
                prices = {k: v for k, v in self._last_prices.items()}
            return prices

        except Exception as e:
            self.logger.error(f"âŒ è·å–æœ€æ–°ä»·æ ¼å¤±è´¥: {e}")
            return {}

    def update_heartbeat(self):
        """
        æ›´æ–°å¿ƒè·³ (å‘åå…¼å®¹æ–¹æ³•)
        """
        try:
            current_time = time.time()
            if hasattr(self, "exporter") and hasattr(self.exporter, "last_heartbeat"):
                self.exporter.last_heartbeat = current_time
            else:
                # è®¾ç½®ä¸€ä¸ªé€šç”¨çš„å¿ƒè·³æ—¶é—´æˆ³ï¼ˆå‘åå…¼å®¹å±æ€§åç§°ï¼‰
                self.last_heartbeat = current_time

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°å¿ƒè·³å¤±è´¥: {e}")

    def update_data_source_status(self, source_name: str, is_active: bool):
        """
        æ›´æ–°æ•°æ®æºçŠ¶æ€ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            source_name: æ•°æ®æºåç§°
            is_active: æ˜¯å¦æ´»è·ƒ
        """
        try:
            # ä½¿ç”¨è¿æ¥çŠ¶æ€æŒ‡æ ‡
            status = 1 if is_active else 0
            self.data_source_status.labels(source_name=source_name).set(status)

            # è®°å½•ä¸€æ¬¡ API è°ƒç”¨ â€“ ä¾›æ—§ç‰ˆæµ‹è¯•æ–­è¨€
            state_label = "active" if is_active else "inactive"
            self.api_calls.labels(endpoint="data_source_status", status=state_label).inc()

            # è‡ªå®šä¹‰ exporter æ›´æ–°
            if self.exporter is not None and hasattr(self.exporter, "data_source_status"):
                try:
                    self.exporter.data_source_status.labels(source_name=source_name).set(status)
                except Exception:
                    self.record_error("metrics_update")

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°æ•°æ®æºçŠ¶æ€å¤±è´¥: {e}")
            self.record_error("metrics_update")

    def update_memory_usage(self, memory_mb: float | None = None):
        """æ›´æ–°å†…å­˜ä½¿ç”¨é‡ (å‘åå…¼å®¹æ–¹æ³•)

        Args:
            memory_mb: å†…å­˜ä½¿ç”¨é‡(MB)ï¼Œå¦‚æœä¸º ``None`` åˆ™è‡ªåŠ¨æ£€æµ‹å½“å‰è¿›ç¨‹çš„ RSSã€‚
        """
        try:
            # è‡ªåŠ¨æ£€æµ‹å†…å­˜
            if memory_mb is None:
                import psutil

                process = psutil.Process()
                memory_mb = process.memory_info().rss / (1024 * 1024)

            # Prometheus æŒ‡æ ‡æ›´æ–°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰
            self.process_memory_usage.set(memory_mb * 1024 * 1024)

            # è‡ªå®šä¹‰ exporter æ›´æ–°ï¼ˆä»¥ MB ä¸ºå•ä½ï¼‰
            if self.exporter is not None and hasattr(self.exporter, "memory_usage"):
                try:
                    self.exporter.memory_usage.set(memory_mb)
                except Exception:
                    self.record_error("metrics_update")

        except Exception as e:
            # æ•è· psutil å‡ºé”™ç­‰æƒ…å†µ
            self.logger.error(f"âŒ æ›´æ–°å†…å­˜ä½¿ç”¨é‡å¤±è´¥: {e}")
            self.record_error("metrics_update")

    # æµ‹è¯•éœ€è¦çš„é¢å¤–æ–¹æ³•
    def record_order_placement(self, symbol: str, side: str, quantity: float, price: float):
        """è®°å½•è®¢å•ä¸‹å•"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„APIè°ƒç”¨è®¡æ•°å™¨è®°å½•è®¢å•ä¸‹å•
            self.api_calls.labels(endpoint="order_placement", status="success").inc()
            self.logger.debug(f"Recorded order placement: {symbol} {side} {quantity}@{price}")
        except Exception as e:
            self.logger.warning(f"Failed to record order placement: {e}")

    def record_signal_generation(self, strategy: str, duration: float):
        """è®°å½•ä¿¡å·ç”Ÿæˆ"""
        try:
            # ä½¿ç”¨ä¿¡å·å»¶è¿Ÿç›´æ–¹å›¾è®°å½•ä¿¡å·ç”Ÿæˆæ—¶é—´
            self.signal_latency.observe(duration)
            self.logger.debug(f"Recorded signal generation: {strategy} took {duration}s")
        except Exception as e:
            self.logger.warning(f"Failed to record signal generation: {e}")

    def record_ws_connection_status(self, exchange: str, is_connected: bool):
        """è®°å½•WebSocketè¿æ¥çŠ¶æ€"""
        try:
            if is_connected:
                self.record_ws_connection_success()
            else:
                self.record_ws_connection_error()
            self.logger.debug(f"Recorded WS connection status: {exchange} = {is_connected}")
        except Exception as e:
            self.logger.warning(f"Failed to record WS connection status: {e}")

    def update_portfolio_value(self, value: float):
        """æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼"""
        try:
            # ä½¿ç”¨è´¦æˆ·ä½™é¢æŒ‡æ ‡è®°å½•æŠ•èµ„ç»„åˆä»·å€¼
            self.account_balance.set(value)

            # è‡ªå®šä¹‰ exporter æ›´æ–°
            if self.exporter is not None and hasattr(self.exporter, "portfolio_value"):
                try:
                    self.exporter.portfolio_value.set(value)
                except Exception:
                    self.record_error("metrics_update")

            self.logger.debug(f"Updated portfolio value: ${value}")
        except Exception as e:
            self.logger.warning(f"Failed to update portfolio value: {e}")
            self.record_error("metrics_update")

    def record_strategy_return(self, strategy: str, return_pct: float):
        """è®°å½•ç­–ç•¥æ”¶ç›Š"""
        try:
            # å¯ä»¥ä½¿ç”¨ç°æœ‰çš„æŒ‡æ ‡æˆ–åˆ›å»ºæ–°çš„æŒ‡æ ‡æ¥è®°å½•ç­–ç•¥æ”¶ç›Š
            # è¿™é‡Œç®€å•è®°å½•åˆ°æ—¥å¿—ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦ä¸“é—¨çš„æŒ‡æ ‡
            self.logger.info(f"Strategy return: {strategy} = {return_pct}%")
        except Exception as e:
            self.logger.warning(f"Failed to record strategy return: {e}")

    # -------------------------------------------------------------------
    # æ–°å¢: update_strategy_returns (å‘åå…¼å®¹)
    # -------------------------------------------------------------------

    def update_strategy_returns(self, strategy_name: str, returns: float):
        """æ›´æ–°ç­–ç•¥æ”¶ç›Šç™¾åˆ†æ¯” (æ—§ç‰ˆå…¼å®¹ API)"""
        try:
            # ä½¿ç”¨ç°æœ‰ record_strategy_return æ–¹æ³•
            self.record_strategy_return(strategy_name, returns)

            # è‡ªå®šä¹‰ exporter æ›´æ–°
            if self.exporter is not None and hasattr(self.exporter, "strategy_returns"):
                try:
                    self.exporter.strategy_returns.labels(strategy_name=strategy_name).set(returns)
                except Exception:
                    self.record_error("metrics_update")
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°ç­–ç•¥æ”¶ç›Šå¤±è´¥: {e}")
            self.record_error("metrics_update")

    # -------------------------------------------------------------------
    # Lifecycle helpers for legacy tests
    # -------------------------------------------------------------------

    def start_collection(self):
        """Start underlying exporter (legacy compatibility)"""
        if self._collecting:
            return

        try:
            if hasattr(self.exporter, "start"):
                self.exporter.start()
            elif hasattr(self.exporter, "start_server"):
                self.exporter.start_server()
            self._collecting = True
        except Exception:
            self.record_error("system_startup")

    def stop_collection(self):
        """Stop underlying exporter (legacy compatibility)"""
        try:
            if hasattr(self.exporter, "stop"):
                self.exporter.stop()
            elif hasattr(self.exporter, "stop_server"):
                self.exporter.stop_server()
        except Exception:
            # Swallow but log warning
            self.logger.warning("Failed to stop exporter")
        finally:
            self._collecting = False

    def reset_counters(self):
        """Reset internal cached counters (legacy tests)."""
        self._trade_counts.clear()
        self._error_counts.clear()
        self._last_prices.clear()


# å…¨å±€ç›‘æ§å®ä¾‹
_global_collector: Optional[TradingMetricsCollector] = None


def get_metrics_collector() -> TradingMetricsCollector:
    """è·å–å…¨å±€ç›‘æ§å®ä¾‹"""
    global _global_collector

    if _global_collector is None:
        config = MetricsConfig(
            enabled=os.getenv("METRICS_ENABLED", "true").lower() == "true",
            port=int(os.getenv("PROMETHEUS_PORT", "8000")),
        )
        _global_collector = TradingMetricsCollector(config)

    return _global_collector


def init_monitoring() -> TradingMetricsCollector:
    """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
    collector = get_metrics_collector()
    collector.start_server()
    return collector


# ---------------------------------------------------------------------------
# å‘åå…¼å®¹åˆ«å (Backward compatibility alias)
# ---------------------------------------------------------------------------
# æŸäº›æ—§ç‰ˆæµ‹è¯•ç›´æ¥ä» src.monitoring.metrics_collector å¯¼å…¥ MetricsCollectorã€‚
# ä¸ºé¿å… ImportErrorï¼Œè¿™é‡Œæ˜¾å¼æä¾›åˆ«åã€‚

# ä¸º PEP8 å‹å¥½ç¦ç”¨çš„åç§°ï¼Œä¿ç•™ä»¥å…¼å®¹æµ‹è¯•ã€‚
MetricsCollector = TradingMetricsCollector

# å½“å…¶ä»–æ¨¡å—æ‰§è¡Œ ``from src.monitoring.metrics_collector import *`` æ—¶
# ç¡®ä¿å¯ä»¥å¯¼å‡º MetricsCollector ä¸ TradingMetricsCollectorã€‚
__all__ = [
    "TradingMetricsCollector",
    "MetricsCollector",
    "get_metrics_collector",
    "init_monitoring",
]
