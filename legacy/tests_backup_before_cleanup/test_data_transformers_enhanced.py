#!/usr/bin/env python3
"""
ðŸ§ª æ•°æ®è½¬æ¢å™¨å¢žå¼ºæµ‹è¯• (Data Transformers Enhanced Tests)

æå‡data_transformers.pyæ¨¡å—æµ‹è¯•è¦†ç›–çŽ‡çš„å…¨é¢æµ‹è¯•å¥—ä»¶
å½“å‰è¦†ç›–çŽ‡: 22% -> ç›®æ ‡: 80%+
"""

import unittest
from unittest.mock import patch

import numpy as np
import pandas as pd

from src.data.transformers.data_transformers import (
    DataNormalizer,
    DataSplitter,
    MissingValueHandler,
    TimeSeriesProcessor,
    create_sequences,
    create_train_test_split,
    normalize_data,
)


class TestDataNormalizerComprehensive(unittest.TestCase):
    """å…¨é¢æµ‹è¯•DataNormalizerç±»"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        self.df_data = pd.DataFrame(
            {"price": [100, 200, 300, 400, 500], "volume": [1000, 2000, 3000, 4000, 5000]}
        )
        self.series_data = pd.Series([10, 20, 30, 40, 50], name="test_series")

    def test_init_default_parameters(self):
        """æµ‹è¯•é»˜è®¤å‚æ•°åˆå§‹åŒ–"""
        normalizer = DataNormalizer()
        self.assertEqual(normalizer.method, "minmax")
        self.assertEqual(normalizer.feature_range, (0, 1))

    def test_init_custom_parameters(self):
        """æµ‹è¯•è‡ªå®šä¹‰å‚æ•°åˆå§‹åŒ–"""
        normalizer = DataNormalizer(method="standard", feature_range=(-1, 1))
        self.assertEqual(normalizer.method, "standard")
        self.assertEqual(normalizer.feature_range, (-1, 1))

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", True)
    def test_init_invalid_method_with_sklearn(self):
        """æµ‹è¯•æœ‰sklearnæ—¶çš„æ— æ•ˆæ–¹æ³•"""
        with self.assertRaises(ValueError):
            DataNormalizer(method="invalid_method")

    def test_fit_transform_dataframe_minmax(self):
        """æµ‹è¯•DataFrameçš„MinMaxå½’ä¸€åŒ–"""
        normalizer = DataNormalizer(method="minmax")
        result = normalizer.fit_transform(self.df_data)

        self.assertIsInstance(result, pd.DataFrame)
        self.assertTrue((result >= 0).all().all())
        self.assertTrue((result <= 1).all().all())
        self.assertEqual(result.index.tolist(), self.df_data.index.tolist())
        self.assertEqual(result.columns.tolist(), self.df_data.columns.tolist())

    def test_fit_transform_series_minmax(self):
        """æµ‹è¯•Seriesçš„MinMaxå½’ä¸€åŒ–"""
        normalizer = DataNormalizer(method="minmax")
        result = normalizer.fit_transform(self.series_data)

        self.assertIsInstance(result, pd.Series)
        self.assertTrue((result >= 0).all())
        self.assertTrue((result <= 1).all())
        self.assertEqual(result.name, self.series_data.name)

    def test_fit_transform_standard(self):
        """æµ‹è¯•æ ‡å‡†åŒ–"""
        normalizer = DataNormalizer(method="standard")
        result = normalizer.fit_transform(self.df_data)

        # æ ‡å‡†åŒ–åŽå‡å€¼åº”æŽ¥è¿‘0ï¼Œæ ‡å‡†å·®æŽ¥è¿‘1
        self.assertTrue(np.allclose(result.mean(), 0, atol=1e-10))
        self.assertTrue(np.allclose(result.std(), 1, atol=1e-10))

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", True)
    def test_fit_transform_robust_with_sklearn(self):
        """æµ‹è¯•æœ‰sklearnæ—¶çš„é²æ£’å½’ä¸€åŒ–"""
        normalizer = DataNormalizer(method="robust")
        result = normalizer.fit_transform(self.df_data)

        self.assertIsInstance(result, pd.DataFrame)

    def test_fit_transform_robust_without_sklearn(self):
        """æµ‹è¯•æ²¡æœ‰sklearnæ—¶çš„é²æ£’å½’ä¸€åŒ–"""
        normalizer = DataNormalizer(method="robust")
        with self.assertRaises(ValueError):
            # ç®€åŒ–å®žçŽ°ä¸æ”¯æŒrobustæ–¹æ³•
            normalizer.fit_transform(self.df_data)

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", True)
    def test_transform_without_fit_with_sklearn(self):
        """æµ‹è¯•æœ‰sklearnæ—¶åœ¨æœªè®­ç»ƒæ—¶è°ƒç”¨transform"""
        normalizer = DataNormalizer()
        with self.assertRaises(ValueError):
            normalizer.transform(self.df_data)

    def test_transform_after_fit(self):
        """æµ‹è¯•è®­ç»ƒåŽçš„transform"""
        normalizer = DataNormalizer(method="minmax")
        normalizer.fit_transform(self.df_data)

        new_data = pd.DataFrame({"price": [150], "volume": [1500]})
        result = normalizer.transform(new_data)

        self.assertIsInstance(result, pd.DataFrame)
        self.assertEqual(len(result), 1)

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", True)
    def test_inverse_transform_with_sklearn(self):
        """æµ‹è¯•æœ‰sklearnæ—¶çš„åå‘è½¬æ¢"""
        normalizer = DataNormalizer(method="minmax")
        normalized = normalizer.fit_transform(self.df_data)
        recovered = normalizer.inverse_transform(normalized)

        # åŽŸå§‹æ•°æ®åº”è¯¥è¢«æ¢å¤
        pd.testing.assert_frame_equal(recovered, self.df_data, check_dtype=False)

    def test_inverse_transform_without_sklearn(self):
        """æµ‹è¯•æ²¡æœ‰sklearnæ—¶çš„åå‘è½¬æ¢"""
        normalizer = DataNormalizer()
        result = normalizer.inverse_transform(self.df_data)

        # ç®€åŒ–å®žçŽ°è¿”å›žåŽŸæ•°æ®
        pd.testing.assert_frame_equal(result, self.df_data)

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", False)
    def test_simple_normalize_minmax(self):
        """æµ‹è¯•ç®€åŒ–ç‰ˆMinMaxå½’ä¸€åŒ–"""
        normalizer = DataNormalizer(method="minmax")
        result = normalizer._simple_normalize(self.series_data)

        self.assertTrue((result >= 0).all())
        self.assertTrue((result <= 1).all())

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", False)
    def test_simple_normalize_standard(self):
        """æµ‹è¯•ç®€åŒ–ç‰ˆæ ‡å‡†åŒ–"""
        normalizer = DataNormalizer(method="standard")
        result = normalizer._simple_normalize(self.series_data)

        self.assertTrue(np.allclose(result.mean(), 0))
        self.assertTrue(np.allclose(result.std(), 1))

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", False)
    def test_simple_normalize_invalid_method(self):
        """æµ‹è¯•ç®€åŒ–ç‰ˆæ— æ•ˆæ–¹æ³•"""
        normalizer = DataNormalizer(method="robust")
        with self.assertRaises(ValueError):
            normalizer._simple_normalize(self.series_data)

    @patch("src.data.transformers.data_transformers.HAS_SKLEARN", False)
    def test_fit_transform_without_sklearn(self):
        """æµ‹è¯•æ²¡æœ‰sklearnæ—¶çš„fit_transform"""
        normalizer = DataNormalizer(method="minmax")
        result = normalizer.fit_transform(self.series_data)

        self.assertTrue((result >= 0).all())
        self.assertTrue((result <= 1).all())


class TestTimeSeriesProcessorComprehensive(unittest.TestCase):
    """å…¨é¢æµ‹è¯•TimeSeriesProcessorç±»"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        self.data_array = np.random.rand(100)

        self.df_data = pd.DataFrame(
            {
                "price": np.random.rand(50) * 100,
                "volume": np.random.rand(50) * 1000,
            },
            index=pd.date_range("2023-01-01", periods=50),
        )

    def test_create_sequences_basic(self):
        """æµ‹è¯•åŸºæœ¬åºåˆ—åˆ›å»º"""
        X, y = TimeSeriesProcessor.create_sequences(self.data_array, seq_length=10)

        self.assertEqual(X.shape[1], 10)
        self.assertEqual(y.shape[1], 1)
        self.assertEqual(len(X), len(y))
        self.assertEqual(len(X), len(self.data_array) - 10)

    def test_create_sequences_custom_pred_length(self):
        """æµ‹è¯•è‡ªå®šä¹‰é¢„æµ‹é•¿åº¦"""
        X, y = TimeSeriesProcessor.create_sequences(self.data_array, seq_length=5, pred_length=3)

        self.assertEqual(X.shape[1], 5)
        self.assertEqual(y.shape[1], 3)
        self.assertEqual(len(X), len(self.data_array) - 5 - 3 + 1)

    def test_create_sequences_custom_step(self):
        """æµ‹è¯•è‡ªå®šä¹‰æ­¥é•¿"""
        X, y = TimeSeriesProcessor.create_sequences(self.data_array, seq_length=5, step=2)

        # æ ¹æ®å®žé™…å®žçŽ°è°ƒæ•´æœŸæœ›å€¼
        expected_length = len([i for i in range(0, len(self.data_array) - 5 - 1 + 1, 2)])
        self.assertEqual(len(X), expected_length)

    def test_create_sequences_edge_case(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        small_data = np.array([1, 2, 3])
        X, y = TimeSeriesProcessor.create_sequences(small_data, seq_length=2)

        self.assertEqual(len(X), 1)
        self.assertEqual(len(y), 1)

    def test_create_lagged_features(self):
        """æµ‹è¯•æ»žåŽç‰¹å¾åˆ›å»º"""
        result = TimeSeriesProcessor.create_lagged_features(self.df_data, ["price"], [1, 2, 3])

        self.assertIn("price_lag_1", result.columns)
        self.assertIn("price_lag_2", result.columns)
        self.assertIn("price_lag_3", result.columns)
        self.assertEqual(len(result), len(self.df_data))

    def test_create_lagged_features_multiple_columns(self):
        """æµ‹è¯•å¤šåˆ—æ»žåŽç‰¹å¾"""
        result = TimeSeriesProcessor.create_lagged_features(
            self.df_data, ["price", "volume"], [1, 2]
        )

        expected_cols = ["price_lag_1", "price_lag_2", "volume_lag_1", "volume_lag_2"]
        for col in expected_cols:
            self.assertIn(col, result.columns)

    def test_create_rolling_features(self):
        """æµ‹è¯•æ»šåŠ¨ç‰¹å¾åˆ›å»º"""
        result = TimeSeriesProcessor.create_rolling_features(self.df_data, ["price"], [5, 10])

        # æ ¹æ®å®žé™…å®žçŽ°è°ƒæ•´åˆ—åæ ¼å¼
        expected_cols = [
            "price_rolling_mean_5",
            "price_rolling_std_5",
            "price_rolling_min_5",
            "price_rolling_max_5",
            "price_rolling_mean_10",
            "price_rolling_std_10",
            "price_rolling_min_10",
            "price_rolling_max_10",
        ]
        for col in expected_cols:
            self.assertIn(col, result.columns)

    def test_create_rolling_features_custom_functions(self):
        """æµ‹è¯•è‡ªå®šä¹‰æ»šåŠ¨å‡½æ•°"""
        result = TimeSeriesProcessor.create_rolling_features(
            self.df_data, ["price"], [5], ["mean", "sum"]
        )

        self.assertIn("price_rolling_mean_5", result.columns)
        self.assertIn("price_rolling_sum_5", result.columns)
        self.assertNotIn("price_rolling_std_5", result.columns)

    def test_resample_data_basic(self):
        """æµ‹è¯•æ•°æ®é‡é‡‡æ ·"""
        result = TimeSeriesProcessor.resample_data(self.df_data, "5D")

        self.assertLess(len(result), len(self.df_data))
        # åˆ—çš„é¡ºåºå¯èƒ½ä¸åŒï¼Œåªæ£€æŸ¥åˆ—é›†åˆ
        self.assertEqual(set(result.columns), set(self.df_data.columns))

    def test_resample_data_custom_agg(self):
        """æµ‹è¯•è‡ªå®šä¹‰èšåˆæ–¹æ³•"""
        agg_methods = {"price": "mean", "volume": "sum"}
        result = TimeSeriesProcessor.resample_data(self.df_data, "7D", agg_methods)

        self.assertIsInstance(result, pd.DataFrame)
        self.assertLess(len(result), len(self.df_data))


class TestDataSplitterComprehensive(unittest.TestCase):
    """å…¨é¢æµ‹è¯•DataSplitterç±»"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        self.df_data = pd.DataFrame(
            {
                "feature1": np.random.rand(100),
                "feature2": np.random.rand(100),
                "target": np.random.rand(100),
            }
        )

    def test_train_test_split_basic(self):
        """æµ‹è¯•åŸºæœ¬è®­ç»ƒæµ‹è¯•åˆ†å‰²"""
        train, test = DataSplitter.train_test_split(self.df_data, test_size=0.2)

        self.assertEqual(len(train) + len(test), len(self.df_data))
        self.assertAlmostEqual(len(test) / len(self.df_data), 0.2, places=1)

    def test_train_test_split_with_shuffle(self):
        """æµ‹è¯•å¸¦æ´—ç‰Œçš„åˆ†å‰²"""
        train1, test1 = DataSplitter.train_test_split(
            self.df_data, test_size=0.2, shuffle=True, random_state=42
        )
        train2, test2 = DataSplitter.train_test_split(
            self.df_data, test_size=0.2, shuffle=True, random_state=42
        )

        # ç›¸åŒéšæœºç§å­åº”è¯¥äº§ç”Ÿç›¸åŒç»“æžœ
        pd.testing.assert_frame_equal(train1, train2)
        pd.testing.assert_frame_equal(test1, test2)

    def test_train_test_split_without_shuffle(self):
        """æµ‹è¯•ä¸æ´—ç‰Œçš„åˆ†å‰²"""
        train, test = DataSplitter.train_test_split(self.df_data, test_size=0.2, shuffle=False)

        # è®­ç»ƒé›†åº”è¯¥æ˜¯å‰80è¡Œï¼Œæµ‹è¯•é›†æ˜¯åŽ20è¡Œ
        expected_train_size = int(0.8 * len(self.df_data))
        self.assertEqual(len(train), expected_train_size)
        self.assertEqual(train.index[0], 0)
        self.assertEqual(test.index[0], expected_train_size)

    def test_train_val_test_split(self):
        """æµ‹è¯•ä¸‰åˆ†å‰²"""
        train, val, test = DataSplitter.train_val_test_split(
            self.df_data, train_size=0.7, val_size=0.15, test_size=0.15
        )

        total_size = len(train) + len(val) + len(test)
        self.assertEqual(total_size, len(self.df_data))

        self.assertAlmostEqual(len(train) / len(self.df_data), 0.7, places=1)
        self.assertAlmostEqual(len(val) / len(self.df_data), 0.15, places=1)
        self.assertAlmostEqual(len(test) / len(self.df_data), 0.15, places=1)

    def test_train_val_test_split_size_validation(self):
        """æµ‹è¯•ä¸‰åˆ†å‰²å¤§å°éªŒè¯"""
        with self.assertRaises(ValueError):
            DataSplitter.train_val_test_split(
                self.df_data, train_size=0.5, val_size=0.3, test_size=0.3
            )

    def test_time_series_split(self):
        """æµ‹è¯•æ—¶é—´åºåˆ—åˆ†å‰²"""
        splits = DataSplitter.time_series_split(self.df_data, n_splits=3)

        self.assertEqual(len(splits), 3)

        # æ£€æŸ¥æ¯ä¸ªåˆ†å‰²
        for train, test in splits:
            self.assertIsInstance(train, pd.DataFrame)
            self.assertIsInstance(test, pd.DataFrame)
            self.assertGreater(len(train), 0)
            self.assertGreater(len(test), 0)

    def test_time_series_split_custom_test_size(self):
        """æµ‹è¯•è‡ªå®šä¹‰æµ‹è¯•å¤§å°çš„æ—¶é—´åºåˆ—åˆ†å‰²"""
        splits = DataSplitter.time_series_split(self.df_data, n_splits=3, test_size=10)

        for train, test in splits:
            self.assertEqual(len(test), 10)


class TestMissingValueHandlerComprehensive(unittest.TestCase):
    """å…¨é¢æµ‹è¯•MissingValueHandlerç±»"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        self.df_data = pd.DataFrame(
            {
                "price": [100, np.nan, 300, np.nan, 500],
                "volume": [1000, 2000, np.nan, 4000, np.nan],
                "returns": [0.01, 0.02, 0.03, np.nan, 0.05],
            }
        )

    def test_fill_missing_values_forward(self):
        """æµ‹è¯•å‰å‘å¡«å……"""
        result = MissingValueHandler.fill_missing_values(self.df_data, method="forward")

        # æ£€æŸ¥æ²¡æœ‰ç¼ºå¤±å€¼
        self.assertEqual(result.isnull().sum().sum(), 0)

        # æ£€æŸ¥å‰å‘å¡«å……é€»è¾‘
        self.assertEqual(result.iloc[1]["price"], 100)  # å‰å‘å¡«å……

    def test_fill_missing_values_backward(self):
        """æµ‹è¯•åŽå‘å¡«å……"""
        result = MissingValueHandler.fill_missing_values(self.df_data, method="backward")

        # åŽå‘å¡«å……å¯èƒ½ä»æœ‰ç¼ºå¤±å€¼ï¼ˆç¬¬ä¸€ä¸ªå€¼ï¼‰
        self.assertLessEqual(result.isnull().sum().sum(), self.df_data.isnull().sum().sum())

    def test_fill_missing_values_mean(self):
        """æµ‹è¯•å‡å€¼å¡«å……"""
        result = MissingValueHandler.fill_missing_values(self.df_data, method="mean")

        self.assertEqual(result.isnull().sum().sum(), 0)

        # å‡å€¼å¡«å……åº”è¯¥ç”¨åˆ—çš„å‡å€¼
        original_mean = self.df_data["price"].mean()
        self.assertEqual(result.iloc[1]["price"], original_mean)

    def test_fill_missing_values_median(self):
        """æµ‹è¯•ä¸­ä½æ•°å¡«å……"""
        result = MissingValueHandler.fill_missing_values(self.df_data, method="median")

        self.assertEqual(result.isnull().sum().sum(), 0)

    def test_fill_missing_values_unsupported_mode(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„ä¼—æ•°å¡«å……"""
        with self.assertRaises(ValueError):
            MissingValueHandler.fill_missing_values(self.df_data, method="mode")

    def test_fill_missing_values_specific_columns(self):
        """æµ‹è¯•æŒ‡å®šåˆ—å¡«å……"""
        result = MissingValueHandler.fill_missing_values(
            self.df_data, method="mean", columns=["price"]
        )

        # åªæœ‰priceåˆ—è¢«å¡«å……
        self.assertEqual(result["price"].isnull().sum(), 0)
        self.assertGreater(result["volume"].isnull().sum(), 0)

    def test_fill_missing_values_invalid_method(self):
        """æµ‹è¯•æ— æ•ˆå¡«å……æ–¹æ³•"""
        with self.assertRaises(ValueError):
            MissingValueHandler.fill_missing_values(self.df_data, method="invalid")

    def test_interpolate_missing_values_linear(self):
        """æµ‹è¯•çº¿æ€§æ’å€¼"""
        result = MissingValueHandler.interpolate_missing_values(self.df_data, method="linear")

        self.assertLessEqual(result.isnull().sum().sum(), self.df_data.isnull().sum().sum())

    def test_interpolate_missing_values_specific_columns(self):
        """æµ‹è¯•æŒ‡å®šåˆ—æ’å€¼"""
        result = MissingValueHandler.interpolate_missing_values(
            self.df_data, method="linear", columns=["price"]
        )

        # åªæœ‰priceåˆ—è¢«æ’å€¼
        self.assertEqual(result["price"].isnull().sum(), 0)

    def test_get_target_columns_all(self):
        """æµ‹è¯•èŽ·å–æ‰€æœ‰ç›®æ ‡åˆ—"""
        columns = MissingValueHandler._get_target_columns(self.df_data, None)
        self.assertEqual(set(columns), set(self.df_data.columns))

    def test_get_target_columns_specific(self):
        """æµ‹è¯•èŽ·å–æŒ‡å®šç›®æ ‡åˆ—"""
        columns = MissingValueHandler._get_target_columns(self.df_data, ["price", "volume"])
        self.assertEqual(set(columns), {"price", "volume"})

    def test_fill_column_missing_values_forward(self):
        """æµ‹è¯•å•åˆ—å‰å‘å¡«å……"""
        result = MissingValueHandler._fill_column_missing_values(
            self.df_data.copy(), "price", "forward"
        )

        self.assertEqual(result["price"].isnull().sum(), 0)

    def test_fill_column_missing_values_mean(self):
        """æµ‹è¯•å•åˆ—å‡å€¼å¡«å……"""
        result = MissingValueHandler._fill_column_missing_values(
            self.df_data.copy(), "price", "mean"
        )

        self.assertEqual(result["price"].isnull().sum(), 0)


class TestConvenienceFunctions(unittest.TestCase):
    """æµ‹è¯•ä¾¿æ·å‡½æ•°"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        self.data = pd.Series([10, 20, 30, 40, 50])
        self.df_data = pd.DataFrame({"col1": [1, 2, 3, 4, 5]})

    def test_normalize_data_function(self):
        """æµ‹è¯•normalize_dataä¾¿æ·å‡½æ•°"""
        result = normalize_data(self.data)

        self.assertTrue((result >= 0).all())
        self.assertTrue((result <= 1).all())

    def test_normalize_data_custom_params(self):
        """æµ‹è¯•è‡ªå®šä¹‰å‚æ•°çš„å½’ä¸€åŒ–"""
        result = normalize_data(self.data, method="standard")

        self.assertTrue(np.allclose(result.mean(), 0))
        self.assertTrue(np.allclose(result.std(), 1))

    def test_create_train_test_split_function(self):
        """æµ‹è¯•create_train_test_splitä¾¿æ·å‡½æ•°"""
        train, test = create_train_test_split(self.df_data, test_size=0.2)

        self.assertEqual(len(train) + len(test), len(self.df_data))

    def test_create_sequences_function(self):
        """æµ‹è¯•create_sequencesä¾¿æ·å‡½æ•°"""
        data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
        X, y = create_sequences(data, seq_length=3)

        self.assertEqual(X.shape[1], 3)
        self.assertEqual(len(X), len(data) - 3)


if __name__ == "__main__":
    unittest.main()
