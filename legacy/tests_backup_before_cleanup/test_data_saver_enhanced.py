#!/usr/bin/env python3
"""
ğŸ§ª æ•°æ®ä¿å­˜å™¨å¢å¼ºæµ‹è¯• (Data Saver Enhanced Tests)

æå‡data_saver.pyæ¨¡å—æµ‹è¯•è¦†ç›–ç‡çš„å…¨é¢æµ‹è¯•å¥—ä»¶
å½“å‰è¦†ç›–ç‡: 30% -> ç›®æ ‡: 75%+
"""

import json
import os
import shutil
import tempfile
import unittest
from pathlib import Path
from unittest.mock import patch

import pandas as pd

from src.data.validators.data_saver import DataSaver


class TestDataSaverInitialization(unittest.TestCase):
    """æµ‹è¯•DataSaveråˆå§‹åŒ–"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

    def test_init_with_default_dir(self):
        """æµ‹è¯•é»˜è®¤ç›®å½•åˆå§‹åŒ–"""
        saver = DataSaver()
        self.assertEqual(saver.base_output_dir, Path("output"))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_string(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•å­—ç¬¦ä¸²åˆå§‹åŒ–"""
        saver = DataSaver(self.temp_dir)
        self.assertEqual(saver.base_output_dir, Path(self.temp_dir))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_path(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•Pathå¯¹è±¡åˆå§‹åŒ–"""
        custom_path = Path(self.temp_dir) / "custom"
        saver = DataSaver(custom_path)
        self.assertEqual(saver.base_output_dir, custom_path)
        self.assertTrue(saver.base_output_dir.exists())


class TestDataSaverBasicSaving(unittest.TestCase):
    """æµ‹è¯•DataSaveråŸºæœ¬ä¿å­˜åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame(
            {
                "price": [100.0, 200.0, 300.0],
                "volume": [1000, 2000, 3000],
                "timestamp": pd.date_range("2023-01-01", periods=3),
            }
        )

    def test_save_data_csv_success(self):
        """æµ‹è¯•CSVæ ¼å¼ä¿å­˜æˆåŠŸ"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.csv"
        self.assertTrue(file_path.exists())

        # éªŒè¯æ•°æ®å†…å®¹
        loaded_df = pd.read_csv(file_path, index_col=0)
        self.assertEqual(len(loaded_df), 3)

    def test_save_data_with_subdirectory(self):
        """æµ‹è¯•åœ¨å­ç›®å½•ä¸­ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", "subdir")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "subdir" / "test.csv"
        self.assertTrue(file_path.exists())

    def test_save_data_with_timestamp(self):
        """æµ‹è¯•å¸¦æ—¶é—´æˆ³çš„ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", add_timestamp=True)
        self.assertTrue(result)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        files = list(self.saver.base_output_dir.glob("test_*.csv"))
        self.assertEqual(len(files), 1)

    def test_save_data_without_metadata(self):
        """æµ‹è¯•ä¸ä¿å­˜å…ƒæ•°æ®"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", save_metadata=False)
        self.assertTrue(result)

        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨
        metadata_path = self.saver.base_output_dir / "test.csv.metadata.json"
        self.assertFalse(metadata_path.exists())

    def test_save_data_parquet_format(self):
        """æµ‹è¯•Parquetæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.parquet", "parquet")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.parquet"
        self.assertTrue(file_path.exists())

    def test_save_data_pickle_format(self):
        """æµ‹è¯•Pickleæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.pkl", "pickle")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.pkl"
        self.assertTrue(file_path.exists())

    def test_save_data_json_format(self):
        """æµ‹è¯•JSONæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.json", "json")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.json"
        self.assertTrue(file_path.exists())

    def test_save_data_excel_format(self):
        """æµ‹è¯•Excelæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.xlsx", "excel")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.xlsx"
        self.assertTrue(file_path.exists())

    def test_save_data_unsupported_format(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼"""
        result = self.saver.save_data(self.test_df, "test.xyz", "xyz")
        self.assertFalse(result)

    @patch("builtins.print")
    def test_save_data_exception_handling(self, mock_print):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # åˆ›å»ºæ— æ•ˆçš„DataFrameä»¥è§¦å‘å¼‚å¸¸
        invalid_df = None
        result = self.saver.save_data(invalid_df, "test.csv", "csv")
        self.assertFalse(result)

        # éªŒè¯é”™è¯¯æ¶ˆæ¯è¢«æ‰“å°
        mock_print.assert_called()


class TestDataSaverFormatHandling(unittest.TestCase):
    """æµ‹è¯•DataSaveræ ¼å¼å¤„ç†"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_is_supported_format_valid(self):
        """æµ‹è¯•æœ‰æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertTrue(self.saver._is_supported_format("csv"))
        self.assertTrue(self.saver._is_supported_format("parquet"))
        self.assertTrue(self.saver._is_supported_format("pickle"))
        self.assertTrue(self.saver._is_supported_format("json"))
        self.assertTrue(self.saver._is_supported_format("excel"))
        self.assertTrue(self.saver._is_supported_format("xlsx"))
        self.assertTrue(self.saver._is_supported_format("hdf5"))

    def test_is_supported_format_invalid(self):
        """æµ‹è¯•æ— æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertFalse(self.saver._is_supported_format("xyz"))
        self.assertFalse(self.saver._is_supported_format(""))

    def test_execute_save_operation_csv(self):
        """æµ‹è¯•CSVä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.csv"
        self.saver._execute_save_operation(self.test_df, file_path, "csv")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_hdf5(self):
        """æµ‹è¯•HDF5ä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.h5"
        self.saver._execute_save_operation(self.test_df, file_path, "hdf5", key="data")
        self.assertTrue(file_path.exists())

    @patch("builtins.print")
    def test_save_by_format_exception(self, mock_print):
        """æµ‹è¯•æ ¼å¼ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path(self.temp_dir) / "test.csv"

        # ä½¿ç”¨æ— æ•ˆçš„DataFrameæ¥è§¦å‘å¼‚å¸¸
        with patch.object(self.test_df, "to_csv", side_effect=Exception("Test error")):
            result = self.saver._save_by_format(self.test_df, file_path, "csv")
            self.assertFalse(result)
            mock_print.assert_called()


class TestDataSaverBackupFunctionality(unittest.TestCase):
    """æµ‹è¯•DataSaverå¤‡ä»½åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_create_backup_success(self):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºå¤‡ä»½"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        file_path = Path(self.temp_dir) / "test.csv"
        self.test_df.to_csv(file_path)

        # åˆ›å»ºå¤‡ä»½
        self.saver._create_backup(file_path)

        # æ£€æŸ¥å¤‡ä»½ç›®å½•å’Œæ–‡ä»¶
        backup_dir = file_path.parent / "backups"
        self.assertTrue(backup_dir.exists())

        backup_files = list(backup_dir.glob("test_*.csv"))
        self.assertEqual(len(backup_files), 1)

    @patch("builtins.print")
    def test_create_backup_exception(self, mock_print):
        """æµ‹è¯•å¤‡ä»½åˆ›å»ºå¼‚å¸¸"""
        # ä½¿ç”¨ä¸å­˜åœ¨çš„æ–‡ä»¶
        non_existent_file = Path(self.temp_dir) / "non_existent.csv"
        self.saver._create_backup(non_existent_file)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()

    def test_save_data_with_backup(self):
        """æµ‹è¯•å¸¦å¤‡ä»½çš„ä¿å­˜"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # ä¿®æ”¹æ•°æ®å¹¶ä¿å­˜ï¼Œå¯ç”¨å¤‡ä»½
        modified_df = pd.DataFrame({"col1": [4, 5, 6]})
        result = self.saver.save_data(modified_df, "test.csv", "csv", create_backup=True)
        self.assertTrue(result)

        # æ£€æŸ¥å¤‡ä»½æ˜¯å¦åˆ›å»º
        backup_dir = self.saver.base_output_dir / "backups"
        self.assertTrue(backup_dir.exists())


class TestDataSaverMetadata(unittest.TestCase):
    """æµ‹è¯•DataSaverå…ƒæ•°æ®åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºåŒ…å«ä¸åŒæ•°æ®ç±»å‹çš„æµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame(
            {
                "int_col": [1, 2, 3],
                "float_col": [1.1, 2.2, 3.3],
                "str_col": ["a", "b", "c"],
                "null_col": [1, None, 3],
            }
        )

    def test_save_metadata_success(self):
        """æµ‹è¯•æˆåŠŸä¿å­˜å…ƒæ•°æ®"""
        file_path = self.saver.base_output_dir / "test.csv"
        self.saver._save_metadata(self.test_df, file_path)

        metadata_path = file_path.with_suffix(".csv.metadata.json")
        self.assertTrue(metadata_path.exists())

        # éªŒè¯å…ƒæ•°æ®å†…å®¹
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        self.assertIn("filename", metadata)
        self.assertIn("created_at", metadata)
        self.assertIn("shape", metadata)
        self.assertIn("columns", metadata)
        self.assertIn("dtypes", metadata)
        self.assertIn("memory_usage_mb", metadata)
        self.assertIn("null_counts", metadata)
        self.assertIn("numeric_summary", metadata)

        self.assertEqual(metadata["shape"], [4, 4])  # 4 rows, 4 columns
        self.assertEqual(len(metadata["columns"]), 4)

    @patch("builtins.print")
    def test_save_metadata_exception(self, mock_print):
        """æµ‹è¯•å…ƒæ•°æ®ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path("/invalid/path/test.csv")
        self.saver._save_metadata(self.test_df, file_path)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()


class TestDataSaverAdvancedFeatures(unittest.TestCase):
    """æµ‹è¯•DataSaveré«˜çº§åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_save_multiple_formats(self):
        """æµ‹è¯•å¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "json", "pickle"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertEqual(len(results), 3)
        for fmt in formats:
            self.assertTrue(results[fmt])

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "test.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "test.json").exists())
        self.assertTrue((self.saver.base_output_dir / "test.pickle").exists())

    def test_save_multiple_formats_with_excel(self):
        """æµ‹è¯•åŒ…å«Excelçš„å¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "excel"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertTrue(results["excel"])
        self.assertTrue((self.saver.base_output_dir / "test.xlsx").exists())

    def test_batch_save(self):
        """æµ‹è¯•æ‰¹é‡ä¿å­˜"""
        dataframes = {
            "df1": pd.DataFrame({"a": [1, 2]}),
            "df2": pd.DataFrame({"b": [3, 4]}),
            "df3.csv": pd.DataFrame({"c": [5, 6]}),  # å·²æœ‰æ‰©å±•å
        }

        results = self.saver.batch_save(dataframes, "csv")

        self.assertEqual(len(results), 3)
        self.assertTrue(all(results.values()))

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "df1.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df2.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df3.csv").exists())

    def test_get_saved_files_info_empty_directory(self):
        """æµ‹è¯•ç©ºç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info()
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_non_existent_directory(self):
        """æµ‹è¯•ä¸å­˜åœ¨ç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info("non_existent")
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_with_files(self):
        """æµ‹è¯•æœ‰æ–‡ä»¶æ—¶çš„ä¿¡æ¯è·å–"""
        # åˆ›å»ºä¸€äº›æ–‡ä»¶
        self.saver.save_data(self.test_df, "test1.csv", "csv")
        self.saver.save_data(self.test_df, "test2.json", "json")

        info = self.saver.get_saved_files_info()
        self.assertGreaterEqual(len(info), 2)

        # æ£€æŸ¥ä¿¡æ¯å­—æ®µ
        for file_info in info:
            self.assertIn("filename", file_info)
            self.assertIn("path", file_info)
            self.assertIn("size_mb", file_info)
            self.assertIn("created", file_info)
            self.assertIn("modified", file_info)
            self.assertIn("extension", file_info)

    @patch("builtins.print")
    def test_get_saved_files_info_exception(self, mock_print):
        """æµ‹è¯•æ–‡ä»¶ä¿¡æ¯è·å–å¼‚å¸¸å¤„ç†"""
        # åˆ›å»ºæ–‡ä»¶ç„¶åä¿®æ”¹å…¶æƒé™æˆ–è·¯å¾„ä»¥è§¦å‘å¼‚å¸¸
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # Mock Path.stat to raise exception
        with patch("pathlib.Path.stat", side_effect=Exception("Permission denied")):
            info = self.saver.get_saved_files_info()
            # åº”è¯¥è¿”å›ç©ºåˆ—è¡¨æˆ–è·³è¿‡å¼‚å¸¸æ–‡ä»¶
            mock_print.assert_called()


class TestDataSaverCleanup(unittest.TestCase):
    """æµ‹è¯•DataSaveræ¸…ç†åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_cleanup_old_files_no_directory(self):
        """æµ‹è¯•æ¸…ç†ä¸å­˜åœ¨çš„ç›®å½•"""
        count = self.saver.cleanup_old_files("non_existent")
        self.assertEqual(count, 0)

    def test_cleanup_old_files_no_old_files(self):
        """æµ‹è¯•æ¸…ç†æ— æ—§æ–‡ä»¶çš„æƒ…å†µ"""
        # åˆ›å»ºæ–°æ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # å°è¯•æ¸…ç†1å¤©å‰çš„æ–‡ä»¶ï¼ˆåº”è¯¥æ²¡æœ‰ï¼‰
        count = self.saver.cleanup_old_files(days_old=1)
        self.assertEqual(count, 0)

    @patch("time.time")
    def test_cleanup_old_files_with_old_files(self, mock_time):
        """æµ‹è¯•æ¸…ç†æ—§æ–‡ä»¶"""
        # è®¾ç½®å½“å‰æ—¶é—´
        current_time = 1000000
        mock_time.return_value = current_time

        # åˆ›å»ºæ–‡ä»¶
        file_path = self.saver.base_output_dir / "old_file.csv"
        self.test_df.to_csv(file_path)

        # ä¿®æ”¹æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ä¸º30å¤©å‰
        old_time = current_time - (31 * 24 * 60 * 60)  # 31å¤©å‰
        os.utime(file_path, (old_time, old_time))

        # æ¸…ç†30å¤©å‰çš„æ–‡ä»¶
        count = self.saver.cleanup_old_files(days_old=30)
        self.assertEqual(count, 1)
        self.assertFalse(file_path.exists())

    def test_get_search_directory(self):
        """æµ‹è¯•è·å–æœç´¢ç›®å½•"""
        # æ— å­ç›®å½•
        search_dir = self.saver._get_search_directory(None)
        self.assertEqual(search_dir, self.saver.base_output_dir)

        # æœ‰å­ç›®å½•
        search_dir = self.saver._get_search_directory("subdir")
        self.assertEqual(search_dir, self.saver.base_output_dir / "subdir")

    def test_calculate_cutoff_time(self):
        """æµ‹è¯•è®¡ç®—æˆªæ­¢æ—¶é—´"""
        with patch("time.time", return_value=1000000):
            cutoff = self.saver._calculate_cutoff_time(30)
            expected = 1000000 - (30 * 24 * 60 * 60)
            self.assertEqual(cutoff, expected)

    def test_delete_file_and_metadata(self):
        """æµ‹è¯•åˆ é™¤æ–‡ä»¶å’Œå…ƒæ•°æ®"""
        # åˆ›å»ºæ–‡ä»¶å’Œå…ƒæ•°æ®
        file_path = self.saver.base_output_dir / "test.csv"
        metadata_path = file_path.with_suffix(".csv.metadata.json")

        self.test_df.to_csv(file_path)
        with open(metadata_path, "w") as f:
            json.dump({"test": "data"}, f)

        # åˆ é™¤
        self.saver._delete_file_and_metadata(file_path)

        # éªŒè¯éƒ½è¢«åˆ é™¤
        self.assertFalse(file_path.exists())
        self.assertFalse(metadata_path.exists())

    @patch("builtins.print")
    def test_cleanup_old_files_exception(self, mock_print):
        """æµ‹è¯•æ¸…ç†æ–‡ä»¶å¼‚å¸¸å¤„ç†"""
        # Mock glob to raise exception
        with patch("pathlib.Path.glob", side_effect=Exception("Permission denied")):
            count = self.saver.cleanup_old_files()
            self.assertEqual(count, 0)
            mock_print.assert_called()


if __name__ == "__main__":
    unittest.main()
