#!/usr/bin/env python3
"""
ğŸ§ª æ•°æ®ä¿å­˜å™¨å¢å¼ºæµ‹è¯• - ä¿®å¤ç‰ˆæœ¬ (Data Saver Enhanced Tests - Fixed)

è§£å†³JSONä¿å­˜å’Œå…ƒæ•°æ®é—®é¢˜ï¼Œç›®æ ‡ä»30%æå‡åˆ°75%+è¦†ç›–ç‡
"""

import json
import os
import shutil
import tempfile
import unittest
from pathlib import Path
from unittest.mock import patch

import pandas as pd

from src.data.validators.data_saver import DataSaver, ProcessedDataExporter, save_processed_data


class TestDataSaverInitialization(unittest.TestCase):
    """æµ‹è¯•DataSaveråˆå§‹åŒ–"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

    def test_init_with_default_dir(self):
        """æµ‹è¯•é»˜è®¤ç›®å½•åˆå§‹åŒ–"""
        saver = DataSaver()
        self.assertEqual(saver.base_output_dir, Path("output"))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_string(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•å­—ç¬¦ä¸²åˆå§‹åŒ–"""
        saver = DataSaver(self.temp_dir)
        self.assertEqual(saver.base_output_dir, Path(self.temp_dir))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_path(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•Pathå¯¹è±¡åˆå§‹åŒ–"""
        custom_path = Path(self.temp_dir) / "custom"
        saver = DataSaver(custom_path)
        self.assertEqual(saver.base_output_dir, custom_path)
        self.assertTrue(saver.base_output_dir.exists())


class TestDataSaverBasicSaving(unittest.TestCase):
    """æµ‹è¯•DataSaveråŸºæœ¬ä¿å­˜åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®ï¼ˆé¿å…å¤æ‚ç±»å‹ï¼‰
        self.test_df = pd.DataFrame(
            {
                "price": [100.0, 200.0, 300.0],
                "volume": [1000, 2000, 3000],
                "date": ["2023-01-01", "2023-01-02", "2023-01-03"],
            }
        )

    def test_save_data_csv_success(self):
        """æµ‹è¯•CSVæ ¼å¼ä¿å­˜æˆåŠŸ"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.csv"
        self.assertTrue(file_path.exists())

        # éªŒè¯æ•°æ®å†…å®¹
        loaded_df = pd.read_csv(file_path, index_col=0)
        self.assertEqual(len(loaded_df), 3)

    def test_save_data_with_subdirectory(self):
        """æµ‹è¯•åœ¨å­ç›®å½•ä¸­ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", "subdir")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "subdir" / "test.csv"
        self.assertTrue(file_path.exists())

    def test_save_data_with_timestamp(self):
        """æµ‹è¯•å¸¦æ—¶é—´æˆ³çš„ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", add_timestamp=True)
        self.assertTrue(result)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        files = list(self.saver.base_output_dir.glob("test_*.csv"))
        self.assertEqual(len(files), 1)

    def test_save_data_without_metadata(self):
        """æµ‹è¯•ä¸ä¿å­˜å…ƒæ•°æ®"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", save_metadata=False)
        self.assertTrue(result)

        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨
        metadata_path = self.saver.base_output_dir / "test.csv.metadata.json"
        self.assertFalse(metadata_path.exists())

    def test_save_data_parquet_format(self):
        """æµ‹è¯•Parquetæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.parquet", "parquet")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.parquet"
        self.assertTrue(file_path.exists())

    def test_save_data_pickle_format(self):
        """æµ‹è¯•Pickleæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.pkl", "pickle")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.pkl"
        self.assertTrue(file_path.exists())

    def test_save_data_json_format(self):
        """æµ‹è¯•JSONæ ¼å¼ä¿å­˜ï¼ˆä½¿ç”¨ç®€å•æ•°æ®ï¼‰"""
        simple_df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
        result = self.saver.save_data(simple_df, "test.json", "json")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.json"
        self.assertTrue(file_path.exists())

    def test_save_data_excel_format(self):
        """æµ‹è¯•Excelæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.xlsx", "excel")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.xlsx"
        self.assertTrue(file_path.exists())

    def test_save_data_unsupported_format(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼"""
        result = self.saver.save_data(self.test_df, "test.xyz", "xyz")
        self.assertFalse(result)

    @patch("builtins.print")
    def test_save_data_exception_handling(self, mock_print):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # åˆ›å»ºæ— æ•ˆçš„DataFrameä»¥è§¦å‘å¼‚å¸¸
        invalid_df = None
        result = self.saver.save_data(invalid_df, "test.csv", "csv")
        self.assertFalse(result)

        # éªŒè¯é”™è¯¯æ¶ˆæ¯è¢«æ‰“å°
        mock_print.assert_called()


class TestDataSaverFormatHandling(unittest.TestCase):
    """æµ‹è¯•DataSaveræ ¼å¼å¤„ç†"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_is_supported_format_valid(self):
        """æµ‹è¯•æœ‰æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertTrue(self.saver._is_supported_format("csv"))
        self.assertTrue(self.saver._is_supported_format("parquet"))
        self.assertTrue(self.saver._is_supported_format("pickle"))
        self.assertTrue(self.saver._is_supported_format("json"))
        self.assertTrue(self.saver._is_supported_format("excel"))
        self.assertTrue(self.saver._is_supported_format("xlsx"))
        self.assertTrue(self.saver._is_supported_format("hdf5"))

    def test_is_supported_format_invalid(self):
        """æµ‹è¯•æ— æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertFalse(self.saver._is_supported_format("xyz"))
        self.assertFalse(self.saver._is_supported_format(""))

    def test_execute_save_operation_csv(self):
        """æµ‹è¯•CSVä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.csv"
        self.saver._execute_save_operation(self.test_df, file_path, "csv")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_hdf5(self):
        """æµ‹è¯•HDF5ä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.h5"
        self.saver._execute_save_operation(self.test_df, file_path, "hdf5", key="data")
        self.assertTrue(file_path.exists())

    @patch("builtins.print")
    def test_save_by_format_exception(self, mock_print):
        """æµ‹è¯•æ ¼å¼ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path(self.temp_dir) / "test.csv"

        # ä½¿ç”¨æ— æ•ˆçš„DataFrameæ¥è§¦å‘å¼‚å¸¸
        with patch.object(self.test_df, "to_csv", side_effect=Exception("Test error")):
            result = self.saver._save_by_format(self.test_df, file_path, "csv")
            self.assertFalse(result)
            mock_print.assert_called()


class TestDataSaverBackupFunctionality(unittest.TestCase):
    """æµ‹è¯•DataSaverå¤‡ä»½åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_create_backup_success(self):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºå¤‡ä»½"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        file_path = Path(self.temp_dir) / "test.csv"
        self.test_df.to_csv(file_path)

        # åˆ›å»ºå¤‡ä»½
        self.saver._create_backup(file_path)

        # æ£€æŸ¥å¤‡ä»½ç›®å½•å’Œæ–‡ä»¶
        backup_dir = file_path.parent / "backups"
        self.assertTrue(backup_dir.exists())

        backup_files = list(backup_dir.glob("test_*.csv"))
        self.assertEqual(len(backup_files), 1)

    @patch("builtins.print")
    def test_create_backup_exception(self, mock_print):
        """æµ‹è¯•å¤‡ä»½åˆ›å»ºå¼‚å¸¸"""
        # ä½¿ç”¨ä¸å­˜åœ¨çš„æ–‡ä»¶
        non_existent_file = Path(self.temp_dir) / "non_existent.csv"
        self.saver._create_backup(non_existent_file)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()

    def test_save_data_with_backup(self):
        """æµ‹è¯•å¸¦å¤‡ä»½çš„ä¿å­˜"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # ä¿®æ”¹æ•°æ®å¹¶ä¿å­˜ï¼Œå¯ç”¨å¤‡ä»½
        modified_df = pd.DataFrame({"col1": [4, 5, 6]})
        result = self.saver.save_data(modified_df, "test.csv", "csv", create_backup=True)
        self.assertTrue(result)

        # æ£€æŸ¥å¤‡ä»½æ˜¯å¦åˆ›å»º
        backup_dir = self.saver.base_output_dir / "backups"
        self.assertTrue(backup_dir.exists())


class TestDataSaverMetadata(unittest.TestCase):
    """æµ‹è¯•DataSaverå…ƒæ•°æ®åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºåŒ…å«æ˜ç¡®æ•°æ®ç±»å‹çš„æµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame(
            {
                "int_col": pd.Series([1, 2, 3], dtype="int64"),
                "float_col": pd.Series([1.1, 2.2, 3.3], dtype="float64"),
                "str_col": pd.Series(["a", "b", "c"], dtype="string"),
                "bool_col": pd.Series([True, False, True], dtype="bool"),
            }
        )

    def test_save_metadata_success(self):
        """æµ‹è¯•æˆåŠŸä¿å­˜å…ƒæ•°æ®"""
        file_path = self.saver.base_output_dir / "test.csv"
        self.saver._save_metadata(self.test_df, file_path)

        metadata_path = file_path.with_suffix(".csv.metadata.json")
        self.assertTrue(metadata_path.exists())

        # éªŒè¯å…ƒæ•°æ®å†…å®¹
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        self.assertIn("filename", metadata)
        self.assertIn("created_at", metadata)
        self.assertIn("shape", metadata)
        self.assertIn("columns", metadata)
        self.assertIn("dtypes", metadata)
        self.assertIn("memory_usage_mb", metadata)

        self.assertEqual(metadata["shape"], [4, 4])  # 4 rows, 4 columns
        self.assertEqual(len(metadata["columns"]), 4)

    @patch("builtins.print")
    def test_save_metadata_exception(self, mock_print):
        """æµ‹è¯•å…ƒæ•°æ®ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path("/invalid/path/test.csv")
        self.saver._save_metadata(self.test_df, file_path)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()


class TestDataSaverAdvancedFeatures(unittest.TestCase):
    """æµ‹è¯•DataSaveré«˜çº§åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_save_multiple_formats(self):
        """æµ‹è¯•å¤šæ ¼å¼ä¿å­˜ï¼ˆé¿å…JSONï¼‰"""
        formats = ["csv", "pickle", "parquet"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertEqual(len(results), 3)
        for fmt in formats:
            self.assertTrue(results[fmt])

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "test.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "test.pickle").exists())
        self.assertTrue((self.saver.base_output_dir / "test.parquet").exists())

    def test_save_multiple_formats_with_excel(self):
        """æµ‹è¯•åŒ…å«Excelçš„å¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "excel"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertTrue(results["excel"])
        self.assertTrue((self.saver.base_output_dir / "test.xlsx").exists())

    def test_batch_save(self):
        """æµ‹è¯•æ‰¹é‡ä¿å­˜"""
        dataframes = {
            "df1": pd.DataFrame({"a": [1, 2]}),
            "df2": pd.DataFrame({"b": [3, 4]}),
            "df3.csv": pd.DataFrame({"c": [5, 6]}),  # å·²æœ‰æ‰©å±•å
        }

        results = self.saver.batch_save(dataframes, "csv")

        self.assertEqual(len(results), 3)
        self.assertTrue(all(results.values()))

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "df1.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df2.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df3.csv").exists())

    def test_get_saved_files_info_empty_directory(self):
        """æµ‹è¯•ç©ºç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info()
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_non_existent_directory(self):
        """æµ‹è¯•ä¸å­˜åœ¨ç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info("non_existent")
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_with_files(self):
        """æµ‹è¯•æœ‰æ–‡ä»¶æ—¶çš„ä¿¡æ¯è·å–"""
        # åˆ›å»ºä¸€äº›æ–‡ä»¶ï¼ˆåªä¿å­˜åˆ°CSVï¼‰
        self.saver.save_data(self.test_df, "test1.csv", "csv")
        self.saver.save_data(self.test_df, "test2.csv", "csv")

        info = self.saver.get_saved_files_info()
        self.assertGreaterEqual(len(info), 2)

        # æ£€æŸ¥ä¿¡æ¯å­—æ®µ
        for file_info in info:
            self.assertIn("filename", file_info)
            self.assertIn("path", file_info)
            self.assertIn("size_mb", file_info)
            self.assertIn("created", file_info)
            self.assertIn("modified", file_info)
            self.assertIn("extension", file_info)

    @patch("builtins.print")
    def test_get_saved_files_info_file_stat_exception(self, mock_print):
        """æµ‹è¯•æ–‡ä»¶çŠ¶æ€è·å–å¼‚å¸¸å¤„ç†"""
        # åˆ›å»ºæ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # Mock file iteration to raise exception for specific files
        original_iterdir = Path.iterdir

        def mock_iterdir(self):
            for item in original_iterdir(self):
                if item.name == "test.csv":
                    # Mock stat method for this specific file
                    with patch.object(item, "stat", side_effect=Exception("Permission denied")):
                        yield item
                else:
                    yield item

        with patch.object(Path, "iterdir", mock_iterdir):
            info = self.saver.get_saved_files_info()
            # åº”è¯¥è·³è¿‡å¼‚å¸¸æ–‡ä»¶ä½†ä¸å½±å“å…¶ä»–æ–‡ä»¶
            mock_print.assert_called()


class TestDataSaverCleanup(unittest.TestCase):
    """æµ‹è¯•DataSaveræ¸…ç†åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_cleanup_old_files_no_directory(self):
        """æµ‹è¯•æ¸…ç†ä¸å­˜åœ¨çš„ç›®å½•"""
        count = self.saver.cleanup_old_files("non_existent")
        self.assertEqual(count, 0)

    def test_cleanup_old_files_no_old_files(self):
        """æµ‹è¯•æ¸…ç†æ— æ—§æ–‡ä»¶çš„æƒ…å†µ"""
        # åˆ›å»ºæ–°æ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # å°è¯•æ¸…ç†1å¤©å‰çš„æ–‡ä»¶ï¼ˆåº”è¯¥æ²¡æœ‰ï¼‰
        count = self.saver.cleanup_old_files(days_old=1)
        self.assertEqual(count, 0)

    @patch("time.time")
    def test_cleanup_old_files_with_old_files(self, mock_time):
        """æµ‹è¯•æ¸…ç†æ—§æ–‡ä»¶"""
        # è®¾ç½®å½“å‰æ—¶é—´
        current_time = 1000000
        mock_time.return_value = current_time

        # åˆ›å»ºæ–‡ä»¶
        file_path = self.saver.base_output_dir / "old_file.csv"
        self.test_df.to_csv(file_path)

        # ä¿®æ”¹æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ä¸º30å¤©å‰
        old_time = current_time - (31 * 24 * 60 * 60)  # 31å¤©å‰
        os.utime(file_path, (old_time, old_time))

        # æ¸…ç†30å¤©å‰çš„æ–‡ä»¶
        count = self.saver.cleanup_old_files(days_old=30)
        self.assertEqual(count, 1)
        self.assertFalse(file_path.exists())

    def test_get_search_directory(self):
        """æµ‹è¯•è·å–æœç´¢ç›®å½•"""
        # æ— å­ç›®å½•
        search_dir = self.saver._get_search_directory(None)
        self.assertEqual(search_dir, self.saver.base_output_dir)

        # æœ‰å­ç›®å½•
        search_dir = self.saver._get_search_directory("subdir")
        self.assertEqual(search_dir, self.saver.base_output_dir / "subdir")

    def test_calculate_cutoff_time(self):
        """æµ‹è¯•è®¡ç®—æˆªæ­¢æ—¶é—´"""
        with patch("time.time", return_value=1000000):
            cutoff = self.saver._calculate_cutoff_time(30)
            expected = 1000000 - (30 * 24 * 60 * 60)
            self.assertEqual(cutoff, expected)

    def test_delete_file_and_metadata(self):
        """æµ‹è¯•åˆ é™¤æ–‡ä»¶å’Œå…ƒæ•°æ®"""
        # åˆ›å»ºæ–‡ä»¶å’Œå…ƒæ•°æ®
        file_path = self.saver.base_output_dir / "test.csv"
        metadata_path = file_path.with_suffix(".csv.metadata.json")

        self.test_df.to_csv(file_path)
        with open(metadata_path, "w") as f:
            json.dump({"test": "data"}, f)

        # åˆ é™¤
        self.saver._delete_file_and_metadata(file_path)

        # éªŒè¯éƒ½è¢«åˆ é™¤
        self.assertFalse(file_path.exists())
        self.assertFalse(metadata_path.exists())

    @patch("builtins.print")
    def test_cleanup_old_files_exception(self, mock_print):
        """æµ‹è¯•æ¸…ç†æ–‡ä»¶å¼‚å¸¸å¤„ç†"""
        # Mock glob to raise exception
        with patch("pathlib.Path.glob", side_effect=Exception("Permission denied")):
            count = self.saver.cleanup_old_files()
            self.assertEqual(count, 0)
            mock_print.assert_called()


# ProcessedDataExporteræµ‹è¯•ç±»
class TestProcessedDataExporterInitialization(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporteråˆå§‹åŒ–"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

    def test_init_with_default_data_saver(self):
        """æµ‹è¯•é»˜è®¤DataSaveråˆå§‹åŒ–"""
        exporter = ProcessedDataExporter()
        self.assertIsInstance(exporter.data_saver, DataSaver)

    def test_init_with_custom_data_saver(self):
        """æµ‹è¯•è‡ªå®šä¹‰DataSaveråˆå§‹åŒ–"""
        custom_saver = DataSaver(self.temp_dir)
        exporter = ProcessedDataExporter(custom_saver)
        self.assertEqual(exporter.data_saver, custom_saver)


class TestProcessedDataExporterOHLCV(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporter OHLCVå¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºOHLCVæµ‹è¯•æ•°æ®
        self.ohlcv_df = pd.DataFrame(
            {
                "open": [100.0, 101.0, 102.0],
                "high": [105.0, 106.0, 107.0],
                "low": [99.0, 100.0, 101.0],
                "close": [104.0, 105.0, 106.0],
                "volume": [1000, 1100, 1200],
                "sma_20": [102.0, 103.0, 104.0],  # æŠ€æœ¯æŒ‡æ ‡
                "rsi": [50.0, 55.0, 60.0],
            }
        )

    def test_export_ohlcv_data_basic(self):
        """æµ‹è¯•åŸºæœ¬OHLCVæ•°æ®å¯¼å‡º"""
        result = self.exporter.export_ohlcv_data(
            self.ohlcv_df, "BTCUSDT", "1h", include_indicators=True
        )
        self.assertTrue(result)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        ohlcv_dir = self.data_saver.base_output_dir / "ohlcv_data"
        self.assertTrue(ohlcv_dir.exists())

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        files = list(ohlcv_dir.glob("BTCUSDT_1h_ohlcv_with_indicators_*.csv"))
        self.assertEqual(len(files), 1)

    def test_export_ohlcv_data_without_indicators(self):
        """æµ‹è¯•ä¸åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„OHLCVæ•°æ®å¯¼å‡º"""
        result = self.exporter.export_ohlcv_data(
            self.ohlcv_df, "ETHUSDT", "4h", include_indicators=False
        )
        self.assertTrue(result)

        # æ£€æŸ¥æ–‡ä»¶åæ ¼å¼
        ohlcv_dir = self.data_saver.base_output_dir / "ohlcv_data"
        files = list(ohlcv_dir.glob("ETHUSDT_4h_ohlcv_*.csv"))
        self.assertEqual(len(files), 1)

        # æ–‡ä»¶åä¸åº”åŒ…å«"with_indicators"
        filename = files[0].name
        self.assertNotIn("with_indicators", filename)


class TestProcessedDataExporterSignals(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporterä¿¡å·å¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºä¿¡å·æµ‹è¯•æ•°æ®
        self.signals_df = pd.DataFrame(
            {
                "signal": ["BUY", "HOLD", "SELL"],
                "strength": [0.8, 0.2, 0.9],
                "confidence": [0.9, 0.5, 0.85],
                "price": [100.0, 101.0, 99.0],
            }
        )

    def test_export_signals_data_success(self):
        """æµ‹è¯•æˆåŠŸå¯¼å‡ºä¿¡å·æ•°æ®"""
        result = self.exporter.export_signals_data(self.signals_df, "momentum_strategy")
        self.assertTrue(result)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        signals_dir = self.data_saver.base_output_dir / "signals"
        self.assertTrue(signals_dir.exists())

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        files = list(signals_dir.glob("momentum_strategy_signals_*.csv"))
        self.assertEqual(len(files), 1)


class TestProcessedDataExporterBacktest(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporterå›æµ‹ç»“æœå¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºå›æµ‹ç»“æœæµ‹è¯•æ•°æ®
        self.backtest_results = {
            "strategy_name": "test_strategy",
            "total_return": 0.15,
            "sharpe_ratio": 1.2,
            "max_drawdown": -0.05,
            "win_rate": 0.65,
            "total_trades": 100,
            "start_date": "2023-01-01",
            "end_date": "2023-12-31",
        }

    def test_export_backtest_results_success(self):
        """æµ‹è¯•æˆåŠŸå¯¼å‡ºå›æµ‹ç»“æœ"""
        result = self.exporter.export_backtest_results(self.backtest_results, "momentum_strategy")
        self.assertTrue(result)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        backtest_dir = self.data_saver.base_output_dir / "backtest_results"
        self.assertTrue(backtest_dir.exists())

        file_path = backtest_dir / "momentum_strategy_backtest_results.json"
        self.assertTrue(file_path.exists())

    def test_make_serializable_basic_types(self):
        """æµ‹è¯•åŸºæœ¬ç±»å‹åºåˆ—åŒ–"""
        # åŸºæœ¬ç±»å‹åº”è¯¥ä¿æŒä¸å˜
        self.assertEqual(self.exporter._make_serializable(42), 42)
        self.assertEqual(self.exporter._make_serializable(3.14), 3.14)
        self.assertEqual(self.exporter._make_serializable("hello"), "hello")
        self.assertEqual(self.exporter._make_serializable(True), True)
        self.assertEqual(self.exporter._make_serializable(None), None)

    def test_make_serializable_pandas_objects(self):
        """æµ‹è¯•Pandaså¯¹è±¡åºåˆ—åŒ–"""
        # Series
        series = pd.Series([1, 2, 3], name="test_series")
        result = self.exporter._make_serializable(series)
        self.assertIsInstance(result, dict)

        # DataFrame
        df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})
        result = self.exporter._make_serializable(df)
        self.assertIsInstance(result, dict)

        # Timestamp
        timestamp = pd.Timestamp("2023-01-01 12:00:00")
        result = self.exporter._make_serializable(timestamp)
        self.assertIsInstance(result, str)


class TestSaveProcessedDataFunction(unittest.TestCase):
    """æµ‹è¯•save_processed_dataä¾¿æ·å‡½æ•°"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame({"price": [100.0, 200.0, 300.0], "volume": [1000, 2000, 3000]})

    def test_save_processed_data_csv(self):
        """æµ‹è¯•CSVæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.csv")
        result = save_processed_data(self.test_df, output_path, "csv")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_pickle(self):
        """æµ‹è¯•Pickleæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.pkl")
        result = save_processed_data(self.test_df, output_path, "pickle")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_parquet(self):
        """æµ‹è¯•Parquetæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.parquet")
        result = save_processed_data(self.test_df, output_path, "parquet")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_unsupported_format(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼"""
        output_path = os.path.join(self.temp_dir, "test.xyz")
        result = save_processed_data(self.test_df, output_path, "xyz")

        self.assertFalse(result)

    @patch("builtins.print")
    def test_save_processed_data_exception(self, mock_print):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # ä½¿ç”¨æ— æ•ˆè·¯å¾„è§¦å‘å¼‚å¸¸
        invalid_path = "/invalid/path/test.csv"
        result = save_processed_data(self.test_df, invalid_path, "csv")

        self.assertFalse(result)
        mock_print.assert_called()


if __name__ == "__main__":
    unittest.main()
