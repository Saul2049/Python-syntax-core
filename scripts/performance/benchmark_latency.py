#!/usr/bin/env python3
"""
ä¿¡å·å»¶è¿ŸåŸºå‡†æµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€Ÿè¿­ä»£å’Œä¼˜åŒ–ä¿¡å·è®¡ç®—æ€§èƒ½
"""
import os
import statistics
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict

import pandas as pd

# æ·»åŠ srcè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

from src.core.price_fetcher import calculate_atr
from src.core.signal_processor import get_trading_signals
from src.core.signal_processor_optimized import get_trading_signals_optimized
from src.monitoring.metrics_collector import get_metrics_collector


class LatencyBenchmark:
    """å»¶è¿ŸåŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self):
        self.metrics = get_metrics_collector()
        self.results = []

    def generate_test_data(self, symbol: str = "BTCUSDT", periods: int = 100) -> pd.DataFrame:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        # åˆ›å»ºæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
        import random

        base_price = 50000.0
        data = []

        for i in range(periods):
            # æ¨¡æ‹Ÿä»·æ ¼éšæœºæ¸¸èµ°
            price_change = random.uniform(-0.02, 0.02)
            base_price *= 1 + price_change

            data.append(
                {
                    "timestamp": pd.Timestamp.now() - pd.Timedelta(minutes=periods - i),
                    "open": base_price * 0.999,
                    "high": base_price * 1.002,
                    "low": base_price * 0.998,
                    "close": base_price,
                    "volume": random.uniform(100, 1000),
                }
            )

        df = pd.DataFrame(data)
        df.set_index("timestamp", inplace=True)
        return df

    def benchmark_signal_calculation(self, iterations: int = 100) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ä¿¡å·è®¡ç®—"""
        print(f"ğŸ§ª ä¿¡å·è®¡ç®—åŸºå‡†æµ‹è¯• ({iterations}æ¬¡è¿­ä»£)")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = self.generate_test_data()
        latencies = []

        for i in range(iterations):
            start_time = time.time()

            # æ‰§è¡Œä¿¡å·è®¡ç®—
            try:
                signals = get_trading_signals(test_data, fast_win=7, slow_win=25)
                atr = calculate_atr(test_data)

                # éªŒè¯è®¡ç®—ç»“æœ
                if i == 0:
                    print(f"   ä¿¡å·æ•°é‡: {len(signals) if signals else 0}, ATRå€¼: {atr:.4f}")

                latency = time.time() - start_time
                latencies.append(latency)

                if (i + 1) % 20 == 0:
                    current_p95 = statistics.quantiles(latencies, n=20)[18]  # P95
                    print(f"   è¿›åº¦: {i+1}/{iterations}, å½“å‰P95: {current_p95*1000:.1f}ms")

            except Exception as e:
                print(f"   é”™è¯¯: {e}")
                continue

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if latencies:
            stats = {
                "mean": statistics.mean(latencies),
                "median": statistics.median(latencies),
                "p95": statistics.quantiles(latencies, n=20)[18],
                "p99": statistics.quantiles(latencies, n=100)[98],
                "min": min(latencies),
                "max": max(latencies),
                "count": len(latencies),
            }
        else:
            stats = {"error": "No successful iterations"}

        return stats

    def benchmark_data_fetch(self, iterations: int = 50) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•æ•°æ®è·å–"""
        print(f"ğŸ“Š æ•°æ®è·å–åŸºå‡†æµ‹è¯• ({iterations}æ¬¡è¿­ä»£)")

        latencies = []

        for i in range(iterations):
            start_time = time.time()

            try:
                # æ¨¡æ‹Ÿæ•°æ®è·å– (ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•æ•°æ®ä»£æ›¿çœŸå®APIè°ƒç”¨)
                test_data = self.generate_test_data(periods=200)

                # éªŒè¯æ•°æ®ç”Ÿæˆç»“æœ
                if i == 0:
                    print(f"   ç”Ÿæˆæ•°æ®è¡Œæ•°: {len(test_data)}")

                latency = time.time() - start_time
                latencies.append(latency)

                if (i + 1) % 10 == 0:
                    current_avg = statistics.mean(latencies)
                    print(f"   è¿›åº¦: {i+1}/{iterations}, å¹³å‡å»¶è¿Ÿ: {current_avg*1000:.1f}ms")

            except Exception as e:
                print(f"   é”™è¯¯: {e}")
                continue

        if latencies:
            stats = {
                "mean": statistics.mean(latencies),
                "median": statistics.median(latencies),
                "p95": statistics.quantiles(latencies, n=20)[18],
                "min": min(latencies),
                "max": max(latencies),
                "count": len(latencies),
            }
        else:
            stats = {"error": "No successful iterations"}

        return stats

    def benchmark_parallel_signals(
        self, iterations: int = 50, max_workers: int = 4
    ) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•å¹¶è¡Œä¿¡å·è®¡ç®—"""
        print(f"âš¡ å¹¶è¡Œä¿¡å·è®¡ç®—åŸºå‡†æµ‹è¯• ({iterations}æ¬¡è¿­ä»£, {max_workers}çº¿ç¨‹)")

        # å‡†å¤‡å¤šä¸ªæµ‹è¯•æ•°æ®é›†
        test_datasets = [self.generate_test_data() for _ in range(max_workers)]
        latencies = []

        def calculate_signal_worker(data):
            """å•ä¸ªä¿¡å·è®¡ç®—å·¥ä½œå‡½æ•°"""
            start_time = time.time()
            signals = get_trading_signals(data, fast_win=7, slow_win=25)
            atr = calculate_atr(data)
            # éªŒè¯è®¡ç®—ç»“æœ
            if signals and atr > 0:
                return time.time() - start_time
            return time.time() - start_time

        for i in range(iterations):
            batch_start = time.time()

            try:
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = [
                        executor.submit(calculate_signal_worker, data) for data in test_datasets
                    ]

                    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                    for future in as_completed(futures):
                        future.result()  # ç¡®ä¿æ²¡æœ‰å¼‚å¸¸

                total_latency = time.time() - batch_start
                latencies.append(total_latency)

                if (i + 1) % 10 == 0:
                    current_avg = statistics.mean(latencies)
                    print(f"   è¿›åº¦: {i+1}/{iterations}, å¹³å‡å»¶è¿Ÿ: {current_avg*1000:.1f}ms")

            except Exception as e:
                print(f"   é”™è¯¯: {e}")
                continue

        if latencies:
            stats = {
                "mean": statistics.mean(latencies),
                "median": statistics.median(latencies),
                "p95": statistics.quantiles(latencies, n=20)[18],
                "min": min(latencies),
                "max": max(latencies),
                "count": len(latencies),
                "workers": max_workers,
            }
        else:
            stats = {"error": "No successful iterations"}

        return stats

    def benchmark_optimized_signals(self, iterations: int = 100) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ä¼˜åŒ–ç‰ˆä¿¡å·è®¡ç®—"""
        print(f"ğŸš€ ä¼˜åŒ–ç‰ˆä¿¡å·è®¡ç®—åŸºå‡†æµ‹è¯• ({iterations}æ¬¡è¿­ä»£)")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = self.generate_test_data()
        latencies = []

        for i in range(iterations):
            start_time = time.time()

            # æ‰§è¡Œä¼˜åŒ–ç‰ˆä¿¡å·è®¡ç®—
            try:
                signals = get_trading_signals_optimized(test_data, fast_win=7, slow_win=25)

                # éªŒè¯è®¡ç®—ç»“æœ
                if i == 0:
                    print(f"   ä¼˜åŒ–ç‰ˆä¿¡å·æ•°é‡: {len(signals) if signals else 0}")

                latency = time.time() - start_time
                latencies.append(latency)

                if (i + 1) % 20 == 0:
                    current_p95 = statistics.quantiles(latencies, n=20)[18]  # P95
                    print(f"   è¿›åº¦: {i+1}/{iterations}, å½“å‰P95: {current_p95*1000:.1f}ms")

            except Exception as e:
                print(f"   é”™è¯¯: {e}")
                continue

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if latencies:
            stats = {
                "mean": statistics.mean(latencies),
                "median": statistics.median(latencies),
                "p95": statistics.quantiles(latencies, n=20)[18],
                "p99": statistics.quantiles(latencies, n=100)[98],
                "min": min(latencies),
                "max": max(latencies),
                "count": len(latencies),
            }
        else:
            stats = {"error": "No successful iterations"}

        return stats

    def benchmark_cache_performance(self, iterations: int = 200) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print(f"ğŸ’¾ ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯• ({iterations}æ¬¡è¿­ä»£)")

        # å‡†å¤‡æµ‹è¯•æ•°æ® - ä½¿ç”¨ç›¸åŒæ•°æ®æµ‹è¯•ç¼“å­˜å‘½ä¸­
        test_data = self.generate_test_data()
        latencies = []
        cache_hits = 0

        for i in range(iterations):
            start_time = time.time()

            try:
                # å‰ä¸€åŠä½¿ç”¨ç›¸åŒæ•°æ®ï¼Œåä¸€åŠä½¿ç”¨ä¸åŒæ•°æ®
                if i < iterations // 2:
                    signals = get_trading_signals_optimized(test_data, fast_win=7, slow_win=25)
                    if i > 0:  # ç¬¬ä¸€æ¬¡ä¹‹ååº”è¯¥æ˜¯ç¼“å­˜å‘½ä¸­
                        cache_hits += 1
                else:
                    # ä½¿ç”¨æ–°æ•°æ®
                    new_data = self.generate_test_data()
                    signals = get_trading_signals_optimized(new_data, fast_win=7, slow_win=25)

                # éªŒè¯è®¡ç®—ç»“æœ
                if i == 0:
                    print(f"   ç¼“å­˜æµ‹è¯•ä¿¡å·æ•°é‡: {len(signals) if signals else 0}")

                latency = time.time() - start_time
                latencies.append(latency)

                if (i + 1) % 50 == 0:
                    current_avg = statistics.mean(latencies)
                    print(f"   è¿›åº¦: {i+1}/{iterations}, å¹³å‡å»¶è¿Ÿ: {current_avg*1000:.1f}ms")

            except Exception as e:
                print(f"   é”™è¯¯: {e}")
                continue

        if latencies:
            stats = {
                "mean": statistics.mean(latencies),
                "median": statistics.median(latencies),
                "p95": statistics.quantiles(latencies, n=20)[18],
                "min": min(latencies),
                "max": max(latencies),
                "count": len(latencies),
                "cache_hits": cache_hits,
                "hit_rate": cache_hits / (iterations // 2 - 1) if iterations > 2 else 0,
            }
        else:
            stats = {"error": "No successful iterations"}

        return stats

    def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´å»¶è¿ŸåŸºå‡†æµ‹è¯•")
        print("=" * 60)

        results = {
            "timestamp": time.time(),
            "signal_calculation": {},
            "data_fetch": {},
            "parallel_signals": {},
            "optimized_signals": {},
            "cache_performance": {},
        }

        # 1. ä¿¡å·è®¡ç®—åŸºå‡†
        results["signal_calculation"] = self.benchmark_signal_calculation(100)
        print()

        # 2. æ•°æ®è·å–åŸºå‡†
        results["data_fetch"] = self.benchmark_data_fetch(50)
        print()

        # 3. å¹¶è¡Œä¿¡å·è®¡ç®—åŸºå‡†
        results["parallel_signals"] = self.benchmark_parallel_signals(30, max_workers=4)
        print()

        # 4. ä¼˜åŒ–ç‰ˆä¿¡å·è®¡ç®—åŸºå‡†
        results["optimized_signals"] = self.benchmark_optimized_signals(100)
        print()

        # 5. ç¼“å­˜æ€§èƒ½åŸºå‡†
        results["cache_performance"] = self.benchmark_cache_performance(200)
        print()

        # è¾“å‡ºæ±‡æ€»æŠ¥å‘Š
        self._print_summary(results)

        return results

    def _print_summary(self, results: Dict[str, Any]):
        """æ‰“å°æ±‡æ€»æŠ¥å‘Š"""
        print("=" * 60)
        print("ğŸ“Š åŸºå‡†æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print("=" * 60)

        for category, stats in results.items():
            if category == "timestamp":
                continue

            if "error" in stats:
                print(f"âŒ {category}: {stats['error']}")
                continue

            category_name = {
                "signal_calculation": "ğŸ§® ä¿¡å·è®¡ç®—",
                "data_fetch": "ğŸ“Š æ•°æ®è·å–",
                "parallel_signals": "âš¡ å¹¶è¡Œè®¡ç®—",
                "optimized_signals": "ğŸš€ ä¼˜åŒ–ç‰ˆä¿¡å·è®¡ç®—",
                "cache_performance": "ğŸ’¾ ç¼“å­˜æ€§èƒ½",
            }.get(category, category)

            print(f"\n{category_name}:")
            print(f"   å¹³å‡å»¶è¿Ÿ: {stats['mean']*1000:.1f}ms")
            print(f"   P95å»¶è¿Ÿ:  {stats['p95']*1000:.1f}ms")
            print(f"   P99å»¶è¿Ÿ:  {stats['p99']*1000:.1f}ms" if "p99" in stats else "")
            print(f"   æœ€å°å»¶è¿Ÿ: {stats['min']*1000:.1f}ms")
            print(f"   æœ€å¤§å»¶è¿Ÿ: {stats['max']*1000:.1f}ms")
            print(f"   æ ·æœ¬æ•°é‡: {stats['count']}")

            # ç¼“å­˜å‘½ä¸­ç‡æ˜¾ç¤º
            if "hit_rate" in stats:
                print(f"   ç¼“å­˜å‘½ä¸­ç‡: {stats['hit_rate']*100:.1f}%")

            # ä¸ç›®æ ‡å¯¹æ¯”
            target_ms = 500  # 0.5s = 500ms
            p95_ms = stats["p95"] * 1000

            if p95_ms < target_ms:
                status = "âœ… å·²è¾¾æ ‡"
            elif p95_ms < target_ms * 1.2:
                status = "âš ï¸ æ¥è¿‘ç›®æ ‡"
            else:
                status = "âŒ éœ€è¦ä¼˜åŒ–"

            print(f"   çŠ¶æ€: {status} (ç›®æ ‡P95 < {target_ms}ms)")

        print("\n" + "=" * 60)
        print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")

        signal_p95 = results["signal_calculation"].get("p95", 0) * 1000
        if signal_p95 > 500:
            print("   ğŸ”§ ä¿¡å·è®¡ç®—å»¶è¿Ÿè¿‡é«˜ï¼Œå»ºè®®ï¼š")
            print("      - æ·»åŠ æŒ‡æ ‡ç¼“å­˜ (ATR, EMA)")
            print("      - ä¼˜åŒ–pandasæ“ä½œ")
            print("      - ä½¿ç”¨å‘é‡åŒ–è®¡ç®—")

        parallel_p95 = results["parallel_signals"].get("p95", 0) * 1000
        if parallel_p95 < signal_p95 * 0.7:
            print("   âš¡ å¹¶è¡Œè®¡ç®—æ•ˆæœæ˜¾è‘—ï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒå¯ç”¨")

        print("   ğŸ“ˆ æŒç»­ç›‘æ§: make monitor-metrics")


def main():
    """ä¸»å‡½æ•°"""
    benchmark = LatencyBenchmark()

    print("ğŸ¯ äº¤æ˜“ç³»ç»Ÿå»¶è¿ŸåŸºå‡†æµ‹è¯•")
    print("ç›®æ ‡: P95ä¿¡å·å»¶è¿Ÿ < 0.5ç§’ (500ms)")
    print()

    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    results = benchmark.run_full_benchmark()

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    import json

    timestamp = int(time.time())
    filename = f"benchmark_results_{timestamp}.json"

    with open(filename, "w") as f:
        json.dump(results, f, indent=2)

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    print("ğŸ”„ å»ºè®®å®šæœŸè¿è¡Œæ­¤è„šæœ¬ç›‘æ§æ€§èƒ½å˜åŒ–")


if __name__ == "__main__":
    main()
