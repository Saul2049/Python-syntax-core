#!/usr/bin/env python3
"""
M4é˜¶æ®µç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•
M4 Simplified Async Performance Benchmark

ç”¨é€”ï¼š
- æµ‹è¯•å¼‚æ­¥ä¿¡å·å¤„ç†æ€§èƒ½
- æµ‹è¯•å¹¶å‘ä»»åŠ¡è°ƒåº¦æ€§èƒ½
- éªŒè¯M3+M4ç»„åˆä¼˜åŒ–æ•ˆæœ
"""

import asyncio
import json
import statistics
import time
from datetime import datetime
from typing import Any, Dict

import numpy as np
import pandas as pd
import psutil

from src.core.signal_processor_vectorized import OptimizedSignalProcessor
from src.monitoring.metrics_collector import get_metrics_collector


class M4SimpleBenchmark:
    """M4ç®€åŒ–æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self):
        self.metrics = get_metrics_collector()
        self.signal_processor = OptimizedSignalProcessor()

        # æµ‹è¯•é…ç½®
        self.test_duration = 30  # æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        self.symbols = ["BTCUSDT", "ETHUSDT", "ADAUSDT"]

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        self.test_data = self._generate_market_data()

        # æ€§èƒ½ç»Ÿè®¡
        self.async_latencies = []
        self.signal_latencies = []
        self.cpu_usage = []

    def _generate_market_data(self) -> Dict[str, pd.DataFrame]:
        """ç”Ÿæˆæµ‹è¯•å¸‚åœºæ•°æ®"""
        market_data = {}

        for symbol in self.symbols:
            np.random.seed(hash(symbol) % 2**32)  # ç¡®ä¿æ¯ä¸ªsymbolæœ‰ä¸åŒä½†å¯é‡å¤çš„æ•°æ®

            data = []
            base_price = 30000 if "BTC" in symbol else 2000 if "ETH" in symbol else 0.5

            for i in range(200):  # 200ä¸ªæ•°æ®ç‚¹
                # ç”Ÿæˆä»·æ ¼èµ°åŠ¿
                if i == 0:
                    price = base_price
                else:
                    price = data[-1]["close"] * (1 + np.random.normal(0, 0.01))

                # ç”ŸæˆOHLC
                high = price * (1 + abs(np.random.normal(0, 0.005)))
                low = price * (1 - abs(np.random.normal(0, 0.005)))
                open_price = data[-1]["close"] if i > 0 else price

                data.append(
                    {
                        "timestamp": pd.Timestamp.now() - pd.Timedelta(minutes=200 - i),
                        "open": open_price,
                        "high": high,
                        "low": low,
                        "close": price,
                        "volume": np.random.randint(100, 10000),
                    }
                )

            df = pd.DataFrame(data)
            df.set_index("timestamp", inplace=True)
            market_data[symbol] = df

        return market_data

    async def benchmark_async_signal_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä¿¡å·å¤„ç†æ€§èƒ½"""
        print("ğŸ”„ æµ‹è¯•å¼‚æ­¥ä¿¡å·å¤„ç†æ€§èƒ½")

        signal_times = []
        concurrent_count = 0
        max_concurrent = 0

        async def process_symbol_signals(symbol: str, iterations: int = 50):
            """å¤„ç†å•ä¸ªäº¤æ˜“å¯¹çš„ä¿¡å·"""
            nonlocal concurrent_count, max_concurrent

            concurrent_count += 1
            max_concurrent = max(max_concurrent, concurrent_count)

            symbol_times = []

            try:
                for i in range(iterations):
                    # æ¨¡æ‹Ÿæ•°æ®æ›´æ–°
                    data = self.test_data[symbol].copy()

                    start_time = time.perf_counter()

                    # å¼‚æ­¥ä¿¡å·å¤„ç†
                    signals = self.signal_processor.get_trading_signals_optimized(data)
                    atr = self.signal_processor.compute_atr_optimized(data)

                    end_time = time.perf_counter()
                    processing_time = (end_time - start_time) * 1000  # ms

                    symbol_times.append(processing_time)

                    # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†å»¶è¿Ÿ
                    await asyncio.sleep(0.001)  # 1mså¼‚æ­¥å»¶è¿Ÿ

                return symbol_times

            finally:
                concurrent_count -= 1

        # å¹¶å‘å¤„ç†æ‰€æœ‰äº¤æ˜“å¯¹
        start_time = time.time()

        tasks = [process_symbol_signals(symbol) for symbol in self.symbols]
        results = await asyncio.gather(*tasks)

        end_time = time.time()
        total_time = end_time - start_time

        # åˆå¹¶æ‰€æœ‰ä¿¡å·å»¶è¿Ÿ
        for symbol_times in results:
            signal_times.extend(symbol_times)

        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        if signal_times:
            avg_latency = statistics.mean(signal_times)
            p95_latency = (
                statistics.quantiles(signal_times, n=20)[18]
                if len(signal_times) >= 20
                else max(signal_times)
            )
            max_latency = max(signal_times)
            min_latency = min(signal_times)
        else:
            avg_latency = p95_latency = max_latency = min_latency = 0

        results = {
            "avg_latency_ms": avg_latency,
            "p95_latency_ms": p95_latency,
            "max_latency_ms": max_latency,
            "min_latency_ms": min_latency,
            "total_signals": len(signal_times),
            "symbols_processed": len(self.symbols),
            "max_concurrent": max_concurrent,
            "total_time_s": total_time,
            "throughput_signals_per_sec": len(signal_times) / total_time if total_time > 0 else 0,
            "target_met": p95_latency <= 50,  # ç›®æ ‡ï¼šP95â‰¤50msï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        }

        self._print_async_signal_results(results)
        return results

    async def benchmark_concurrent_cpu_usage(self) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘CPUä½¿ç”¨ç‡"""
        print("ğŸ’» æµ‹è¯•å¹¶å‘CPUä½¿ç”¨ç‡ï¼ˆç›®æ ‡ï¼šâ‰¤30%ï¼‰")

        cpu_measurements = []
        memory_measurements = []

        async def cpu_monitor():
            """CPUç›‘æ§ä»»åŠ¡"""
            for _ in range(self.test_duration):
                cpu_percent = psutil.cpu_percent(interval=None)
                memory_percent = psutil.virtual_memory().percent

                cpu_measurements.append(cpu_percent)
                memory_measurements.append(memory_percent)

                await asyncio.sleep(1)

        async def high_frequency_signal_processing():
            """é«˜é¢‘ä¿¡å·å¤„ç†ä»»åŠ¡"""
            for i in range(self.test_duration * 10):  # 10Hzé¢‘ç‡
                # éšæœºé€‰æ‹©äº¤æ˜“å¯¹
                symbol = self.symbols[i % len(self.symbols)]
                data = self.test_data[symbol]

                # ä¿¡å·å¤„ç†
                signals = self.signal_processor.get_trading_signals_optimized(data)
                atr = self.signal_processor.compute_atr_optimized(data)

                await asyncio.sleep(0.1)  # 100msé—´éš”

        async def market_data_simulation():
            """å¸‚åœºæ•°æ®æ¨¡æ‹Ÿä»»åŠ¡"""
            for i in range(self.test_duration * 5):  # 5Hzé¢‘ç‡
                # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è´Ÿè½½
                data = [x**2 for x in range(1000)]
                sum(data)  # æ¶ˆè€—ä¸€äº›CPU

                await asyncio.sleep(0.2)  # 200msé—´éš”

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        await asyncio.gather(
            cpu_monitor(), high_frequency_signal_processing(), market_data_simulation()
        )

        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        avg_cpu = statistics.mean(cpu_measurements) if cpu_measurements else 0
        max_cpu = max(cpu_measurements) if cpu_measurements else 0
        avg_memory = statistics.mean(memory_measurements) if memory_measurements else 0

        results = {
            "avg_cpu_percent": avg_cpu,
            "max_cpu_percent": max_cpu,
            "avg_memory_percent": avg_memory,
            "measurements": len(cpu_measurements),
            "target_met": max_cpu <= 30,  # ç›®æ ‡ï¼šCPUâ‰¤30%
        }

        self._print_cpu_results(results)
        return results

    async def benchmark_async_task_scheduling(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡è°ƒåº¦æ€§èƒ½"""
        print("âš¡ æµ‹è¯•å¼‚æ­¥ä»»åŠ¡è°ƒåº¦æ€§èƒ½")

        task_latencies = []
        completed_tasks = 0

        async def async_task(task_id: int, complexity: int = 1):
            """å¼‚æ­¥ä»»åŠ¡"""
            start_time = time.perf_counter()

            # æ¨¡æ‹Ÿä¸åŒå¤æ‚åº¦çš„è®¡ç®—
            for _ in range(complexity * 100):
                await asyncio.sleep(0.0001)  # 0.1mså¼‚æ­¥å»¶è¿Ÿ

            end_time = time.perf_counter()
            latency = (end_time - start_time) * 1000  # ms

            return task_id, latency

        # åˆ›å»ºå¤§é‡å¼‚æ­¥ä»»åŠ¡
        tasks = []
        for i in range(100):  # 100ä¸ªä»»åŠ¡
            complexity = (i % 5) + 1  # 1-5å¤æ‚åº¦
            tasks.append(async_task(i, complexity))

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        start_time = time.time()
        results = await asyncio.gather(*tasks)
        end_time = time.time()

        total_time = end_time - start_time

        # æå–å»¶è¿Ÿæ•°æ®
        for task_id, latency in results:
            task_latencies.append(latency)
            completed_tasks += 1

        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        if task_latencies:
            avg_latency = statistics.mean(task_latencies)
            p95_latency = (
                statistics.quantiles(task_latencies, n=20)[18]
                if len(task_latencies) >= 20
                else max(task_latencies)
            )
            max_latency = max(task_latencies)
        else:
            avg_latency = p95_latency = max_latency = 0

        results = {
            "avg_task_latency_ms": avg_latency,
            "p95_task_latency_ms": p95_latency,
            "max_task_latency_ms": max_latency,
            "completed_tasks": completed_tasks,
            "total_time_s": total_time,
            "task_throughput": completed_tasks / total_time if total_time > 0 else 0,
            "target_met": p95_latency <= 200,  # ç›®æ ‡ï¼šP95â‰¤200ms
        }

        self._print_task_results(results)
        return results

    def _print_async_signal_results(self, results: Dict[str, Any]):
        """æ‰“å°å¼‚æ­¥ä¿¡å·å¤„ç†ç»“æœ"""
        print("\n" + "=" * 60)
        print("ğŸ”„ å¼‚æ­¥ä¿¡å·å¤„ç†æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 60)

        print("ğŸ“Š ä¿¡å·å¤„ç†å»¶è¿Ÿ:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {results['avg_latency_ms']:.2f}ms")
        print(f"   P95å»¶è¿Ÿ:  {results['p95_latency_ms']:.2f}ms")
        print(f"   æœ€å¤§å»¶è¿Ÿ: {results['max_latency_ms']:.2f}ms")
        print(f"   æœ€å°å»¶è¿Ÿ: {results['min_latency_ms']:.2f}ms")

        print("\nğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        print(f"   ä¿¡å·æ€»æ•°: {results['total_signals']}")
        print(f"   äº¤æ˜“å¯¹æ•°: {results['symbols_processed']}")
        print(f"   æœ€å¤§å¹¶å‘: {results['max_concurrent']}")
        print(f"   æ€»è€—æ—¶: {results['total_time_s']:.2f}ç§’")
        print(f"   ååé‡: {results['throughput_signals_per_sec']:.1f} ä¿¡å·/ç§’")

        status = "âœ… ç›®æ ‡è¾¾æˆ" if results["target_met"] else "âŒ æœªè¾¾ç›®æ ‡"
        print(f"\nğŸ¯ ç›®æ ‡æ£€æŸ¥ (P95â‰¤50ms): {status}")
        print("=" * 60)

    def _print_cpu_results(self, results: Dict[str, Any]):
        """æ‰“å°CPUä½¿ç”¨ç‡ç»“æœ"""
        print("\n" + "=" * 60)
        print("ğŸ’» å¹¶å‘CPUä½¿ç”¨ç‡æµ‹è¯•ç»“æœ")
        print("=" * 60)

        print("ğŸ–¥ï¸ CPUä½¿ç”¨ç‡:")
        print(f"   å¹³å‡CPU: {results['avg_cpu_percent']:.1f}%")
        print(f"   å³°å€¼CPU: {results['max_cpu_percent']:.1f}%")

        print("\nğŸ’¾ å†…å­˜ä½¿ç”¨ç‡:")
        print(f"   å¹³å‡å†…å­˜: {results['avg_memory_percent']:.1f}%")

        print("\nğŸ“Š ç›‘æ§ç»Ÿè®¡:")
        print(f"   æµ‹é‡æ¬¡æ•°: {results['measurements']}")

        status = "âœ… ç›®æ ‡è¾¾æˆ" if results["target_met"] else "âŒ æœªè¾¾ç›®æ ‡"
        print(f"\nğŸ¯ ç›®æ ‡æ£€æŸ¥ (CPUâ‰¤30%): {status}")
        print("=" * 60)

    def _print_task_results(self, results: Dict[str, Any]):
        """æ‰“å°ä»»åŠ¡è°ƒåº¦ç»“æœ"""
        print("\n" + "=" * 60)
        print("âš¡ å¼‚æ­¥ä»»åŠ¡è°ƒåº¦æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 60)

        print("ğŸ“Š ä»»åŠ¡å»¶è¿Ÿ:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {results['avg_task_latency_ms']:.2f}ms")
        print(f"   P95å»¶è¿Ÿ:  {results['p95_task_latency_ms']:.2f}ms")
        print(f"   æœ€å¤§å»¶è¿Ÿ: {results['max_task_latency_ms']:.2f}ms")

        print("\nğŸ“ˆ è°ƒåº¦ç»Ÿè®¡:")
        print(f"   å®Œæˆä»»åŠ¡: {results['completed_tasks']}")
        print(f"   æ€»è€—æ—¶: {results['total_time_s']:.2f}ç§’")
        print(f"   ä»»åŠ¡åå: {results['task_throughput']:.1f} ä»»åŠ¡/ç§’")

        status = "âœ… ç›®æ ‡è¾¾æˆ" if results["target_met"] else "âŒ æœªè¾¾ç›®æ ‡"
        print(f"\nğŸ¯ ç›®æ ‡æ£€æŸ¥ (P95â‰¤200ms): {status}")
        print("=" * 60)

    async def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„M4æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ M4é˜¶æ®µç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•å¯åŠ¨")
        print(f"â±ï¸ æµ‹è¯•æ—¶é•¿: {self.test_duration}ç§’")
        print(f"ğŸ“Š æµ‹è¯•äº¤æ˜“å¯¹: {self.symbols}")

        start_time = time.time()
        results = {}

        try:
            # 1. å¼‚æ­¥ä¿¡å·å¤„ç†æµ‹è¯•
            results["async_signals"] = await self.benchmark_async_signal_processing()

            # 2. å¼‚æ­¥ä»»åŠ¡è°ƒåº¦æµ‹è¯•
            results["task_scheduling"] = await self.benchmark_async_task_scheduling()

            # 3. å¹¶å‘CPUä½¿ç”¨ç‡æµ‹è¯•
            results["cpu_usage"] = await self.benchmark_concurrent_cpu_usage()

            # 4. ç”Ÿæˆç»¼åˆè¯„ä¼°
            results["summary"] = self._generate_summary(results)

            # 5. ä¿å­˜ç»“æœ
            await self._save_results(results)

            return results

        except Exception as e:
            print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return {"error": str(e)}
        finally:
            total_time = time.time() - start_time
            print(f"\nâ±ï¸ æµ‹è¯•æ€»è€—æ—¶: {total_time:.1f}ç§’")

    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°"""
        targets_met = []

        # æ£€æŸ¥å„é¡¹ç›®æ ‡
        for test_name in ["async_signals", "task_scheduling", "cpu_usage"]:
            if test_name in results and "target_met" in results[test_name]:
                targets_met.append(results[test_name]["target_met"])

        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        if targets_met:
            success_rate = sum(targets_met) / len(targets_met) * 100
            all_targets_met = all(targets_met)
        else:
            success_rate = 0
            all_targets_met = False

        summary = {
            "all_targets_met": all_targets_met,
            "success_rate": success_rate,
            "targets_checked": len(targets_met),
            "timestamp": datetime.now().isoformat(),
        }

        self._print_summary(summary)
        return summary

    def _print_summary(self, summary: Dict[str, Any]):
        """æ‰“å°ç»¼åˆè¯„ä¼°"""
        print("\n" + "=" * 60)
        print("ğŸ¯ M4å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•ç»¼åˆè¯„ä¼°")
        print("=" * 60)

        status = "ğŸ‰ å…¨éƒ¨è¾¾æ ‡" if summary["all_targets_met"] else "âš ï¸ éƒ¨åˆ†æœªè¾¾æ ‡"
        print(f"ğŸ“Š æ€»ä½“çŠ¶æ€: {status}")
        print(f"ğŸ¯ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"ğŸ” æ£€æŸ¥é¡¹ç›®: {summary['targets_checked']}")

        print("\nğŸ“‹ M4é˜¶æ®µå…³é”®æŒ‡æ ‡:")
        print("   âœ“ å¼‚æ­¥ä¿¡å·P95 â‰¤ 50ms")
        print("   âœ“ ä»»åŠ¡è°ƒåº¦P95 â‰¤ 200ms")
        print("   âœ“ å¹¶å‘CPU â‰¤ 30%")

        if summary["all_targets_met"]:
            print("\nğŸ† M4é˜¶æ®µå¼‚æ­¥ä¼˜åŒ–ç›®æ ‡è¾¾æˆï¼")
            print("âœ… CPUä»æ¯«ç§’çº§ä¼˜åŒ–åˆ°å¾®ç§’çº§æˆåŠŸ")
            print("ğŸš€ ç³»ç»Ÿå…·å¤‡é«˜å¹¶å‘å®æ—¶å¤„ç†èƒ½åŠ›")
        else:
            print("\nâš ï¸ éƒ¨åˆ†æŒ‡æ ‡éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

        print("=" * 60)

    async def _save_results(self, results: Dict[str, Any]):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        try:
            filename = f"output/m4_simple_benchmark_{int(time.time())}.json"
            with open(filename, "w") as f:
                json.dump(results, f, indent=2, default=str)

            print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜: {filename}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨M4é˜¶æ®µç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•")

    benchmark = M4SimpleBenchmark()
    results = await benchmark.run_full_benchmark()

    if "error" not in results:
        print("\nğŸŠ M4ç®€åŒ–æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {results['error']}")


if __name__ == "__main__":
    asyncio.run(main())
