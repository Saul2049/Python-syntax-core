#!/usr/bin/env python3
"""
å†…å­˜åŸºçº¿é‡‡é›†å™¨ - M5é˜¶æ®µ
Memory Baseline Collector for M5 Phase

ç”¨é€”ï¼š
- 30åˆ†é’Ÿå†…å­˜åŸºçº¿é‡‡æ ·
- å»ºç«‹æ€§èƒ½åŸºå‡†
- ä¸ºåç»­ä¼˜åŒ–æä¾›å¯¹æ¯”
"""

import argparse
import asyncio
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Any, Dict

import psutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../.."))

from scripts.memory.gc_profiler import GCProfiler
from scripts.memory.mem_snapshot import MemorySnapshot


class MemoryBaseline:
    """å†…å­˜åŸºçº¿é‡‡é›†å™¨"""

    def __init__(self, sample_interval: int = 60):
        self.sample_interval = sample_interval
        self.process = psutil.Process()
        self.baseline_data = {
            "metadata": {
                "start_time": None,
                "end_time": None,
                "duration_seconds": 0,
                "sample_interval": sample_interval,
                "python_version": sys.version,
                "platform": os.name,
            },
            "memory_samples": [],
            "gc_events": [],
            "process_stats": [],
            "system_stats": [],
        }

        self.memory_snapshot = MemorySnapshot()
        self.gc_profiler = GCProfiler(enable_prometheus=False)
        self.logger = logging.getLogger(__name__)

    async def collect_baseline(self, duration_seconds: int):
        """é‡‡é›†å†…å­˜åŸºçº¿æ•°æ®"""
        self.baseline_data["metadata"]["start_time"] = datetime.now().isoformat()
        self.baseline_data["metadata"]["duration_seconds"] = duration_seconds

        self.logger.info(f"ğŸš€ å¼€å§‹é‡‡é›†å†…å­˜åŸºçº¿ ({duration_seconds}ç§’)")

        # å¯åŠ¨å†…å­˜å’ŒGCç›‘æ§
        self.memory_snapshot.start_tracing()
        self.gc_profiler.start_monitoring()

        start_time = time.time()
        end_time = start_time + duration_seconds
        sample_count = 0

        try:
            while time.time() < end_time:
                # é‡‡é›†å½“å‰æ ·æœ¬
                sample = await self._collect_sample()
                sample["sample_id"] = sample_count
                sample["elapsed_seconds"] = time.time() - start_time

                self.baseline_data["memory_samples"].append(sample)

                # è¿›åº¦æŠ¥å‘Š
                progress = (time.time() - start_time) / duration_seconds * 100
                self.logger.info(f"ğŸ“Š é‡‡æ ·è¿›åº¦: {progress:.1f}% (æ ·æœ¬ {sample_count+1})")

                sample_count += 1

                # ç­‰å¾…ä¸‹ä¸€ä¸ªé‡‡æ ·é—´éš”
                await asyncio.sleep(self.sample_interval)

            # æ”¶é›†æœ€ç»ˆç»Ÿè®¡
            await self._finalize_baseline()

        except Exception as e:
            self.logger.error(f"âŒ åŸºçº¿é‡‡é›†é”™è¯¯: {e}")
            raise
        finally:
            # åœæ­¢ç›‘æ§
            self.gc_profiler.stop_monitoring()

        self.baseline_data["metadata"]["end_time"] = datetime.now().isoformat()
        self.logger.info(f"âœ… åŸºçº¿é‡‡é›†å®Œæˆï¼Œå…± {sample_count} ä¸ªæ ·æœ¬")

        return self.baseline_data

    async def _collect_sample(self) -> Dict[str, Any]:
        """é‡‡é›†å•ä¸ªå†…å­˜æ ·æœ¬"""
        # å†…å­˜å¿«ç…§
        memory_snapshot = self.memory_snapshot.take_snapshot()

        # è¿›ç¨‹ç»Ÿè®¡
        try:
            process_info = {
                "cpu_percent": self.process.cpu_percent(),
                "memory_info": self.process.memory_info()._asdict(),
                "memory_percent": self.process.memory_percent(),
                "num_threads": self.process.num_threads(),
                "connections": len(self.process.connections()),
            }

            # å°è¯•è·å–æ–‡ä»¶æè¿°ç¬¦æ•°é‡
            try:
                process_info["num_fds"] = self.process.num_fds()
            except AttributeError:
                # Windowsä¸æ”¯æŒ
                process_info["num_fds"] = len(self.process.open_files())

        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿›ç¨‹ä¿¡æ¯é‡‡é›†å¤±è´¥: {e}")
            process_info = {"error": str(e)}

        # ç³»ç»Ÿç»Ÿè®¡
        system_info = {
            "cpu_percent": psutil.cpu_percent(),
            "memory": psutil.virtual_memory()._asdict(),
            "swap": psutil.swap_memory()._asdict(),
            "disk_usage": psutil.disk_usage("/")._asdict() if os.name != "nt" else None,
        }

        return {
            "timestamp": datetime.now().isoformat(),
            "memory_snapshot": memory_snapshot,
            "process_info": process_info,
            "system_info": system_info,
        }

    async def _finalize_baseline(self):
        """å®ŒæˆåŸºçº¿æ•°æ®æ”¶é›†"""
        # è·å–GCç»Ÿè®¡
        gc_stats = self.gc_profiler.get_statistics()
        self.baseline_data["gc_events"] = gc_stats

        # è®¡ç®—åŸºçº¿ç»Ÿè®¡
        memory_samples = [
            s
            for s in self.baseline_data["memory_samples"]
            if "error" not in s.get("memory_snapshot", {})
        ]

        if memory_samples:
            rss_values = []
            vms_values = []
            cpu_values = []

            for sample in memory_samples:
                if "memory_snapshot" in sample and "memory" in sample["memory_snapshot"]:
                    mem = sample["memory_snapshot"]["memory"]
                    rss_values.append(mem["rss_mb"])
                    vms_values.append(mem.get("vms_bytes", 0) / 1024 / 1024)

                if "process_info" in sample and "cpu_percent" in sample["process_info"]:
                    cpu_values.append(sample["process_info"]["cpu_percent"])

            # åŸºçº¿ç»Ÿè®¡
            baseline_stats = {
                "memory_rss": {
                    "min_mb": min(rss_values) if rss_values else 0,
                    "max_mb": max(rss_values) if rss_values else 0,
                    "avg_mb": sum(rss_values) / len(rss_values) if rss_values else 0,
                    "p50_mb": sorted(rss_values)[len(rss_values) // 2] if rss_values else 0,
                    "p95_mb": sorted(rss_values)[int(len(rss_values) * 0.95)] if rss_values else 0,
                },
                "memory_vms": {
                    "min_mb": min(vms_values) if vms_values else 0,
                    "max_mb": max(vms_values) if vms_values else 0,
                    "avg_mb": sum(vms_values) / len(vms_values) if vms_values else 0,
                },
                "cpu_usage": {
                    "min_percent": min(cpu_values) if cpu_values else 0,
                    "max_percent": max(cpu_values) if cpu_values else 0,
                    "avg_percent": sum(cpu_values) / len(cpu_values) if cpu_values else 0,
                },
                "sample_count": len(memory_samples),
                "gc_summary": {
                    "total_collections": gc_stats.get("total_gc_events", 0),
                    "avg_pause_ms": gc_stats.get("avg_pause_time", 0) * 1000,
                    "gc_frequency": gc_stats.get("gc_frequency", 0),
                },
            }

            self.baseline_data["baseline_stats"] = baseline_stats

    def save_baseline(self, filename: str):
        """ä¿å­˜åŸºçº¿æ•°æ®"""
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with open(filename, "w") as f:
            json.dump(self.baseline_data, f, indent=2, default=str)

        self.logger.info(f"ğŸ’¾ åŸºçº¿æ•°æ®å·²ä¿å­˜: {filename}")

        # æ‰“å°åŸºçº¿æ‘˜è¦
        if "baseline_stats" in self.baseline_data:
            self._print_baseline_summary()

    def _print_baseline_summary(self):
        """æ‰“å°åŸºçº¿æ‘˜è¦"""
        stats = self.baseline_data["baseline_stats"]

        print("\n" + "=" * 60)
        print("ğŸ“Š M5å†…å­˜åŸºçº¿æ‘˜è¦")
        print("=" * 60)
        print(f"â±ï¸ é‡‡æ ·æ—¶é•¿: {self.baseline_data['metadata']['duration_seconds']}ç§’")
        print(f"ğŸ“¸ æ ·æœ¬æ•°é‡: {stats['sample_count']}")

        print("\nğŸ§  å†…å­˜ä½¿ç”¨ (RSS):")
        rss = stats["memory_rss"]
        print(f"   èŒƒå›´: {rss['min_mb']:.1f} - {rss['max_mb']:.1f} MB")
        print(f"   å¹³å‡: {rss['avg_mb']:.1f} MB")
        print(f"   P50:  {rss['p50_mb']:.1f} MB")
        print(f"   P95:  {rss['p95_mb']:.1f} MB")

        print("\nğŸ–¥ï¸ CPUä½¿ç”¨:")
        cpu = stats["cpu_usage"]
        print(f"   èŒƒå›´: {cpu['min_percent']:.1f}% - {cpu['max_percent']:.1f}%")
        print(f"   å¹³å‡: {cpu['avg_percent']:.1f}%")

        print("\nğŸ—‘ï¸ GCç»Ÿè®¡:")
        gc_summary = stats["gc_summary"]
        print(f"   æ€»å›æ”¶: {gc_summary['total_collections']}æ¬¡")
        print(f"   å¹³å‡æš‚åœ: {gc_summary['avg_pause_ms']:.2f}ms")
        print(f"   å›æ”¶é¢‘ç‡: {gc_summary['gc_frequency']:.2f}/ç§’")

        print("=" * 60)
        print("âœ… åŸºçº¿æ•°æ®å¯ç”¨äºåç»­å†…å­˜ä¼˜åŒ–å¯¹æ¯”")
        print("=" * 60)


def compare_with_baseline(current_data: Dict[str, Any], baseline_file: str) -> Dict[str, Any]:
    """ä¸åŸºçº¿æ•°æ®å¯¹æ¯”"""
    try:
        with open(baseline_file, "r") as f:
            baseline = json.load(f)

        if "baseline_stats" not in baseline:
            return {"error": "Invalid baseline file"}

        baseline_stats = baseline["baseline_stats"]
        current_stats = current_data.get("baseline_stats", {})

        comparison = {
            "memory_comparison": {},
            "cpu_comparison": {},
            "gc_comparison": {},
            "regression_detected": False,
            "improvements": [],
            "regressions": [],
        }

        # å†…å­˜å¯¹æ¯”
        if "memory_rss" in current_stats and "memory_rss" in baseline_stats:
            current_rss = current_stats["memory_rss"]
            baseline_rss = baseline_stats["memory_rss"]

            avg_change = (
                (current_rss["avg_mb"] - baseline_rss["avg_mb"]) / baseline_rss["avg_mb"]
            ) * 100
            p95_change = (
                (current_rss["p95_mb"] - baseline_rss["p95_mb"]) / baseline_rss["p95_mb"]
            ) * 100

            comparison["memory_comparison"] = {
                "avg_mb_change": avg_change,
                "p95_mb_change": p95_change,
                "current_avg": current_rss["avg_mb"],
                "baseline_avg": baseline_rss["avg_mb"],
                "current_p95": current_rss["p95_mb"],
                "baseline_p95": baseline_rss["p95_mb"],
            }

            # å›å½’æ£€æµ‹
            if avg_change > 15:  # å¹³å‡å†…å­˜å¢é•¿>15%
                comparison["regressions"].append(f"å†…å­˜ä½¿ç”¨å¢é•¿ {avg_change:.1f}%")
                comparison["regression_detected"] = True
            elif avg_change < -5:  # å†…å­˜å‡å°‘>5%
                comparison["improvements"].append(f"å†…å­˜ä½¿ç”¨å‡å°‘ {-avg_change:.1f}%")

        # CPUå¯¹æ¯”
        if "cpu_usage" in current_stats and "cpu_usage" in baseline_stats:
            current_cpu = current_stats["cpu_usage"]
            baseline_cpu = baseline_stats["cpu_usage"]

            cpu_change = (
                (current_cpu["avg_percent"] - baseline_cpu["avg_percent"])
                / baseline_cpu["avg_percent"]
            ) * 100

            comparison["cpu_comparison"] = {
                "avg_percent_change": cpu_change,
                "current_avg": current_cpu["avg_percent"],
                "baseline_avg": baseline_cpu["avg_percent"],
            }

            if cpu_change > 20:  # CPUä½¿ç”¨å¢é•¿>20%
                comparison["regressions"].append(f"CPUä½¿ç”¨å¢é•¿ {cpu_change:.1f}%")
                comparison["regression_detected"] = True

        return comparison

    except Exception as e:
        return {"error": f"Comparison failed: {e}"}


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å†…å­˜åŸºçº¿é‡‡é›†å·¥å…·")
    parser.add_argument("--duration", type=int, default=1800, help="é‡‡é›†æ—¶é•¿(ç§’ï¼Œé»˜è®¤30åˆ†é’Ÿ)")
    parser.add_argument("--interval", type=int, default=60, help="é‡‡æ ·é—´éš”(ç§’)")
    parser.add_argument("--save", required=True, help="ä¿å­˜åŸºçº¿æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--compare", help="ä¸æŒ‡å®šåŸºçº¿æ–‡ä»¶å¯¹æ¯”")

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

    print("ğŸ“Š M5å†…å­˜åŸºçº¿é‡‡é›†å·¥å…·")
    print(f"â±ï¸ é‡‡é›†æ—¶é•¿: {args.duration}ç§’ ({args.duration//60}åˆ†é’Ÿ)")
    print(f"ğŸ“¸ é‡‡æ ·é—´éš”: {args.interval}ç§’")

    try:
        # åˆ›å»ºåŸºçº¿é‡‡é›†å™¨
        baseline = MemoryBaseline(args.interval)

        # é‡‡é›†åŸºçº¿æ•°æ®
        baseline_data = await baseline.collect_baseline(args.duration)

        # ä¿å­˜åŸºçº¿
        baseline.save_baseline(args.save)

        # å¯¹æ¯”ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.compare and os.path.exists(args.compare):
            print("\nğŸ” ä¸åŸºçº¿å¯¹æ¯”...")
            comparison = compare_with_baseline(baseline_data, args.compare)

            if "error" not in comparison:
                print(
                    f"ğŸ“ˆ å†…å­˜å˜åŒ–: {comparison['memory_comparison'].get('avg_mb_change', 0):+.1f}%"
                )
                print(
                    f"ğŸ–¥ï¸ CPUå˜åŒ–: {comparison['cpu_comparison'].get('avg_percent_change', 0):+.1f}%"
                )

                if comparison["regression_detected"]:
                    print("âš ï¸ æ£€æµ‹åˆ°æ€§èƒ½å›å½’:")
                    for regression in comparison["regressions"]:
                        print(f"   {regression}")

                if comparison["improvements"]:
                    print("âœ… æ£€æµ‹åˆ°æ€§èƒ½æ”¹è¿›:")
                    for improvement in comparison["improvements"]:
                        print(f"   {improvement}")

        print(f"\nğŸ‰ åŸºçº¿é‡‡é›†å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {args.save}")

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ åŸºçº¿é‡‡é›†å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
