#!/usr/bin/env python3
"""
W4 24å°æ—¶å†…å­˜å‹åŠ›æµ‹è¯•
W4 24-Hour Memory Stress Test

é«˜è´Ÿè½½ä¸‹ç³»ç»Ÿç¨³å®šæ€§éªŒè¯ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨ã€GCæ€§èƒ½ã€å»¶è¿ŸæŒ‡æ ‡
"""

import argparse
import asyncio
import gc
import json
import logging
import os
import random
import sys
import time
import traceback
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from typing import Dict, List

# uvloop ä¼˜åŒ–ï¼šç”¨Cå®ç°çš„äº‹ä»¶å¾ªç¯
try:
    import uvloop

    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
    print("âœ… å¯ç”¨ uvloop äº‹ä»¶å¾ªç¯ä¼˜åŒ–")
except ImportError:
    print("âš ï¸ uvloop æœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤äº‹ä»¶å¾ªç¯")

# ç¯å¢ƒå˜é‡é…ç½®
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
GC_THRESH = os.getenv("GC_THRESH", "900,20,10")
PG_FLUSH_INTERVAL = int(os.getenv("PG_FLUSH_INTERVAL", "10"))

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../.."))

# å¯¼å…¥ GC é…ç½®
try:
    from config.gc_settings import apply_optimal_gc_config
except ImportError:

    def apply_optimal_gc_config():
        """å¤‡ç”¨ GC é…ç½®ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡GC_THRESH"""
        thresholds = list(map(int, GC_THRESH.split(",")))
        gc.set_threshold(*thresholds)
        print(f"âœ… åº”ç”¨ç¯å¢ƒå˜é‡ GC é…ç½®: {tuple(thresholds)}")


@dataclass
class W4Metrics:
    """W4 å‹åŠ›æµ‹è¯•æŒ‡æ ‡"""

    timestamp: str
    signals_processed: int
    avg_latency_ms: float
    p95_latency_ms: float
    rss_mb: float
    gc_pause_ms: float
    gc_gen0_count: int
    gc_gen1_count: int
    gc_gen2_count: int
    cpu_percent: float
    alerts_count: int


class W4StressTest:
    """W4 24å°æ—¶å‹åŠ›æµ‹è¯•å™¨"""

    def __init__(
        self,
        run_name: str = "W4-stress",
        signals_target: int = 20000,
        duration_hours: int = 24,
        max_rss_mb: int = 40,
    ):
        self.run_name = run_name
        self.signals_target = signals_target
        self.duration_hours = duration_hours
        self.max_rss_mb = max_rss_mb

        self.start_time = datetime.now()
        self.end_time = self.start_time + timedelta(hours=duration_hours)

        # æŒ‡æ ‡æ”¶é›†
        self.signals_processed = 0
        self.latencies = []
        self.metrics_history: List[W4Metrics] = []
        self.alerts = []

        # çŠ¶æ€æ–‡ä»¶
        self.status_file = f"output/w4_stress_status_{run_name}.json"

        # æ—¥å¿—é…ç½®
        self.logger = logging.getLogger(__name__)

        # è¿è¡ŒçŠ¶æ€
        self.running = False
        self.failed = False
        self.failure_reason = ""

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = f"logs/w4_stress_{self.run_name}.log"
        os.makedirs(os.path.dirname(log_file), exist_ok=True)

        # å°†å­—ç¬¦ä¸²çº§åˆ«è½¬æ¢ä¸ºloggingå¸¸é‡
        level_map = {
            "DEBUG": logging.DEBUG,
            "INFO": logging.INFO,
            "WARN": logging.WARNING,
            "WARNING": logging.WARNING,
            "ERROR": logging.ERROR,
            "CRITICAL": logging.CRITICAL,
        }
        log_level = level_map.get(LOG_LEVEL, logging.INFO)

        logging.basicConfig(
            level=log_level,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[logging.FileHandler(log_file), logging.StreamHandler()],
        )

        if LOG_LEVEL != "INFO":
            print(f"âœ… æ—¥å¿—çº§åˆ«è®¾ä¸º: {LOG_LEVEL}")

    def simulate_trading_signal(self) -> float:
        """æ¨¡æ‹Ÿäº¤æ˜“ä¿¡å·å¤„ç†ï¼Œè¿”å›å»¶è¿Ÿ(ms)"""
        start_time = time.perf_counter()

        # æ¨¡æ‹Ÿè®¡ç®—å¯†é›†å‹æ“ä½œ - ä¼˜åŒ–ï¼šå‡å°‘å¾ªç¯æ¬¡æ•°
        data = []
        for i in range(random.randint(30, 100)):  # ä»50-200å‡å°‘åˆ°30-100
            # æ¨¡æ‹Ÿä»·æ ¼è®¡ç®—
            price = random.uniform(30000, 70000)
            volume = random.uniform(0.1, 10.0)

            # æ¨¡æ‹ŸæŠ€æœ¯æŒ‡æ ‡è®¡ç®— - ä¼˜åŒ–ï¼šå‡å°‘SMAè®¡ç®—ç‚¹æ•°
            sma = (
                sum([random.uniform(price * 0.95, price * 1.05) for _ in range(10)]) / 10
            )  # ä»20å‡å°‘åˆ°10

            # æ¨¡æ‹Ÿå†³ç­–é€»è¾‘
            signal = "BUY" if price < sma * 0.98 else "SELL" if price > sma * 1.02 else "HOLD"

            # ä½¿ç”¨å…ƒç»„æ›¿ä»£å­—å…¸å‡å°‘å¼€é”€
            data.append((price, volume, sma, signal, time.time()))

        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ - ä¼˜åŒ–ï¼šå‡å°‘ç­‰å¾…æ—¶é—´
        await_time = random.uniform(0.0005, 0.002)  # ä»0.001-0.005å‡å°‘åˆ°0.0005-0.002
        time.sleep(await_time)

        end_time = time.perf_counter()
        latency_ms = (end_time - start_time) * 1000

        return latency_ms

    def get_system_metrics(self) -> Dict:
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        try:
            import psutil

            # è·å–å½“å‰è¿›ç¨‹
            process = psutil.Process()

            # å†…å­˜ä½¿ç”¨
            memory_info = process.memory_info()
            rss_mb = memory_info.rss / 1024 / 1024

            # CPU ä½¿ç”¨
            cpu_percent = process.cpu_percent()

            # GC ç»Ÿè®¡
            gc_stats = gc.get_stats()
            gc_counts = gc.get_count()

            return {
                "rss_mb": rss_mb,
                "cpu_percent": cpu_percent,
                "gc_gen0": gc_counts[0],
                "gc_gen1": gc_counts[1],
                "gc_gen2": gc_counts[2],
                "gc_collections": [s["collections"] for s in gc_stats],
            }
        except Exception as e:
            self.logger.warning(f"è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return {"rss_mb": 0, "cpu_percent": 0, "gc_gen0": 0, "gc_gen1": 0, "gc_gen2": 0}

    def check_thresholds(self, metrics: Dict) -> List[str]:
        """æ£€æŸ¥é˜ˆå€¼"""
        alerts = []

        # RSS æ£€æŸ¥
        if metrics["rss_mb"] > self.max_rss_mb:
            alert = f"RSS {metrics['rss_mb']:.1f}MB è¶…è¿‡ {self.max_rss_mb}MB é˜ˆå€¼"
            alerts.append(alert)
            self.logger.warning(alert)

        # å»¶è¿Ÿæ£€æŸ¥ (P95 > 6ms)
        if len(self.latencies) >= 20:
            p95_latency = sorted(self.latencies)[-len(self.latencies) // 20]
            if p95_latency > 6.0:
                alert = f"P95å»¶è¿Ÿ {p95_latency:.2f}ms è¶…è¿‡ 6ms é˜ˆå€¼"
                alerts.append(alert)
                self.logger.warning(alert)

        return alerts

    def update_status(self, status_update: Dict):
        """æ›´æ–°çŠ¶æ€æ–‡ä»¶"""
        status = {
            "run_name": self.run_name,
            "status": "running" if self.running else ("failed" if self.failed else "completed"),
            "start_time": self.start_time.isoformat(),
            "signals_processed": self.signals_processed,
            "target_signals": self.signals_target,
            "duration_hours": self.duration_hours,
            "progress_percent": (
                (self.signals_processed / self.signals_target * 100)
                if self.signals_target > 0
                else 0
            ),
            "last_update": datetime.now().isoformat(),
        }

        status.update(status_update)

        if self.failed:
            status["failure_reason"] = self.failure_reason

        os.makedirs(os.path.dirname(self.status_file), exist_ok=True)
        with open(self.status_file, "w") as f:
            json.dump(status, f, indent=2, default=str)

    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡å†å²"""
        metrics_file = f"output/w4_stress_metrics_{self.run_name}_{int(time.time())}.json"

        report = {
            "test_info": {
                "run_name": self.run_name,
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_hours": self.duration_hours,
                "signals_target": self.signals_target,
                "signals_processed": self.signals_processed,
            },
            "performance": {
                "avg_latency_ms": (
                    sum(self.latencies) / len(self.latencies) if self.latencies else 0
                ),
                "p95_latency_ms": (
                    sorted(self.latencies)[-len(self.latencies) // 20]
                    if len(self.latencies) >= 20
                    else 0
                ),
                "p99_latency_ms": (
                    sorted(self.latencies)[-len(self.latencies) // 100]
                    if len(self.latencies) >= 100
                    else 0
                ),
                "max_latency_ms": max(self.latencies) if self.latencies else 0,
                "min_latency_ms": min(self.latencies) if self.latencies else 0,
            },
            "metrics_history": [asdict(m) for m in self.metrics_history],
            "alerts": self.alerts,
            "validation": {
                "completed": self.signals_processed >= self.signals_target,
                "rss_under_limit": all(m.rss_mb <= self.max_rss_mb for m in self.metrics_history),
                "latency_under_limit": all(m.p95_latency_ms <= 6.0 for m in self.metrics_history),
                "no_critical_alerts": len([a for a in self.alerts if "critical" in a.lower()]) == 0,
            },
        }

        os.makedirs(os.path.dirname(metrics_file), exist_ok=True)
        with open(metrics_file, "w") as f:
            json.dump(report, f, indent=2, default=str)

        self.logger.info(f"ğŸ“Š æŒ‡æ ‡æŠ¥å‘Šå·²ä¿å­˜: {metrics_file}")
        return metrics_file

    async def run_stress_test(self):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        self.logger.info("ğŸ”¥ W4 å‹åŠ›æµ‹è¯•å¯åŠ¨")
        self.logger.info(f"ğŸ“‹ è¿è¡Œåç§°: {self.run_name}")
        self.logger.info(f"ğŸ¯ ç›®æ ‡ä¿¡å·: {self.signals_target}")
        self.logger.info(f"â° æ—¶é•¿: {self.duration_hours} å°æ—¶")
        self.logger.info(f"ğŸ“Š RSSé™åˆ¶: {self.max_rss_mb} MB")

        # è®¡ç®—çœŸå®ä¿¡å·é¢‘ç‡ (signals/second)
        target_frequency = self.signals_target / (self.duration_hours * 3600)
        signal_interval = 1.0 / target_frequency if target_frequency > 0 else 1.0

        self.logger.info(
            f"ğŸ“¡ ä¿¡å·é¢‘ç‡: {target_frequency:.3f} æ¡/ç§’ (é—´éš”: {signal_interval:.1f}ç§’)"
        )

        # åº”ç”¨ GC é…ç½®
        apply_optimal_gc_config()

        self.running = True
        self.update_status({"status": "running"})

        try:
            while self.signals_processed < self.signals_target and datetime.now() < self.end_time:
                # è®°å½•ä¿¡å·å¤„ç†å¼€å§‹æ—¶é—´
                signal_start = time.perf_counter()

                # å¤„ç†ä¿¡å·
                latency = self.simulate_trading_signal()
                self.latencies.append(latency)
                self.signals_processed += 1

                # å®šæœŸæ”¶é›†æŒ‡æ ‡
                if self.signals_processed % 100 == 0:
                    system_metrics = self.get_system_metrics()

                    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                    recent_latencies = (
                        self.latencies[-100:] if len(self.latencies) >= 100 else self.latencies
                    )
                    avg_latency = sum(recent_latencies) / len(recent_latencies)
                    p95_latency = (
                        sorted(recent_latencies)[-len(recent_latencies) // 20]
                        if len(recent_latencies) >= 20
                        else avg_latency
                    )

                    # åˆ›å»ºæŒ‡æ ‡è®°å½•
                    metrics = W4Metrics(
                        timestamp=datetime.now().isoformat(),
                        signals_processed=self.signals_processed,
                        avg_latency_ms=avg_latency,
                        p95_latency_ms=p95_latency,
                        rss_mb=system_metrics["rss_mb"],
                        gc_pause_ms=0,  # TODO: å®é™…æµ‹é‡ GC æš‚åœ
                        gc_gen0_count=system_metrics["gc_gen0"],
                        gc_gen1_count=system_metrics["gc_gen1"],
                        gc_gen2_count=system_metrics["gc_gen2"],
                        cpu_percent=system_metrics["cpu_percent"],
                        alerts_count=len(self.alerts),
                    )

                    self.metrics_history.append(metrics)

                    # æ£€æŸ¥é˜ˆå€¼
                    new_alerts = self.check_thresholds(system_metrics)
                    self.alerts.extend(new_alerts)

                    # æ›´æ–°çŠ¶æ€
                    self.update_status(
                        {"current_metrics": asdict(metrics), "recent_alerts": new_alerts}
                    )

                    # è¿›åº¦æ—¥å¿—
                    progress = self.signals_processed / self.signals_target * 100
                    elapsed_hours = (datetime.now() - self.start_time).total_seconds() / 3600
                    self.logger.info(
                        f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% ({self.signals_processed}/{self.signals_target}), "
                        f"ç”¨æ—¶: {elapsed_hours:.1f}h, P95: {p95_latency:.2f}ms, RSS: {system_metrics['rss_mb']:.1f}MB"
                    )

                # ğŸ¯ å…³é”®æ”¹åŠ¨ï¼šæŒ‰çœŸå®é¢‘ç‡æ§åˆ¶ä¿¡å·å‘é€
                signal_process_time = time.perf_counter() - signal_start
                sleep_time = signal_interval - signal_process_time

                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                else:
                    # å¦‚æœå¤„ç†æ—¶é—´è¶…è¿‡é—´éš”ï¼Œæ¯10ä¸ªä¿¡å·å°æ†©ä¸€ä¸‹é¿å…CPU 100%
                    if self.signals_processed % 10 == 0:
                        await asyncio.sleep(0.001)

                # ğŸš€ åˆ†ç‰‡ä¼‘çœ ä¼˜åŒ–ï¼šæ¯300ä¸ªä¿¡å·è®©äº‹ä»¶å¾ªç¯å–˜æ¯50ms
                if self.signals_processed % 300 == 0:
                    await asyncio.sleep(0.05)
                    self.logger.debug(f"ğŸ”„ åˆ†ç‰‡ä¼‘çœ : {self.signals_processed}ä¿¡å·å®Œæˆ")

            self.logger.info("âœ… W4 å‹åŠ›æµ‹è¯•å®Œæˆ")
            self.logger.info(f"ğŸ“Š å¤„ç†ä¿¡å·: {self.signals_processed}/{self.signals_target}")
            self.logger.info(
                f"â° ç”¨æ—¶: {(datetime.now() - self.start_time).total_seconds() / 3600:.1f} å°æ—¶"
            )

        except Exception as e:
            self.failed = True
            self.failure_reason = str(e)
            self.logger.error(f"âŒ W4 å‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())

        finally:
            self.running = False

            # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
            report_file = self.save_metrics()

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            final_status = {
                "status": "completed" if not self.failed else "failed",
                "completion_time": datetime.now().isoformat(),
                "final_signals": self.signals_processed,
                "report_file": report_file,
            }

            if not self.failed:
                # éªŒæ”¶æ£€æŸ¥
                validation = {
                    "signals_completed": self.signals_processed >= self.signals_target,
                    "rss_under_limit": all(
                        m.rss_mb <= self.max_rss_mb for m in self.metrics_history
                    ),
                    "latency_acceptable": all(
                        m.p95_latency_ms <= 6.0 for m in self.metrics_history
                    ),
                    "no_critical_alerts": len([a for a in self.alerts if "critical" in a.lower()])
                    == 0,
                }

                passed = all(validation.values())
                final_status["validation"] = validation
                final_status["passed"] = passed

                if passed:
                    self.logger.info("ğŸ‰ W4 å‹åŠ›æµ‹è¯•éªŒæ”¶é€šè¿‡!")
                else:
                    self.logger.warning("âš ï¸ W4 å‹åŠ›æµ‹è¯•éƒ¨åˆ†æŒ‡æ ‡æœªè¾¾æ ‡")

            self.update_status(final_status)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="W4 24å°æ—¶å‹åŠ›æµ‹è¯•")
    parser.add_argument("--run-name", type=str, default="W4-stress", help="è¿è¡Œåç§°æ ‡ç­¾")
    parser.add_argument("--signals", type=int, default=20000, help="ç›®æ ‡ä¿¡å·å¤„ç†æ•°é‡")
    parser.add_argument("--duration", type=str, default="24h", help="æµ‹è¯•æ—¶é•¿ (ä¾‹: 24h, 1d)")
    parser.add_argument("--max-rss", type=int, default=40, help="æœ€å¤§ RSS é™åˆ¶ (MB)")

    args = parser.parse_args()

    # è§£ææ—¶é•¿
    duration_str = args.duration.lower()
    if duration_str.endswith("h"):
        duration_hours = int(duration_str[:-1])
    elif duration_str.endswith("d"):
        duration_hours = int(duration_str[:-1]) * 24
    else:
        duration_hours = int(duration_str)  # å‡è®¾æ˜¯å°æ—¶

    # åˆ›å»ºæµ‹è¯•å™¨
    stress_test = W4StressTest(
        run_name=args.run_name,
        signals_target=args.signals,
        duration_hours=duration_hours,
        max_rss_mb=args.max_rss,
    )

    # è®¾ç½®æ—¥å¿—
    stress_test.setup_logging()

    # è¿è¡Œæµ‹è¯•
    await stress_test.run_stress_test()


if __name__ == "__main__":
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs("output", exist_ok=True)
    os.makedirs("logs", exist_ok=True)

    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
