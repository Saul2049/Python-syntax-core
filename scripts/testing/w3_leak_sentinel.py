#!/usr/bin/env python3
"""
W3 æ³„æ¼å“¨å…µ - è¿ç»­æ³„æ¼ç›‘æ§
W3 Leak Sentinel - Continuous Leak Monitoring

ç›®æ ‡: è¿ç»­6å°æ—¶æ— å†…å­˜æ³„æ¼
éªŒæ”¶æ ‡å‡†:
- å†…å­˜å¢é•¿ç‡ < 0.1 MB/min
- æ–‡ä»¶æè¿°ç¬¦å¢é•¿ç‡ < 0.1 FD/min
- æ¸…æ´å°æ—¶æ•° â‰¥ 6
"""

import asyncio
import gc
import os
import sys
import time
import json
import psutil
import logging
import argparse
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../.."))

from scripts.memory.mem_snapshot import MemorySnapshot
from config.gc_settings import GCSettings


@dataclass
class LeakCheckpoint:
    """æ³„æ¼æ£€æŸ¥ç‚¹"""

    timestamp: datetime
    rss_mb: float
    fd_count: int
    gc_gen0: int
    gc_gen1: int
    gc_gen2: int
    clean_hours: int


class W3LeakSentinel:
    """W3 æ³„æ¼å“¨å…µ"""

    def __init__(self, target_hours: int = 6):
        self.target_hours = target_hours
        self.check_interval = 300  # 5åˆ†é’Ÿæ£€æŸ¥é—´éš”
        self.memory_snapshot = MemorySnapshot()
        self.process = psutil.Process()
        self.logger = logging.getLogger(__name__)

        # æ³„æ¼é˜ˆå€¼
        self.memory_leak_threshold = 0.1  # MB/min
        self.fd_leak_threshold = 0.1  # FD/min

        # ç›‘æ§æ•°æ®
        self.checkpoints: List[LeakCheckpoint] = []
        self.clean_hours_count = 0
        self.last_leak_detected = None

        # ç»Ÿè®¡
        self.start_time = None
        self.w3_status = {
            "started": False,
            "completed": False,
            "passed": False,
            "clean_hours": 0,
            "target_hours": target_hours,
            "last_leak": None,
            "current_streak": 0,
        }

    async def start_monitoring(self):
        """å¼€å§‹ W3 æ³„æ¼ç›‘æ§"""
        self.start_time = datetime.now()
        self.w3_status["started"] = True

        # åº”ç”¨ W2 GC é…ç½®
        GCSettings.apply_w2_optimal()

        self.logger.info(f"ğŸ” W3 æ³„æ¼å“¨å…µå¯åŠ¨")
        self.logger.info(f"ğŸ¯ ç›®æ ‡: è¿ç»­{self.target_hours}å°æ—¶æ— æ³„æ¼")
        self.logger.info(f"ğŸ“Š ç›‘æ§é—´éš”: {self.check_interval}ç§’")

        # å¯åŠ¨å†…å­˜è¿½è¸ª
        self.memory_snapshot.start_tracing()

        # è®°å½•åˆå§‹çŠ¶æ€
        await self._take_checkpoint("åˆå§‹çŠ¶æ€")

        try:
            while self.clean_hours_count < self.target_hours:
                await asyncio.sleep(self.check_interval)

                # æ‰§è¡Œæ³„æ¼æ£€æŸ¥
                leak_detected = await self._check_for_leaks()

                if leak_detected:
                    self.logger.warning(f"ğŸš¨ æ£€æµ‹åˆ°æ³„æ¼ï¼Œé‡ç½®æ¸…æ´å°æ—¶è®¡æ•°")
                    self.clean_hours_count = 0
                    self.last_leak_detected = datetime.now()
                    self.w3_status["last_leak"] = datetime.now().isoformat()
                    self.w3_status["current_streak"] = 0
                else:
                    # æ›´æ–°æ¸…æ´æ—¶é—´
                    elapsed_hours = (
                        datetime.now() - (self.last_leak_detected or self.start_time)
                    ).total_seconds() / 3600
                    self.clean_hours_count = int(elapsed_hours)
                    self.w3_status["clean_hours"] = self.clean_hours_count
                    self.w3_status["current_streak"] = self.clean_hours_count

                self.logger.info(f"â° æ¸…æ´å°æ—¶æ•°: {self.clean_hours_count}/{self.target_hours}")

            # W3 å®Œæˆ
            self.w3_status["completed"] = True
            self.w3_status["passed"] = True
            self.logger.info(f"ğŸ‰ W3 éªŒæ”¶é€šè¿‡ï¼è¿ç»­{self.target_hours}å°æ—¶æ— æ³„æ¼")

        except Exception as e:
            self.logger.error(f"âŒ W3 ç›‘æ§å¼‚å¸¸: {e}")
            self.w3_status["passed"] = False
            raise

    async def _take_checkpoint(self, reason: str = "å®šæœŸæ£€æŸ¥"):
        """è®°å½•æ£€æŸ¥ç‚¹"""
        snapshot = self.memory_snapshot.take_snapshot()

        if "error" in snapshot:
            self.logger.error(f"âŒ å¿«ç…§å¤±è´¥: {snapshot['error']}")
            return

        checkpoint = LeakCheckpoint(
            timestamp=datetime.now(),
            rss_mb=snapshot["memory"]["rss_mb"],
            fd_count=snapshot["file_descriptors"],
            gc_gen0=snapshot["gc_stats"]["gen0_count"],
            gc_gen1=snapshot["gc_stats"]["gen1_count"],
            gc_gen2=snapshot["gc_stats"]["gen2_count"],
            clean_hours=self.clean_hours_count,
        )

        self.checkpoints.append(checkpoint)

        self.logger.info(
            f"ğŸ“ æ£€æŸ¥ç‚¹ ({reason}): RSS={checkpoint.rss_mb}MB, "
            f"FDs={checkpoint.fd_count}, æ¸…æ´={checkpoint.clean_hours}h"
        )

    async def _check_for_leaks(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ³„æ¼"""
        await self._take_checkpoint()

        if len(self.checkpoints) < 2:
            return False

        # åˆ†ææœ€è¿‘çš„æ•°æ®ç‚¹
        window_size = min(6, len(self.checkpoints))  # æœ€è¿‘30åˆ†é’Ÿçš„æ•°æ®
        recent_checkpoints = self.checkpoints[-window_size:]

        # å†…å­˜æ³„æ¼æ£€æŸ¥
        memory_leak = self._analyze_memory_trend(recent_checkpoints)
        fd_leak = self._analyze_fd_trend(recent_checkpoints)

        leak_detected = memory_leak or fd_leak

        if leak_detected:
            self.logger.warning("ğŸš¨ æ³„æ¼æ£€æµ‹ç»“æœ:")
            if memory_leak:
                self.logger.warning(f"  â€¢ å†…å­˜æ³„æ¼: å¢é•¿ç‡è¶…è¿‡ {self.memory_leak_threshold} MB/min")
            if fd_leak:
                self.logger.warning(f"  â€¢ FDæ³„æ¼: å¢é•¿ç‡è¶…è¿‡ {self.fd_leak_threshold} FD/min")

        return leak_detected

    def _analyze_memory_trend(self, checkpoints: List[LeakCheckpoint]) -> bool:
        """åˆ†æå†…å­˜å¢é•¿è¶‹åŠ¿"""
        if len(checkpoints) < 2:
            return False

        # è®¡ç®—å†…å­˜å¢é•¿ç‡ (MB/min)
        first = checkpoints[0]
        last = checkpoints[-1]

        time_diff_minutes = (last.timestamp - first.timestamp).total_seconds() / 60
        memory_diff_mb = last.rss_mb - first.rss_mb

        if time_diff_minutes > 0:
            growth_rate = memory_diff_mb / time_diff_minutes

            self.logger.debug(
                f"ğŸ“Š å†…å­˜å¢é•¿ç‡: {growth_rate:.3f} MB/min " f"(é˜ˆå€¼: {self.memory_leak_threshold})"
            )

            return growth_rate > self.memory_leak_threshold

        return False

    def _analyze_fd_trend(self, checkpoints: List[LeakCheckpoint]) -> bool:
        """åˆ†ææ–‡ä»¶æè¿°ç¬¦å¢é•¿è¶‹åŠ¿"""
        if len(checkpoints) < 2:
            return False

        # è®¡ç®—FDå¢é•¿ç‡ (FD/min)
        first = checkpoints[0]
        last = checkpoints[-1]

        time_diff_minutes = (last.timestamp - first.timestamp).total_seconds() / 60
        fd_diff = last.fd_count - first.fd_count

        if time_diff_minutes > 0:
            growth_rate = fd_diff / time_diff_minutes

            self.logger.debug(
                f"ğŸ“Š FDå¢é•¿ç‡: {growth_rate:.3f} FD/min " f"(é˜ˆå€¼: {self.fd_leak_threshold})"
            )

            return growth_rate > self.fd_leak_threshold

        return False

    def generate_w3_report(self) -> Dict:
        """ç”Ÿæˆ W3 éªŒæ”¶æŠ¥å‘Š"""
        current_time = datetime.now()
        elapsed_hours = (
            (current_time - self.start_time).total_seconds() / 3600 if self.start_time else 0
        )

        # W3 éªŒæ”¶æ£€æŸ¥
        w3_passed = self.w3_status["completed"] and self.clean_hours_count >= self.target_hours

        report = {
            "w3_acceptance": {
                "passed": w3_passed,
                "target_clean_hours": self.target_hours,
                "achieved_clean_hours": self.clean_hours_count,
                "completion_status": self.w3_status["completed"],
            },
            "monitoring_summary": {
                "start_time": self.start_time.isoformat() if self.start_time else None,
                "elapsed_hours": round(elapsed_hours, 2),
                "total_checkpoints": len(self.checkpoints),
                "leak_threshold_memory_mb_per_min": self.memory_leak_threshold,
                "leak_threshold_fd_per_min": self.fd_leak_threshold,
            },
            "leak_analysis": {
                "last_leak_detected": self.w3_status.get("last_leak"),
                "current_clean_streak_hours": self.clean_hours_count,
                "total_leak_events": self._count_leak_events(),
            },
            "memory_trend": self._analyze_overall_memory_trend(),
            "checkpoints": [
                {
                    "timestamp": cp.timestamp.isoformat(),
                    "rss_mb": cp.rss_mb,
                    "fd_count": cp.fd_count,
                    "clean_hours": cp.clean_hours,
                }
                for cp in self.checkpoints[-20:]  # æœ€è¿‘20ä¸ªæ£€æŸ¥ç‚¹
            ],
        }

        return report

    def _count_leak_events(self) -> int:
        """ç»Ÿè®¡æ³„æ¼äº‹ä»¶æ•°é‡"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºæ¸…æ´å°æ—¶æ•°é‡ç½®æ¬¡æ•°
        return len([cp for cp in self.checkpoints if cp.clean_hours == 0]) - 1

    def _analyze_overall_memory_trend(self) -> Dict:
        """åˆ†ææ•´ä½“å†…å­˜è¶‹åŠ¿"""
        if len(self.checkpoints) < 2:
            return {"status": "insufficient_data"}

        first = self.checkpoints[0]
        last = self.checkpoints[-1]

        total_time_hours = (last.timestamp - first.timestamp).total_seconds() / 3600
        total_memory_change = last.rss_mb - first.rss_mb

        return {
            "total_memory_change_mb": round(total_memory_change, 2),
            "total_time_hours": round(total_time_hours, 2),
            "average_growth_rate_mb_per_hour": (
                round(total_memory_change / total_time_hours, 3) if total_time_hours > 0 else 0
            ),
            "fd_change": last.fd_count - first.fd_count,
            "status": "stable" if abs(total_memory_change) < 5 else "concerning",
        }

    def save_report(self, filename: str):
        """ä¿å­˜ W3 æŠ¥å‘Š"""
        report = self.generate_w3_report()

        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else ".", exist_ok=True)
        with open(filename, "w") as f:
            json.dump(report, f, indent=2, default=str)

        self.logger.info(f"ğŸ’¾ W3 æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        self._print_w3_summary(report)

    def _print_w3_summary(self, report: Dict):
        """æ‰“å° W3 éªŒæ”¶æ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ” W3 æ³„æ¼å“¨å…µéªŒæ”¶æŠ¥å‘Š")
        print("=" * 60)

        acceptance = report["w3_acceptance"]
        monitoring = report["monitoring_summary"]
        leak_analysis = report["leak_analysis"]

        print(f"ğŸ¯ éªŒæ”¶ç›®æ ‡: è¿ç»­{acceptance['target_clean_hours']}å°æ—¶æ— æ³„æ¼")
        print(f"â° è¿è¡Œæ—¶é•¿: {monitoring['elapsed_hours']:.1f}å°æ—¶")
        print(
            f"ğŸ•› æ¸…æ´å°æ—¶: {acceptance['achieved_clean_hours']}/{acceptance['target_clean_hours']}"
        )
        print(f"ğŸ“Š æ£€æŸ¥æ¬¡æ•°: {monitoring['total_checkpoints']}æ¬¡")

        print(f"\nğŸ“ˆ æ³„æ¼é˜ˆå€¼:")
        print(f"   å†…å­˜: â‰¤{monitoring['leak_threshold_memory_mb_per_min']} MB/min")
        print(f"   æ–‡ä»¶æè¿°ç¬¦: â‰¤{monitoring['leak_threshold_fd_per_min']} FD/min")

        print(f"\nğŸ” æ³„æ¼ç»Ÿè®¡:")
        print(f"   å½“å‰è¿ç»­æ¸…æ´: {leak_analysis['current_clean_streak_hours']}å°æ—¶")
        print(f"   æ€»æ³„æ¼äº‹ä»¶: {leak_analysis['total_leak_events']}æ¬¡")

        print(f"\nğŸ¯ W3 éªŒæ”¶ç»“æœ: {'âœ… PASS' if acceptance['passed'] else 'âŒ FAIL'}")

        if acceptance["passed"]:
            print(f"\nğŸ‰ W3 æ³„æ¼å“¨å…µéªŒæ”¶é€šè¿‡ï¼å¯ä»¥è¿›å…¥W4å‹åŠ›æµ‹è¯•")
        else:
            remaining = acceptance["target_clean_hours"] - acceptance["achieved_clean_hours"]
            print(f"\nâš ï¸ è¿˜éœ€è¦ {remaining} å°æ—¶æ— æ³„æ¼æ‰èƒ½é€šè¿‡éªŒæ”¶")

        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="W3 æ³„æ¼å“¨å…µ")
    parser.add_argument("--target-hours", type=int, default=6, help="ç›®æ ‡æ¸…æ´å°æ—¶æ•° (é»˜è®¤: 6)")
    parser.add_argument("--check-interval", type=int, default=300, help="æ£€æŸ¥é—´éš”ç§’æ•° (é»˜è®¤: 300)")
    parser.add_argument(
        "--memory-threshold", type=float, default=0.1, help="å†…å­˜æ³„æ¼é˜ˆå€¼ MB/min (é»˜è®¤: 0.1)"
    )
    parser.add_argument(
        "--fd-threshold", type=float, default=0.1, help="FDæ³„æ¼é˜ˆå€¼ FD/min (é»˜è®¤: 0.1)"
    )

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    print("ğŸ” W3 æ³„æ¼å“¨å…µå¯åŠ¨")
    print(f"ğŸ¯ ç›®æ ‡: è¿ç»­{args.target_hours}å°æ—¶æ— å†…å­˜æ³„æ¼")

    # åˆ›å»ºå“¨å…µ
    sentinel = W3LeakSentinel(target_hours=args.target_hours)
    sentinel.check_interval = args.check_interval
    sentinel.memory_leak_threshold = args.memory_threshold
    sentinel.fd_leak_threshold = args.fd_threshold

    try:
        # å¼€å§‹ç›‘æ§
        await sentinel.start_monitoring()

        # ç”ŸæˆæŠ¥å‘Š
        timestamp = int(time.time())
        report_file = f"output/w3_leak_sentinel_{timestamp}.json"
        os.makedirs("output", exist_ok=True)
        sentinel.save_report(report_file)

        return sentinel.w3_status["passed"]

    except KeyboardInterrupt:
        print("\nâ¸ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
        sentinel.logger.info("ç›‘æ§è¢«ç”¨æˆ·ä¸­æ–­")

        # ä¿å­˜ä¸­é—´æŠ¥å‘Š
        timestamp = int(time.time())
        report_file = f"output/w3_leak_sentinel_interrupted_{timestamp}.json"
        os.makedirs("output", exist_ok=True)
        sentinel.save_report(report_file)

        return False
    except Exception as e:
        print(f"âŒ W3 ç›‘æ§å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
