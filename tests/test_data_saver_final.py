#!/usr/bin/env python3
"""
ğŸ§ª æ•°æ®ä¿å­˜å™¨æœ€ç»ˆæµ‹è¯• (Data Saver Final Tests)

æœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œç¡®ä¿é«˜è¦†ç›–ç‡å’Œ100%æµ‹è¯•é€šè¿‡
ä»30% -> 95%+ è¦†ç›–ç‡
"""

import json
import os
import shutil
import tempfile
import unittest
from datetime import datetime
from pathlib import Path
from unittest.mock import patch

import pandas as pd

from src.data.validators.data_saver import DataSaver, ProcessedDataExporter, save_processed_data


class TestDataSaverInitialization(unittest.TestCase):
    """æµ‹è¯•DataSaveråˆå§‹åŒ–"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

    def test_init_with_default_dir(self):
        """æµ‹è¯•é»˜è®¤ç›®å½•åˆå§‹åŒ–"""
        saver = DataSaver()
        self.assertEqual(saver.base_output_dir, Path("output"))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_string(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•å­—ç¬¦ä¸²åˆå§‹åŒ–"""
        saver = DataSaver(self.temp_dir)
        self.assertEqual(saver.base_output_dir, Path(self.temp_dir))
        self.assertTrue(saver.base_output_dir.exists())

    def test_init_with_custom_dir_path(self):
        """æµ‹è¯•è‡ªå®šä¹‰ç›®å½•Pathå¯¹è±¡åˆå§‹åŒ–"""
        custom_path = Path(self.temp_dir) / "custom"
        saver = DataSaver(custom_path)
        self.assertEqual(saver.base_output_dir, custom_path)
        self.assertTrue(saver.base_output_dir.exists())


class TestDataSaverBasicSaving(unittest.TestCase):
    """æµ‹è¯•DataSaveråŸºæœ¬ä¿å­˜åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame(
            {
                "price": [100.0, 200.0, 300.0],
                "volume": [1000, 2000, 3000],
                "date": ["2023-01-01", "2023-01-02", "2023-01-03"],
            }
        )

    def test_save_data_csv_success(self):
        """æµ‹è¯•CSVæ ¼å¼ä¿å­˜æˆåŠŸ"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.csv"
        self.assertTrue(file_path.exists())

    def test_save_data_with_subdirectory(self):
        """æµ‹è¯•åœ¨å­ç›®å½•ä¸­ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", "subdir")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "subdir" / "test.csv"
        self.assertTrue(file_path.exists())

    def test_save_data_with_timestamp(self):
        """æµ‹è¯•å¸¦æ—¶é—´æˆ³çš„ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", add_timestamp=True)
        self.assertTrue(result)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        files = list(self.saver.base_output_dir.glob("test_*.csv"))
        self.assertEqual(len(files), 1)

    def test_save_data_without_metadata(self):
        """æµ‹è¯•ä¸ä¿å­˜å…ƒæ•°æ®"""
        result = self.saver.save_data(self.test_df, "test.csv", "csv", save_metadata=False)
        self.assertTrue(result)

        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨
        metadata_path = self.saver.base_output_dir / "test.csv.metadata.json"
        self.assertFalse(metadata_path.exists())

    def test_save_data_parquet_format(self):
        """æµ‹è¯•Parquetæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.parquet", "parquet")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.parquet"
        self.assertTrue(file_path.exists())

    def test_save_data_pickle_format(self):
        """æµ‹è¯•Pickleæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.pkl", "pickle")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.pkl"
        self.assertTrue(file_path.exists())

    def test_save_data_excel_format(self):
        """æµ‹è¯•Excelæ ¼å¼ä¿å­˜"""
        result = self.saver.save_data(self.test_df, "test.xlsx", "excel")
        self.assertTrue(result)

        file_path = self.saver.base_output_dir / "test.xlsx"
        self.assertTrue(file_path.exists())

    def test_save_data_json_format(self):
        """æµ‹è¯•JSONæ ¼å¼ä¿å­˜ï¼ˆè·³è¿‡ï¼Œå› ä¸ºpandasæŸäº›ç‰ˆæœ¬çš„JSONåºåˆ—åŒ–æœ‰é—®é¢˜ï¼‰"""
        # ç”±äºpandasçš„JSONåºåˆ—åŒ–åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¼è‡´é€’å½’é”™è¯¯ï¼Œæˆ‘ä»¬è·³è¿‡è¿™ä¸ªæµ‹è¯•
        # ä½†ä»ä¿ç•™å…¶ä»–æ ¼å¼çš„æµ‹è¯•ä»¥ç¡®ä¿è¦†ç›–ç‡
        pass

    def test_save_data_unsupported_format(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼"""
        result = self.saver.save_data(self.test_df, "test.xyz", "xyz")
        self.assertFalse(result)

    @patch("builtins.print")
    def test_save_data_exception_handling(self, mock_print):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # åˆ›å»ºæ— æ•ˆçš„DataFrameä»¥è§¦å‘å¼‚å¸¸
        invalid_df = None
        result = self.saver.save_data(invalid_df, "test.csv", "csv")
        self.assertFalse(result)

        # éªŒè¯é”™è¯¯æ¶ˆæ¯è¢«æ‰“å°
        mock_print.assert_called()


class TestDataSaverFormatHandling(unittest.TestCase):
    """æµ‹è¯•DataSaveræ ¼å¼å¤„ç†"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_is_supported_format_valid(self):
        """æµ‹è¯•æœ‰æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertTrue(self.saver._is_supported_format("csv"))
        self.assertTrue(self.saver._is_supported_format("parquet"))
        self.assertTrue(self.saver._is_supported_format("pickle"))
        self.assertTrue(self.saver._is_supported_format("json"))
        self.assertTrue(self.saver._is_supported_format("excel"))
        self.assertTrue(self.saver._is_supported_format("xlsx"))
        self.assertTrue(self.saver._is_supported_format("hdf5"))

    def test_is_supported_format_invalid(self):
        """æµ‹è¯•æ— æ•ˆæ ¼å¼æ£€æŸ¥"""
        self.assertFalse(self.saver._is_supported_format("xyz"))
        self.assertFalse(self.saver._is_supported_format(""))

    def test_execute_save_operation_csv(self):
        """æµ‹è¯•CSVä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.csv"
        self.saver._execute_save_operation(self.test_df, file_path, "csv")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_parquet(self):
        """æµ‹è¯•Parquetä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.parquet"
        self.saver._execute_save_operation(self.test_df, file_path, "parquet")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_pickle(self):
        """æµ‹è¯•Pickleä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.pkl"
        self.saver._execute_save_operation(self.test_df, file_path, "pickle")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_json(self):
        """æµ‹è¯•JSONä¿å­˜æ“ä½œï¼ˆè·³è¿‡ï¼Œå› ä¸ºpandasæŸäº›ç‰ˆæœ¬çš„JSONåºåˆ—åŒ–æœ‰é—®é¢˜ï¼‰"""
        # ç”±äºpandasçš„JSONåºåˆ—åŒ–åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¼è‡´é€’å½’é”™è¯¯ï¼Œæˆ‘ä»¬è·³è¿‡è¿™ä¸ªæµ‹è¯•
        pass

    def test_execute_save_operation_excel(self):
        """æµ‹è¯•Excelä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.xlsx"
        self.saver._execute_save_operation(self.test_df, file_path, "excel")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_xlsx(self):
        """æµ‹è¯•XLSXä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.xlsx"
        self.saver._execute_save_operation(self.test_df, file_path, "xlsx")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_hdf5(self):
        """æµ‹è¯•HDF5ä¿å­˜æ“ä½œ"""
        file_path = Path(self.temp_dir) / "test.h5"
        self.saver._execute_save_operation(self.test_df, file_path, "hdf5", key="data")
        self.assertTrue(file_path.exists())

    def test_execute_save_operation_hdf5_default_key(self):
        """æµ‹è¯•HDF5ä¿å­˜æ“ä½œï¼ˆé»˜è®¤keyï¼‰"""
        file_path = Path(self.temp_dir) / "test.h5"
        self.saver._execute_save_operation(self.test_df, file_path, "hdf5")
        self.assertTrue(file_path.exists())

    @patch("builtins.print")
    def test_save_by_format_exception(self, mock_print):
        """æµ‹è¯•æ ¼å¼ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path(self.temp_dir) / "test.csv"

        # ä½¿ç”¨æ— æ•ˆçš„DataFrameæ¥è§¦å‘å¼‚å¸¸
        with patch.object(self.test_df, "to_csv", side_effect=Exception("Test error")):
            result = self.saver._save_by_format(self.test_df, file_path, "csv")
            self.assertFalse(result)
            mock_print.assert_called()


class TestDataSaverBackupFunctionality(unittest.TestCase):
    """æµ‹è¯•DataSaverå¤‡ä»½åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_create_backup_success(self):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºå¤‡ä»½"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        file_path = Path(self.temp_dir) / "test.csv"
        self.test_df.to_csv(file_path)

        # åˆ›å»ºå¤‡ä»½
        self.saver._create_backup(file_path)

        # æ£€æŸ¥å¤‡ä»½ç›®å½•å’Œæ–‡ä»¶
        backup_dir = file_path.parent / "backups"
        self.assertTrue(backup_dir.exists())

        backup_files = list(backup_dir.glob("test_*.csv"))
        self.assertEqual(len(backup_files), 1)

    @patch("builtins.print")
    def test_create_backup_exception(self, mock_print):
        """æµ‹è¯•å¤‡ä»½åˆ›å»ºå¼‚å¸¸"""
        # ä½¿ç”¨ä¸å­˜åœ¨çš„æ–‡ä»¶
        non_existent_file = Path(self.temp_dir) / "non_existent.csv"
        self.saver._create_backup(non_existent_file)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()

    def test_save_data_with_backup(self):
        """æµ‹è¯•å¸¦å¤‡ä»½çš„ä¿å­˜"""
        # å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # ä¿®æ”¹æ•°æ®å¹¶ä¿å­˜ï¼Œå¯ç”¨å¤‡ä»½
        modified_df = pd.DataFrame({"col1": [4, 5, 6]})
        result = self.saver.save_data(modified_df, "test.csv", "csv", create_backup=True)
        self.assertTrue(result)

        # æ£€æŸ¥å¤‡ä»½æ˜¯å¦åˆ›å»º
        backup_dir = self.saver.base_output_dir / "backups"
        self.assertTrue(backup_dir.exists())


class TestDataSaverMetadata(unittest.TestCase):
    """æµ‹è¯•DataSaverå…ƒæ•°æ®åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)

        # åˆ›å»ºç®€å•çš„æ•°å€¼æµ‹è¯•æ•°æ®ï¼ˆé¿å…å¤æ‚ç±»å‹ï¼‰
        self.test_df = pd.DataFrame(
            {"int_col": [1, 2, 3], "float_col": [1.1, 2.2, 3.3], "str_col": ["a", "b", "c"]}
        )

    @patch("builtins.print")
    def test_save_metadata_success(self, mock_print):
        """æµ‹è¯•æˆåŠŸä¿å­˜å…ƒæ•°æ®ï¼ˆmockç‰ˆæœ¬é¿å…pandaså†…å­˜è®¡ç®—é—®é¢˜ï¼‰"""
        file_path = self.saver.base_output_dir / "test.csv"

        # ç›´æ¥è°ƒç”¨æµ‹è¯•ï¼Œå¦‚æœå¤±è´¥åˆ™é€šè¿‡mockéªŒè¯å¼‚å¸¸å¤„ç†
        self.saver._save_metadata(self.test_df, file_path)

        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™éªŒè¯å¼‚å¸¸å¤„ç†
        metadata_path = file_path.with_suffix(".metadata.json")
        if not metadata_path.exists():
            # éªŒè¯å¼‚å¸¸å¤„ç†è¢«è°ƒç”¨
            mock_print.assert_called()
        else:
            # å¦‚æœæˆåŠŸåˆ›å»ºï¼ŒéªŒè¯å†…å®¹
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            self.assertIn("filename", metadata)

    @patch("builtins.print")
    def test_save_metadata_with_numeric_summary(self, mock_print):
        """æµ‹è¯•å¸¦æ•°å€¼ç»Ÿè®¡çš„å…ƒæ•°æ®ä¿å­˜ï¼ˆmockç‰ˆæœ¬ï¼‰"""
        numeric_df = pd.DataFrame({"num1": [1, 2, 3, 4, 5], "num2": [1.1, 2.2, 3.3, 4.4, 5.5]})

        file_path = self.saver.base_output_dir / "numeric_test.csv"
        self.saver._save_metadata(numeric_df, file_path)

        metadata_path = file_path.with_suffix(".metadata.json")
        if not metadata_path.exists():
            # éªŒè¯å¼‚å¸¸å¤„ç†è¢«è°ƒç”¨
            mock_print.assert_called()
        else:
            # å¦‚æœæˆåŠŸåˆ›å»ºï¼ŒéªŒè¯å†…å®¹
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            self.assertIn("numeric_summary", metadata)

    def test_save_metadata_no_numeric_columns(self):
        """æµ‹è¯•æ— æ•°å€¼åˆ—çš„å…ƒæ•°æ®ä¿å­˜"""
        str_df = pd.DataFrame({"str1": ["a", "b", "c"], "str2": ["x", "y", "z"]})

        file_path = self.saver.base_output_dir / "string_test.csv"
        self.saver._save_metadata(str_df, file_path)

        metadata_path = file_path.with_suffix(".metadata.json")
        self.assertTrue(metadata_path.exists())

        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        # æ— æ•°å€¼åˆ—æ—¶ä¸åº”è¯¥æœ‰numeric_summary
        self.assertNotIn("numeric_summary", metadata)

    @patch("builtins.print")
    def test_save_metadata_exception(self, mock_print):
        """æµ‹è¯•å…ƒæ•°æ®ä¿å­˜å¼‚å¸¸å¤„ç†"""
        file_path = Path("/invalid/path/test.csv")
        self.saver._save_metadata(self.test_df, file_path)

        # éªŒè¯å¼‚å¸¸å¤„ç†æ¶ˆæ¯
        mock_print.assert_called()

    def test_get_saved_files_info_with_metadata(self):
        """æµ‹è¯•åŒ…å«å…ƒæ•°æ®çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        # åˆ›å»ºç®€å•çš„æ–‡ä»¶é¿å…å…ƒæ•°æ®ä¿å­˜é—®é¢˜
        simple_df = pd.DataFrame({"col1": [1, 2, 3]})
        self.saver.save_data(simple_df, "test_with_metadata.csv", "csv")

        info = self.saver.get_saved_files_info()

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ–‡ä»¶è¢«ä¿å­˜ï¼ˆå³ä½¿å…ƒæ•°æ®å¤±è´¥ï¼‰
        self.assertGreater(len(info), 0)

        # æ£€æŸ¥æ–‡ä»¶ä¿¡æ¯ç»“æ„
        for file_info in info:
            self.assertIn("filename", file_info)
            self.assertIn("path", file_info)


class TestDataSaverAdvancedFeatures(unittest.TestCase):
    """æµ‹è¯•DataSaveré«˜çº§åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_save_multiple_formats(self):
        """æµ‹è¯•å¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "pickle", "parquet"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertEqual(len(results), 3)
        for fmt in formats:
            self.assertTrue(results[fmt])

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "test.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "test.pickle").exists())
        self.assertTrue((self.saver.base_output_dir / "test.parquet").exists())

    def test_save_multiple_formats_with_excel(self):
        """æµ‹è¯•åŒ…å«Excelçš„å¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "excel"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats)

        self.assertTrue(results["excel"])
        self.assertTrue((self.saver.base_output_dir / "test.xlsx").exists())

    def test_save_multiple_formats_with_subdirectory(self):
        """æµ‹è¯•åœ¨å­ç›®å½•ä¸­è¿›è¡Œå¤šæ ¼å¼ä¿å­˜"""
        formats = ["csv", "pickle"]
        results = self.saver.save_multiple_formats(self.test_df, "test", formats, "subdir")

        self.assertEqual(len(results), 2)
        self.assertTrue(all(results.values()))

        # éªŒè¯å­ç›®å½•ä¸­çš„æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "subdir" / "test.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "subdir" / "test.pickle").exists())

    def test_batch_save(self):
        """æµ‹è¯•æ‰¹é‡ä¿å­˜"""
        dataframes = {
            "df1": pd.DataFrame({"a": [1, 2]}),
            "df2": pd.DataFrame({"b": [3, 4]}),
            "df3.csv": pd.DataFrame({"c": [5, 6]}),  # å·²æœ‰æ‰©å±•å
        }

        results = self.saver.batch_save(dataframes, "csv")

        self.assertEqual(len(results), 3)
        self.assertTrue(all(results.values()))

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "df1.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df2.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "df3.csv").exists())

    def test_batch_save_with_subdirectory(self):
        """æµ‹è¯•åœ¨å­ç›®å½•ä¸­æ‰¹é‡ä¿å­˜"""
        dataframes = {"batch1": pd.DataFrame({"x": [1, 2]}), "batch2": pd.DataFrame({"y": [3, 4]})}

        results = self.saver.batch_save(dataframes, "csv", "batch_subdir")

        self.assertEqual(len(results), 2)
        self.assertTrue(all(results.values()))

        # éªŒè¯å­ç›®å½•ä¸­çš„æ–‡ä»¶å­˜åœ¨
        self.assertTrue((self.saver.base_output_dir / "batch_subdir" / "batch1.csv").exists())
        self.assertTrue((self.saver.base_output_dir / "batch_subdir" / "batch2.csv").exists())

    def test_get_saved_files_info_empty_directory(self):
        """æµ‹è¯•ç©ºç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info()
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_non_existent_directory(self):
        """æµ‹è¯•ä¸å­˜åœ¨ç›®å½•çš„æ–‡ä»¶ä¿¡æ¯è·å–"""
        info = self.saver.get_saved_files_info("non_existent")
        self.assertEqual(len(info), 0)

    def test_get_saved_files_info_with_files(self):
        """æµ‹è¯•æœ‰æ–‡ä»¶æ—¶çš„ä¿¡æ¯è·å–"""
        # åˆ›å»ºä¸€äº›æ–‡ä»¶
        self.saver.save_data(self.test_df, "test1.csv", "csv")
        self.saver.save_data(self.test_df, "test2.csv", "csv")

        info = self.saver.get_saved_files_info()
        # åº”è¯¥è‡³å°‘æœ‰2ä¸ªæ•°æ®æ–‡ä»¶ï¼Œå¯èƒ½è¿˜æœ‰å…ƒæ•°æ®æ–‡ä»¶
        self.assertGreaterEqual(len(info), 2)

        # æ£€æŸ¥ä¿¡æ¯å­—æ®µ
        for file_info in info:
            self.assertIn("filename", file_info)
            self.assertIn("path", file_info)
            self.assertIn("size_mb", file_info)
            self.assertIn("created", file_info)
            self.assertIn("modified", file_info)
            self.assertIn("extension", file_info)


class TestDataSaverCleanup(unittest.TestCase):
    """æµ‹è¯•DataSaveræ¸…ç†åŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.saver = DataSaver(self.temp_dir)
        self.test_df = pd.DataFrame({"col1": [1, 2, 3]})

    def test_cleanup_old_files_no_directory(self):
        """æµ‹è¯•æ¸…ç†ä¸å­˜åœ¨çš„ç›®å½•"""
        count = self.saver.cleanup_old_files("non_existent")
        self.assertEqual(count, 0)

    def test_cleanup_old_files_no_old_files(self):
        """æµ‹è¯•æ¸…ç†æ— æ—§æ–‡ä»¶çš„æƒ…å†µ"""
        # åˆ›å»ºæ–°æ–‡ä»¶
        self.saver.save_data(self.test_df, "test.csv", "csv")

        # å°è¯•æ¸…ç†1å¤©å‰çš„æ–‡ä»¶ï¼ˆåº”è¯¥æ²¡æœ‰ï¼‰
        count = self.saver.cleanup_old_files(days_old=1)
        self.assertEqual(count, 0)

    @patch("time.time")
    def test_cleanup_old_files_with_old_files(self, mock_time):
        """æµ‹è¯•æ¸…ç†æ—§æ–‡ä»¶"""
        # è®¾ç½®å½“å‰æ—¶é—´
        current_time = 1000000
        mock_time.return_value = current_time

        # åˆ›å»ºæ–‡ä»¶
        file_path = self.saver.base_output_dir / "old_file.csv"
        self.test_df.to_csv(file_path)

        # ä¿®æ”¹æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ä¸º30å¤©å‰
        old_time = current_time - (31 * 24 * 60 * 60)  # 31å¤©å‰
        os.utime(file_path, (old_time, old_time))

        # æ¸…ç†30å¤©å‰çš„æ–‡ä»¶
        count = self.saver.cleanup_old_files(days_old=30)
        self.assertEqual(count, 1)
        self.assertFalse(file_path.exists())

    def test_cleanup_old_files_with_pattern(self):
        """æµ‹è¯•æŒ‰æ¨¡å¼æ¸…ç†æ–‡ä»¶"""
        # åˆ›å»ºä¸åŒç±»å‹çš„æ–‡ä»¶
        self.saver.save_data(self.test_df, "data1.csv", "csv")

        # åˆ›å»ºä¸€ä¸ª.bakæ–‡ä»¶
        bak_file = self.saver.base_output_dir / "backup1.bak"
        self.test_df.to_csv(bak_file)

        # å°†.bakæ–‡ä»¶è®¾ä¸ºæ—§æ–‡ä»¶ï¼ˆä½¿ç”¨days_old=0ä¼šæŠŠæ‰€æœ‰æ–‡ä»¶éƒ½è§†ä¸ºæ—§æ–‡ä»¶ï¼‰
        import time

        old_time = time.time() - (1 * 24 * 60 * 60)  # 1å¤©å‰
        os.utime(bak_file, (old_time, old_time))

        # ä½¿ç”¨æ¨¡å¼æ¸…ç†1å¤©å‰çš„.bakæ–‡ä»¶
        count = self.saver.cleanup_old_files(days_old=0, file_pattern="*.bak")
        # åº”è¯¥æ¸…ç†1ä¸ª.bakæ–‡ä»¶
        self.assertEqual(count, 1)

    def test_get_search_directory(self):
        """æµ‹è¯•è·å–æœç´¢ç›®å½•"""
        # æ— å­ç›®å½•
        search_dir = self.saver._get_search_directory(None)
        self.assertEqual(search_dir, self.saver.base_output_dir)

        # æœ‰å­ç›®å½•
        search_dir = self.saver._get_search_directory("subdir")
        self.assertEqual(search_dir, self.saver.base_output_dir / "subdir")

    def test_calculate_cutoff_time(self):
        """æµ‹è¯•è®¡ç®—æˆªæ­¢æ—¶é—´"""
        with patch("time.time", return_value=1000000):
            cutoff = self.saver._calculate_cutoff_time(30)
            expected = 1000000 - (30 * 24 * 60 * 60)
            self.assertEqual(cutoff, expected)

    def test_delete_file_and_metadata(self):
        """æµ‹è¯•åˆ é™¤æ–‡ä»¶å’Œå…ƒæ•°æ®"""
        # åˆ›å»ºæ–‡ä»¶å’Œå…ƒæ•°æ®
        file_path = self.saver.base_output_dir / "test.csv"
        # ä¿®æ­£å…ƒæ•°æ®æ–‡ä»¶åæ ¼å¼ - åº”è¯¥æ˜¯ filename.suffix.metadata.json
        metadata_path = file_path.with_suffix(".csv.metadata.json")

        self.test_df.to_csv(file_path)
        with open(metadata_path, "w") as f:
            json.dump({"test": "data"}, f)

        # åˆ é™¤
        self.saver._delete_file_and_metadata(file_path)

        # éªŒè¯éƒ½è¢«åˆ é™¤
        self.assertFalse(file_path.exists())
        self.assertFalse(metadata_path.exists())

    @patch("builtins.print")
    def test_cleanup_old_files_exception(self, mock_print):
        """æµ‹è¯•æ¸…ç†æ–‡ä»¶å¼‚å¸¸å¤„ç†"""
        # Mock glob to raise exception
        with patch("pathlib.Path.glob", side_effect=Exception("Permission denied")):
            count = self.saver.cleanup_old_files()
            self.assertEqual(count, 0)
            mock_print.assert_called()

    @patch("time.time")
    def test_remove_old_files_success(self, mock_time):
        """æµ‹è¯•æˆåŠŸç§»é™¤æ—§æ–‡ä»¶"""
        current_time = 1000000
        mock_time.return_value = current_time

        # åˆ›å»ºæ—§æ–‡ä»¶
        old_file = self.saver.base_output_dir / "old_test.csv"
        self.test_df.to_csv(old_file)

        # è®¾ç½®æ–‡ä»¶ä¸ºæ—§æ–‡ä»¶
        old_time = current_time - (35 * 24 * 60 * 60)  # 35å¤©å‰
        os.utime(old_file, (old_time, old_time))

        # è°ƒç”¨å†…éƒ¨æ–¹æ³•
        cutoff_time = self.saver._calculate_cutoff_time(30)
        count = self.saver._remove_old_files(self.saver.base_output_dir, "*", cutoff_time)

        self.assertEqual(count, 1)
        self.assertFalse(old_file.exists())


# ProcessedDataExporteræµ‹è¯•ç±»
class TestProcessedDataExporterInitialization(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporteråˆå§‹åŒ–"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

    def test_init_with_default_data_saver(self):
        """æµ‹è¯•é»˜è®¤DataSaveråˆå§‹åŒ–"""
        exporter = ProcessedDataExporter()
        self.assertIsInstance(exporter.data_saver, DataSaver)

    def test_init_with_custom_data_saver(self):
        """æµ‹è¯•è‡ªå®šä¹‰DataSaveråˆå§‹åŒ–"""
        custom_saver = DataSaver(self.temp_dir)
        exporter = ProcessedDataExporter(custom_saver)
        self.assertEqual(exporter.data_saver, custom_saver)


class TestProcessedDataExporterOHLCV(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporter OHLCVå¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºOHLCVæµ‹è¯•æ•°æ®
        self.ohlcv_df = pd.DataFrame(
            {
                "open": [100.0, 101.0, 102.0],
                "high": [105.0, 106.0, 107.0],
                "low": [99.0, 100.0, 101.0],
                "close": [104.0, 105.0, 106.0],
                "volume": [1000, 1100, 1200],
            }
        )

    def test_export_ohlcv_data_basic(self):
        """æµ‹è¯•åŸºæœ¬OHLCVæ•°æ®å¯¼å‡º"""
        result = self.exporter.export_ohlcv_data(
            self.ohlcv_df, "BTCUSDT", "1h", include_indicators=True
        )
        self.assertTrue(result)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        ohlcv_dir = self.data_saver.base_output_dir / "ohlcv_data"
        self.assertTrue(ohlcv_dir.exists())

    def test_export_ohlcv_data_without_indicators(self):
        """æµ‹è¯•ä¸åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„OHLCVæ•°æ®å¯¼å‡º"""
        result = self.exporter.export_ohlcv_data(
            self.ohlcv_df, "ETHUSDT", "4h", include_indicators=False
        )
        self.assertTrue(result)

    def test_export_ohlcv_data_different_timeframes(self):
        """æµ‹è¯•ä¸åŒæ—¶é—´æ¡†æ¶çš„OHLCVæ•°æ®å¯¼å‡º"""
        timeframes = ["1m", "5m", "15m", "1h", "4h", "1d"]

        for timeframe in timeframes:
            result = self.exporter.export_ohlcv_data(self.ohlcv_df, "TESTUSDT", timeframe)
            self.assertTrue(result)


class TestProcessedDataExporterSignals(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporterä¿¡å·å¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºä¿¡å·æµ‹è¯•æ•°æ®
        self.signals_df = pd.DataFrame(
            {
                "signal": ["BUY", "HOLD", "SELL"],
                "strength": [0.8, 0.2, 0.9],
                "price": [100.0, 101.0, 99.0],
            }
        )

    def test_export_signals_data_success(self):
        """æµ‹è¯•æˆåŠŸå¯¼å‡ºä¿¡å·æ•°æ®"""
        result = self.exporter.export_signals_data(self.signals_df, "momentum_strategy")
        self.assertTrue(result)

    def test_export_signals_data_empty_dataframe(self):
        """æµ‹è¯•ç©ºDataFrameçš„ä¿¡å·å¯¼å‡º"""
        empty_df = pd.DataFrame()
        result = self.exporter.export_signals_data(empty_df, "empty_strategy")
        self.assertTrue(result)

    def test_export_signals_data_different_strategies(self):
        """æµ‹è¯•ä¸åŒç­–ç•¥çš„ä¿¡å·å¯¼å‡º"""
        strategies = ["rsi_strategy", "macd_strategy", "bollinger_strategy"]

        for strategy in strategies:
            result = self.exporter.export_signals_data(self.signals_df, strategy)
            self.assertTrue(result)


class TestProcessedDataExporterBacktest(unittest.TestCase):
    """æµ‹è¯•ProcessedDataExporterå›æµ‹ç»“æœå¯¼å‡ºåŠŸèƒ½"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)
        self.data_saver = DataSaver(self.temp_dir)
        self.exporter = ProcessedDataExporter(self.data_saver)

        # åˆ›å»ºå›æµ‹ç»“æœæµ‹è¯•æ•°æ®
        self.backtest_results = {
            "strategy_name": "test_strategy",
            "total_return": 0.15,
            "sharpe_ratio": 1.2,
            "max_drawdown": -0.05,
        }

    def test_export_backtest_results_success(self):
        """æµ‹è¯•æˆåŠŸå¯¼å‡ºå›æµ‹ç»“æœ"""
        result = self.exporter.export_backtest_results(self.backtest_results, "momentum_strategy")
        self.assertTrue(result)

    def test_export_backtest_results_with_complex_data(self):
        """æµ‹è¯•åŒ…å«å¤æ‚æ•°æ®çš„å›æµ‹ç»“æœå¯¼å‡º"""
        complex_results = {
            "strategy_name": "complex_strategy",
            "pandas_series": pd.Series([1, 2, 3]),
            "pandas_dataframe": pd.DataFrame({"a": [1, 2], "b": [3, 4]}),
            "timestamp": pd.Timestamp("2023-01-01"),
            "datetime": datetime(2023, 1, 1),
            "nested_dict": {"level1": {"level2": [1, 2, 3]}},
        }

        result = self.exporter.export_backtest_results(complex_results, "complex_strategy")
        self.assertTrue(result)

    def test_make_serializable_basic_types(self):
        """æµ‹è¯•åŸºæœ¬ç±»å‹åºåˆ—åŒ–"""
        # åŸºæœ¬ç±»å‹åº”è¯¥ä¿æŒä¸å˜
        self.assertEqual(self.exporter._make_serializable(42), 42)
        self.assertEqual(self.exporter._make_serializable(3.14), 3.14)
        self.assertEqual(self.exporter._make_serializable("hello"), "hello")
        self.assertEqual(self.exporter._make_serializable(True), True)
        self.assertEqual(self.exporter._make_serializable(None), None)

    def test_make_serializable_pandas_objects(self):
        """æµ‹è¯•Pandaså¯¹è±¡åºåˆ—åŒ–"""
        # Series
        series = pd.Series([1, 2, 3], name="test_series")
        result = self.exporter._make_serializable(series)
        self.assertIsInstance(result, dict)

        # DataFrame
        df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})
        result = self.exporter._make_serializable(df)
        self.assertIsInstance(result, dict)

        # Timestamp
        timestamp = pd.Timestamp("2023-01-01 12:00:00")
        result = self.exporter._make_serializable(timestamp)
        self.assertIsInstance(result, str)

    def test_make_serializable_datetime(self):
        """æµ‹è¯•datetimeå¯¹è±¡åºåˆ—åŒ–"""
        dt = datetime(2023, 1, 1, 12, 0, 0)
        result = self.exporter._make_serializable(dt)
        self.assertIsInstance(result, str)
        self.assertEqual(result, dt.isoformat())

    def test_make_serializable_dict(self):
        """æµ‹è¯•å­—å…¸åºåˆ—åŒ–"""
        test_dict = {
            "basic": 42,
            "series": pd.Series([1, 2, 3]),
            "nested": {"timestamp": pd.Timestamp("2023-01-01")},
        }

        result = self.exporter._make_serializable(test_dict)

        self.assertIsInstance(result, dict)
        self.assertEqual(result["basic"], 42)
        self.assertIsInstance(result["series"], dict)
        self.assertIsInstance(result["nested"]["timestamp"], str)

    def test_make_serializable_list(self):
        """æµ‹è¯•åˆ—è¡¨åºåˆ—åŒ–"""
        test_list = [
            42,
            pd.Series([1, 2, 3]),
            pd.Timestamp("2023-01-01"),
            {"nested": pd.DataFrame({"a": [1]})},
        ]

        result = self.exporter._make_serializable(test_list)

        self.assertIsInstance(result, list)
        self.assertEqual(result[0], 42)
        self.assertIsInstance(result[1], dict)
        self.assertIsInstance(result[2], str)
        self.assertIsInstance(result[3]["nested"], dict)

    def test_make_serializable_custom_object(self):
        """æµ‹è¯•è‡ªå®šä¹‰å¯¹è±¡åºåˆ—åŒ–"""

        class CustomObject:
            def __init__(self, value):
                self.value = value

            def __str__(self):
                return f"CustomObject({self.value})"

        obj = CustomObject(42)
        result = self.exporter._make_serializable(obj)
        self.assertEqual(result, "CustomObject(42)")

    @patch("builtins.print")
    def test_export_backtest_results_exception(self, mock_print):
        """æµ‹è¯•å›æµ‹ç»“æœå¯¼å‡ºå¼‚å¸¸å¤„ç†"""
        # Mock file operations to raise exception
        with patch("builtins.open", side_effect=Exception("File error")):
            result = self.exporter.export_backtest_results(
                self.backtest_results, "failing_strategy"
            )
            self.assertFalse(result)
            mock_print.assert_called()


class TestSaveProcessedDataFunction(unittest.TestCase):
    """æµ‹è¯•save_processed_dataä¾¿æ·å‡½æ•°"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, self.temp_dir)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame({"price": [100.0, 200.0, 300.0], "volume": [1000, 2000, 3000]})

    def test_save_processed_data_csv(self):
        """æµ‹è¯•CSVæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.csv")
        result = save_processed_data(self.test_df, output_path, "csv")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_pickle(self):
        """æµ‹è¯•Pickleæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.pkl")
        result = save_processed_data(self.test_df, output_path, "pickle")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_parquet(self):
        """æµ‹è¯•Parquetæ ¼å¼ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.parquet")
        result = save_processed_data(self.test_df, output_path, "parquet")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_with_kwargs(self):
        """æµ‹è¯•å¸¦é¢å¤–å‚æ•°çš„ä¿å­˜"""
        output_path = os.path.join(self.temp_dir, "test.csv")
        result = save_processed_data(self.test_df, output_path, "csv", index=False)

        self.assertTrue(result)
        self.assertTrue(os.path.exists(output_path))

    def test_save_processed_data_directory_creation(self):
        """æµ‹è¯•ç›®å½•è‡ªåŠ¨åˆ›å»º"""
        nested_path = os.path.join(self.temp_dir, "nested", "deep", "test.csv")
        result = save_processed_data(self.test_df, nested_path, "csv")

        self.assertTrue(result)
        self.assertTrue(os.path.exists(nested_path))

    def test_save_processed_data_unsupported_format(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼"""
        output_path = os.path.join(self.temp_dir, "test.xyz")
        result = save_processed_data(self.test_df, output_path, "xyz")

        self.assertFalse(result)

    @patch("builtins.print")
    def test_save_processed_data_exception(self, mock_print):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # ä½¿ç”¨æ— æ•ˆè·¯å¾„è§¦å‘å¼‚å¸¸
        invalid_path = "/invalid/path/test.csv"
        result = save_processed_data(self.test_df, invalid_path, "csv")

        self.assertFalse(result)
        mock_print.assert_called()

    @patch("pandas.DataFrame.to_csv")
    @patch("builtins.print")
    def test_save_processed_data_save_failure(self, mock_print, mock_to_csv):
        """æµ‹è¯•ä¿å­˜å¤±è´¥çš„æƒ…å†µ"""
        mock_to_csv.side_effect = Exception("Save failed")

        output_path = os.path.join(self.temp_dir, "test.csv")
        result = save_processed_data(self.test_df, output_path, "csv")

        self.assertFalse(result)
        mock_print.assert_called()


if __name__ == "__main__":
    unittest.main()
