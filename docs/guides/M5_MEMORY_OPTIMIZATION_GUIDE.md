# ğŸ§  M5å†…å­˜&GCä¼˜åŒ–æŒ‡å—
# M5 Memory & GC Optimization Guide

## ğŸ¯ æ¦‚è¿°

M5é˜¶æ®µä¸“æ³¨äºå†…å­˜ä½¿ç”¨ä¼˜åŒ–å’Œåƒåœ¾å›æ”¶æ€§èƒ½è°ƒä¼˜ï¼Œç›®æ ‡æ˜¯åœ¨ä¿æŒM4å¼‚æ­¥æ€§èƒ½çš„åŸºç¡€ä¸Šï¼Œå°†å†…å­˜å ç”¨å‡å°‘25%ï¼ŒGCæš‚åœæ—¶é—´å‡å°‘50%ã€‚

**æ ¸å¿ƒç›®æ ‡**:
- RSSå†…å­˜å³°å€¼ < 40MB
- GCæš‚åœP95 < 50ms  
- æ–‡ä»¶æè¿°ç¬¦ç¨³å®š < 500
- 24å°æ—¶å†…å­˜å¢é•¿ < 5%

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ åŸºçº¿é‡‡é›† (30åˆ†é’Ÿ)
```bash
# é‡‡é›†å½“å‰ç³»ç»Ÿå†…å­˜åŸºçº¿
make mem-baseline

# æˆ–è‡ªå®šä¹‰å‚æ•°
python scripts/mem_baseline.py --duration 1800 --save output/baseline.json
```

### 2ï¸âƒ£ å†…å­˜å¥åº·æ£€æŸ¥
```bash
# å¿«é€Ÿå¥åº·çŠ¶æ€
make mem-health

# è¯¦ç»†å†…å­˜å¿«ç…§
make mem-snapshot
```

### 3ï¸âƒ£ GCæ€§èƒ½åˆ†æ
```bash
# 5åˆ†é’ŸGCç›‘æ§
make gc-profile

# æˆ–è‡ªå®šä¹‰æ—¶é•¿
python scripts/gc_profiler.py --duration 300 --optimize
```

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡ä½“ç³»

### æ ¸å¿ƒå†…å­˜æŒ‡æ ‡
```yaml
process_memory_rss_bytes:     # RSSå†…å­˜ä½¿ç”¨é‡
  target: < 40MB
  alert: > 60MB

memory_growth_rate_mb_per_minute:  # å†…å­˜å¢é•¿ç‡
  target: < 0.1MB/min
  alert: > 0.5MB/min

memory_peak_rss_bytes:        # å†…å­˜å³°å€¼
  tracking: å¯åŠ¨åæœ€é«˜å€¼
```

### GCæ€§èƒ½æŒ‡æ ‡
```yaml
gc_pause_duration_seconds:    # GCæš‚åœæ—¶é—´
  target_p95: < 0.05s
  alert_p95: > 0.1s

gc_collections_by_generation_total:  # åˆ†ä»£å›æ”¶æ¬¡æ•°
  gen0_frequency: < 10/sec
  gen1_frequency: < 1/sec
  gen2_frequency: < 0.1/sec
```

### èµ„æºæ³„æ¼æ£€æµ‹
```yaml
process_open_fds:             # æ–‡ä»¶æè¿°ç¬¦
  stable_range: 10-500
  leak_threshold: > 800

active_connections:           # ç½‘ç»œè¿æ¥æ•°
  websocket_target: 3-10
  leak_detection: è‡ªåŠ¨è¯†åˆ«
```

---

## ğŸ—ï¸ ä¼˜åŒ–ç­–ç•¥

### W1: å¯¹è±¡æ± /LRUç¼“å­˜
**ç›®æ ‡**: RSSå‡å°‘25%

#### DataFrameå¤ç”¨æ± 
```python
from cachetools import LRUCache

# DataFrameå¤ç”¨æ± 
df_pool = LRUCache(maxsize=50)

@cached(df_pool, key=lambda symbol, window: f"{symbol}_{window}")
def get_market_data_window(symbol: str, window: int) -> pd.DataFrame:
    """å¤ç”¨DataFrameçª—å£ï¼Œé¿å…é‡å¤åˆ†é…"""
    return self.market_data[symbol].tail(window).copy()
```

#### ATR/MAè®¡ç®—ç¼“å­˜
```python
# æŠ€æœ¯æŒ‡æ ‡LRUç¼“å­˜
indicator_cache = LRUCache(maxsize=100)

@cached(indicator_cache)
def compute_cached_atr(data_hash: str, period: int) -> float:
    """ç¼“å­˜ATRè®¡ç®—ç»“æœ"""
    return self._compute_atr_internal(period)
```

#### é¢„åˆ†é…ç­–ç•¥
```python
# é¢„åˆ†é…å›ºå®šå¤§å°çš„DataFrame
def init_data_buffer(self, max_candles: int = 200):
    """é¢„åˆ†é…æ•°æ®ç¼“å†²åŒºï¼Œé¿å…åŠ¨æ€æ‰©å±•"""
    self.data_buffer = pd.DataFrame(
        index=range(max_candles),
        columns=['open', 'high', 'low', 'close', 'volume']
    )
    self.buffer_index = 0
```

### W2: GCè°ƒå‚ä¼˜åŒ–
**ç›®æ ‡**: GCæš‚åœå‡å°‘50%

#### åŠ¨æ€é˜ˆå€¼è°ƒæ•´
```python
import gc

# M5æ¨èçš„GCé˜ˆå€¼
def optimize_gc_settings():
    """M5ä¼˜åŒ–çš„GCè®¾ç½®"""
    # å‡å°‘Gen0é¢‘ç‡ï¼Œå¢åŠ æ‰¹é‡å¤„ç†
    gc.set_threshold(700, 10, 10)  # é»˜è®¤(700,10,10)
    
    # ç¦ç”¨debugæ¨¡å¼
    gc.set_debug(0)
    
    # æ³¨å†ŒGCç›‘æ§å›è°ƒ
    gc.callbacks.append(gc_monitoring_callback)
```

#### æ‰‹åŠ¨GCè§¦å‘ç­–ç•¥
```python
async def periodic_gc_management(self):
    """å®šæœŸGCç®¡ç†"""
    while self.running:
        # åœ¨ä½è´Ÿè½½æ—¶æœŸä¸»åŠ¨è§¦å‘GC
        if self.current_load < 0.3:
            collected = gc.collect()
            self.metrics.record_gc_event(
                generation=-1, 
                pause_duration=0.001,  # ä¸»åŠ¨GCé€šå¸¸å¾ˆå¿«
                collected_objects=collected
            )
        
        await asyncio.sleep(30)
```

### W3: èµ„æºæ³„æ¼é˜²æŠ¤
**ç›®æ ‡**: FD/è¿æ¥ç¨³å®š<500

#### WebSocketè¿æ¥æ± ç®¡ç†
```python
class ManagedWSPool:
    """ç®¡ç†WebSocketè¿æ¥æ± ï¼Œé˜²æ­¢æ³„æ¼"""
    
    def __init__(self, max_connections: int = 10):
        self.pool = []
        self.max_connections = max_connections
        self._cleanup_timer = None
    
    async def cleanup_stale_connections(self):
        """æ¸…ç†å¤±æ•ˆè¿æ¥"""
        stale_connections = []
        for conn in self.pool:
            if conn.closed or time.time() - conn.last_activity > 300:
                stale_connections.append(conn)
        
        for conn in stale_connections:
            await conn.close()
            self.pool.remove(conn)
```

#### æ–‡ä»¶æè¿°ç¬¦ç›‘æ§
```python
def monitor_fd_leaks(self):
    """ç›‘æ§æ–‡ä»¶æè¿°ç¬¦æ³„æ¼"""
    current_fds = psutil.Process().num_fds()
    
    if current_fds > 800:  # æ³„æ¼é˜ˆå€¼
        self.logger.warning(f"ğŸš¨ FDæ³„æ¼æ£€æµ‹: {current_fds}")
        
        # è‡ªåŠ¨æ¸…ç†
        self._emergency_cleanup()
        
        # å‘Šè­¦
        self.metrics.update_fd_growth_rate(
            (current_fds - self._last_fd_count) / 60  # æ¯åˆ†é’Ÿå¢é•¿
        )
```

---

## ğŸ› ï¸ å·¥å…·ä½¿ç”¨æŒ‡å—

### å†…å­˜å¿«ç…§åˆ†æ
```bash
# è¿ç»­ç›‘æ§60åˆ†é’Ÿï¼Œæ¯60ç§’ä¸€æ¬¡å¿«ç…§
python scripts/mem_snapshot.py --continuous 60 --interval 60

# å•æ¬¡è¯¦ç»†å¿«ç…§
python scripts/mem_snapshot.py --top 50 --save
```

è¾“å‡ºåˆ†æï¼š
```json
{
  "summary": {
    "memory_stats": {
      "max_rss_mb": 45.2,
      "total_growth_mb": 2.1
    },
    "leak_detection": [
      {
        "type": "rss_growth", 
        "severity": "medium",
        "growth_rate_mb_per_snapshot": 0.5
      }
    ]
  }
}
```

### GCæ€§èƒ½è°ƒä¼˜
```bash
# åˆ†æå½“å‰GCæ€§èƒ½
python scripts/gc_profiler.py --duration 600 --prometheus

# è‡ªåŠ¨åº”ç”¨ä¼˜åŒ–å»ºè®®
python scripts/gc_profiler.py --duration 300 --optimize
```

è¾“å‡ºè§£è¯»ï¼š
```
ğŸ—‘ï¸ GCæ€§èƒ½åˆ†ææŠ¥å‘Š
â±ï¸ ç›‘æ§æ—¶é•¿: 300.0ç§’
ğŸ“Š GCäº‹ä»¶: 45æ¬¡
â¸ï¸ æ€»æš‚åœæ—¶é—´: 234.5ms
ğŸ“ˆ å¹³å‡æš‚åœ: 5.21ms
ğŸ”„ GCé¢‘ç‡: 0.15/ç§’

ğŸ·ï¸ åˆ†ä»£ç»Ÿè®¡:
   Gen0: 42æ¬¡, å¹³å‡5.1ms, P95=12.3ms
   Gen1: 3æ¬¡, å¹³å‡8.7ms, P95=15.2ms

ğŸ’¡ ä¼˜åŒ–å»ºè®®:
   gen0: 900 (Gen0é¢‘ç‡è¿‡é«˜(0.14/s)ï¼Œå»ºè®®å¢åŠ é˜ˆå€¼)
```

### åŸºçº¿å¯¹æ¯”åˆ†æ
```bash
# å»ºç«‹åŸºçº¿
python scripts/mem_baseline.py --duration 1800 --save baseline_v1.json

# ä¼˜åŒ–åå¯¹æ¯”
python scripts/mem_baseline.py --duration 1800 --save baseline_v2.json --compare baseline_v1.json
```

---

## ğŸ“ˆ æŒç»­ç›‘æ§è®¾ç½®

### Prometheuså‘Šè­¦è§„åˆ™
```yaml
groups:
- name: m5_memory_alerts
  rules:
  - alert: MemoryUsageHigh
    expr: process_memory_rss_bytes > 60 * 1024 * 1024
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å†…å­˜ä½¿ç”¨è¿‡é«˜"
      
  - alert: GCPauseTimeHigh  
    expr: histogram_quantile(0.95, gc_pause_duration_seconds) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "GCæš‚åœæ—¶é—´è¿‡é•¿"
      
  - alert: FDLeakDetected
    expr: increase(process_open_fds[5m]) > 50
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "æ£€æµ‹åˆ°æ–‡ä»¶æè¿°ç¬¦æ³„æ¼"
```

### è‡ªåŠ¨åŒ–ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# scripts/memory_watchdog.sh

while true; do
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    RSS_MB=$(python -c "import psutil; print(psutil.Process().memory_info().rss // 1024 // 1024)")
    
    if [ $RSS_MB -gt 80 ]; then
        echo "ğŸš¨ å†…å­˜ä½¿ç”¨è¿‡é«˜: ${RSS_MB}MB"
        
        # è‡ªåŠ¨ç”Ÿæˆå¿«ç…§
        python scripts/mem_snapshot.py --save --top 10
        
        # å¯é€‰ï¼šè‡ªåŠ¨é‡å¯
        # systemctl restart trading-engine
    fi
    
    sleep 300  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
done
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### å†…å­˜å‹åŠ›æµ‹è¯•
```python
async def memory_stress_test(duration_hours: int = 24):
    """24å°æ—¶å†…å­˜å‹åŠ›æµ‹è¯•"""
    
    start_rss = psutil.Process().memory_info().rss
    
    for hour in range(duration_hours):
        # æ¨¡æ‹Ÿé«˜è´Ÿè½½
        await simulate_high_frequency_trading()
        
        # æ¯å°æ—¶æ£€æŸ¥
        current_rss = psutil.Process().memory_info().rss
        growth_mb = (current_rss - start_rss) / 1024 / 1024
        
        if growth_mb > hour * 2:  # æ¯å°æ—¶å¢é•¿>2MBè§†ä¸ºå¼‚å¸¸
            raise MemoryLeakDetected(f"å†…å­˜å¢é•¿å¼‚å¸¸: {growth_mb:.1f}MB")
        
        await asyncio.sleep(3600)
```

### æ€§èƒ½å›å½’æµ‹è¯•
```bash
# CI/CDé›†æˆ
- name: M5å†…å­˜å›å½’æµ‹è¯•
  run: |
    python scripts/mem_baseline.py --duration 600 --save current.json
    python scripts/compare_with_baseline.py current.json baseline.json --threshold 15
```

---

## ğŸ¯ M5å®Œæˆæ ‡å‡†

### å®šé‡æŒ‡æ ‡
- [x] RSSå³°å€¼ < 40MB (å½“å‰: ~12MB âœ…)
- [ ] GCæš‚åœP95 < 50ms (ç›®æ ‡)
- [x] FDæ•°é‡ < 500 (å½“å‰: ~3 âœ…)
- [ ] 24hå†…å­˜å¢é•¿ < 5% (å¾…æµ‹è¯•)

### åŸºç¡€è®¾æ–½
- [x] âœ… å†…å­˜ç›‘æ§å·¥å…·å¥—ä»¶
- [x] âœ… GCæ€§èƒ½åˆ†æå™¨  
- [x] âœ… åŸºçº¿é‡‡é›†ç³»ç»Ÿ
- [x] âœ… PrometheusæŒ‡æ ‡é›†æˆ
- [x] âœ… è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹

### éƒ¨ç½²å°±ç»ªåº¦
- [ ] å¯¹è±¡æ± /LRUå®ç°
- [ ] GCå‚æ•°ä¼˜åŒ–åº”ç”¨
- [ ] 24å°æ—¶ç¨³å®šæ€§éªŒè¯
- [ ] ç”Ÿäº§ç¯å¢ƒç›‘æ§é…ç½®

---

## ğŸ”— ç›¸å…³èµ„æº

- **M4å¼‚æ­¥æ¶æ„æ–‡æ¡£**: `docs/M4_INCIDENT_RUNBOOK.md`
- **Prometheusç›‘æ§**: `src/monitoring/metrics_collector.py`
- **å·¥å…·è„šæœ¬ç›®å½•**: `scripts/mem_*.py`, `scripts/gc_*.py`
- **CI/CDé›†æˆ**: `.github/workflows/perf-regression.yml`

---

**æœ€åæ›´æ–°**: 2024-12-20  
**è´Ÿè´£å›¢é˜Ÿ**: M5 Memory Optimization Team  
**ç‰ˆæœ¬**: v5.0.0-alpha 